
@article{altmanAbsenceEvidenceNot1995,
  title = {Absence of Evidence Is Not Evidence of Absence},
  author = {Altman, D. G. and Bland, J. M.},
  year = {1995},
  month = aug,
  volume = {311},
  pages = {485},
  issn = {0959-8138},
  doi = {10.1136/bmj.311.7003.485},
  file = {/Users/zad/Google Drive/Research/Zotero/BMJ (Clinical research ed.)/1995/Altman_Bland_1995_Absence of evidence is not evidence of absence.pdf},
  journal = {BMJ (Clinical research ed.)},
  keywords = {Clinical Research,Clinical Trials,Controlled Clinical Trials as Topic,Data Analysis,Data Interpretation; Statistical,Measurement,Methodological Studies,Randomized Controlled Trials as Topic,Research Methodology,Sample Size,Statistical Regression,Statistics as Topic,Validity},
  language = {eng},
  note = {\url{https://doi.org/10.1136/bmj.311.7003.485}},
  number = {7003},
  pmcid = {PMC2550545},
  pmid = {7647644}
}

@article{amrheinEarthFlat052017,
  title = {The Earth Is Flat (p {$>$} 0.05): Significance Thresholds and the Crisis of Unreplicable Research},
  shorttitle = {The Earth Is Flat (p {$>$} 0.05)},
  author = {Amrhein, Valentin and {Korner-Nievergelt}, Fr{\"a}nzi and Roth, Tobias},
  year = {2017},
  month = jul,
  volume = {5},
  pages = {e3544},
  publisher = {{PeerJ Inc.}},
  issn = {2167-8359},
  doi = {10/gc5stm},
  abstract = {The widespread use of `statistical significance' as a license for making a claim of a scientific finding leads to considerable distortion of the scientific process (according to the American Statistical Association). We review why degrading p-values into `significant' and `nonsignificant' contributes to making studies irreproducible, or to making them seem irreproducible. A major problem is that we tend to take small p-values at face value, but mistrust results with larger p-values. In either case, p-values tell little about reliability of research, because they are hardly replicable even if an alternative hypothesis is true. Also significance (p {$\leq$} 0.05) is hardly replicable: at a good statistical power of 80\%, two studies will be `conflicting', meaning that one is significant and the other is not, in one third of the cases if there is a true effect. A replication can therefore not be interpreted as having failed only because it is nonsignificant. Many apparent replication failures may thus reflect faulty judgment based on significance thresholds rather than a crisis of unreplicable research. Reliable conclusions on replicability and practical importance of a finding can only be drawn using cumulative evidence from multiple independent studies. However, applying significance thresholds makes cumulative knowledge unreliable. One reason is that with anything but ideal statistical power, significant effect sizes will be biased upwards. Interpreting inflated significant results while ignoring nonsignificant results will thus lead to wrong conclusions. But current incentives to hunt for significance lead to selective reporting and to publication bias against nonsignificant findings. Data dredging, p-hacking, and publication bias should be addressed by removing fixed significance thresholds. Consistent with the recommendations of the late Ronald Fisher, p-values should be interpreted as graded measures of the strength of evidence against the null hypothesis. Also larger p-values offer some evidence against the null hypothesis, and they cannot be interpreted as supporting the null hypothesis, falsely concluding that `there is no effect'. Information on possible true effect sizes that are compatible with the data must be obtained from the point estimate, e.g., from a sample average, and from the interval estimate, such as a confidence interval. We review how confusion about interpretation of larger p-values can be traced back to historical disputes among the founders of modern statistics. We further discuss potential arguments against removing significance thresholds, for example that decision rules should rather be more stringent, that sample sizes could decrease, or that p-values should better be completely abandoned. We conclude that whatever method of statistical inference we use, dichotomous threshold thinking must give way to non-automated informed judgment.},
  file = {/Users/zad/Zotero/storage/NPYGF97G/Amrhein et al_2017_The earth is flat (p 0.pdf;/Users/zad/Zotero/storage/3M5FSWKS/3544.html},
  journal = {PeerJ},
  language = {en},
  note = {\url{https://doi.org/10.7717/peerj.3544}}
}

@article{amrheinInferentialStatisticsDescriptive2019,
  title = {Inferential Statistics as Descriptive Statistics: {{There}} Is No Replication Crisis If We Don't Expect Replication},
  shorttitle = {Inferential {{Statistics}} as {{Descriptive Statistics}}},
  author = {Amrhein, Valentin and Trafimow, David and Greenland, Sander},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {262--270},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1543137},
  abstract = {Statistical inference often fails to replicate. One reason is that many results may be selected for drawing inference because some threshold of a statistic like the P-value was crossed, leading to biased reported effect sizes. Nonetheless, considerable non-replication is to be expected even without selective reporting, and generalizations from single studies are rarely if ever warranted. Honestly reported results must vary from replication to replication because of varying assumption violations and random variation; excessive agreement itself would suggest deeper problems, such as failure to publish results in conflict with group expectations or desires. A general perception of a ``replication crisis'' may thus reflect failure to recognize that statistical tests not only test hypotheses, but countless assumptions and the entire environment in which research takes place. Because of all the uncertain and unknown assumptions that underpin statistical inferences, we should treat inferential statistics as highly unstable local descriptions of relations between assumptions and data, rather than as providing generalizable inferences about hypotheses or models. And that means we should treat statistical results as being much more incomplete and uncertain than is currently the norm. Acknowledging this uncertainty could help reduce the allure of selective reporting: Since a small P-value could be large in a replication study, and a large P-value could be small, there is simply no need to selectively report studies based on statistical results. Rather than focusing our study reports on uncertain conclusions, we should thus focus on describing accurately how the study was conducted, what problems occurred, what data were obtained, what analysis methods were used and why, and what output those methods produced.},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/Amrhein et al_2019_Inferential Statistics as Descriptive Statistics.pdf},
  journal = {The American Statistician},
  keywords = {Auxiliary hypotheses,Confidence interval,Hypothesis test,P-value,Posterior probability,Replication,Selective reporting,Significance test,Statistical model,Unreplicable research},
  note = {\url{https://doi.org/10.1080/00031305.2018.1543137}},
  number = {sup1}
}

@article{amrheinScientistsRiseStatistical2019,
  title = {Scientists Rise up against Statistical Significance},
  author = {Amrhein, Valentin and Greenland, Sander and McShane, Blake},
  year = {2019},
  month = mar,
  volume = {567},
  pages = {305},
  doi = {10.1038/d41586-019-00857-9},
  abstract = {Valentin Amrhein, Sander Greenland, Blake McShane and more than 800 signatories call for an end to hyped claims and the dismissal of possibly crucial effects.},
  copyright = {2019 Nature},
  file = {/Users/zad/Google Drive/Research/Zotero/Nature/2019/Amrhein et al_2019_Scientists rise up against statistical significance.pdf},
  journal = {Nature},
  language = {EN},
  note = {\url{https://doi.org/10.1038/d41586-019-00857-9}},
  number = {7748}
}

@misc{aschwNotEvenScientists2015,
  title = {Not {{Even Scientists Can Easily Explain P}}-Values},
  author = {Aschw, Christie and {en}},
  year = {2015},
  month = nov,
  abstract = {P-values have taken quite a beating lately. These widely used and commonly misapplied statistics have been blamed for giving a veneer of legitimacy to dodgy stu\ldots},
  howpublished = {\url{https://fivethirtyeight.com/features/not-even-scientists-can-easily-explain-p-values/}},
  journal = {FiveThirtyEight},
  language = {en-US}
}

@article{bauchnerReportingInterpretationRandomized2019,
  title = {Reporting and {{Interpretation}} of {{Randomized Clinical Trials}}},
  author = {Bauchner, Howard and Golub, Robert M. and Fontanarosa, Phil B.},
  year = {2019},
  month = aug,
  volume = {322},
  pages = {732--735},
  issn = {0098-7484},
  doi = {10.1001/jama.2019.12056},
  abstract = {High-quality randomized clinical trials (RCTs) occupy the highest position on the evidence pyramid, either as stand-alone studies or as part of meta-analyses. H},
  file = {/Users/zad/Zotero/storage/33ZVJ98Y/Bauchner et al. - 2019 - Reporting and Interpretation of Randomized Clinica.pdf},
  journal = {Journal of the American Medical Association},
  language = {en},
  note = {\url{https://doi.org/10.1001/jama.2019.12056}},
  number = {8}
}

@article{bayarriQuantifyingSurpriseData1999,
  title = {Quantifying {{Surprise}} in the {{Data}} and {{Model Verification}}},
  author = {Bayarri, Maria J. and Berger, James O.},
  year = {1999},
  volume = {6},
  pages = {53--82},
  file = {/Users/zad/Zotero/storage/JUEG89AI/e0795969e605e80c62c4120000766280bcd9ab83.html},
  journal = {Bayesian Statistics},
  keywords = {⛔ No DOI found},
  language = {en},
  note = {\url{https://www.semanticscholar.org/paper/Quantifying-Surprise-in-the-Data-and-Model-Bayarri-Berger/e0795969e605e80c62c4120000766280bcd9ab83}}
}

@article{bayarriValuesCompositeNull2000,
  title = {P {{Values}} for {{Composite Null Models}}},
  author = {Bayarri, M. J. and Berger, James O.},
  year = {2000},
  volume = {95},
  pages = {1127--1142},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {01621459},
  doi = {10/dpvq8c},
  abstract = {[The problem of investigating compatibility of an assumed model with the data is investigated in the situation when the assumed model has unknown parameters. The most frequently used measures of compatibility are p values, based on statistics T for which large values are deemed to indicate incompatibility of the data and the model. When the null model has unknown parameters, p values are not uniquely defined. The proposals for computing a p value in such a situation include the plug-in and similar p values on the frequentist side, and the predictive and posterior predictive p values on the Bayesian side. We propose two alternatives, the conditional predictive p value and the partial posterior predictive p value, and indicate their advantages from both Bayesian and frequentist perspectives.]},
  journal = {Journal of the American Statistical Association},
  note = {\url{https://doi.org/10.2307/2669749}},
  number = {452}
}

@article{Benjamin2017-fz,
  title = {Redefine Statistical Significance},
  author = {Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, EJ and Berk, Richard and Bollen, Kenneth A and Brembs, Bj{\"o}rn and Brown, Lawrence and Camerer, Colin and Cesarini, David and Chambers, Christopher D and Clyde, Merlise and Cook, Thomas D and De Boeck, Paul and Dienes, Zoltan and Dreber, Anna and Easwaran, Kenny and Efferson, Charles and Fehr, Ernst and Fidler, Fiona and Field, Andy P and Forster, Malcolm and George, Edward I and Gonzalez, Richard and Goodman, Steven and Green, Edwin and Green, Donald P and Greenwald, Anthony G and Hadfield, Jarrod D and Hedges, Larry V and Held, Leonhard and Ho, Teck Hua and Hoijtink, Herbert and Hruschka, Daniel J and Imai, Kosuke and Imbens, Guido and Ioannidis, John P A and Jeon, Minjeong and Jones, James Holland and Kirchler, Michael and Laibson, David and List, John and Little, Roderick and Lupia, Arthur and Machery, Edouard and Maxwell, Scott E and McCarthy, Michael and Moore, Don A and Morgan, Stephen L and Munaf{\'o}, Marcus and Nakagawa, Shinichi and Nyhan, Brendan and Parker, Timothy H and Pericchi, Luis and Perugini, Marco and Rouder, Jeff and Rousseau, Judith and Savalei, Victoria and Sch{\"o}nbrodt, Felix D and Sellke, Thomas and Sinclair, Betsy and Tingley, Dustin and Van Zandt, Trisha and Vazire, Simine and Watts, Duncan J and Winship, Christopher and Wolpert, Robert L and Xie, Yu and Young, Cristobal and Zinman, Jonathan and Johnson, Valen E},
  year = {2017},
  month = sep,
  volume = {2},
  pages = {6--10},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374, 2397-3374},
  doi = {10.1038/s41562-017-0189-z},
  abstract = {We propose to change the default P-value threshold for statistical significance from 0.05 to 0.005 for claims of new discoveries.},
  file = {/Users/zad/Google Drive/Research/Zotero/Nature Human Behaviour/2017/Benjamin et al_2017_Redefine statistical significance.pdf},
  journal = {Nature Human Behaviour},
  language = {English},
  note = {\url{https://doi.org/10.1038/s41562-017-0189-z}},
  number = {1}
}

@article{birnbaumUnifiedTheoryEstimation1961,
  title = {A Unified Theory of Estimation, {{I}}},
  author = {Birnbaum, Allan},
  year = {1961},
  volume = {32},
  pages = {112--135},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177705145},
  abstract = {This paper extends and unifies some previous formulations and theories of estimation for one-parameter problems. The basic criterion used is admissibility of a point estimator, defined with reference to its full distribution rather than special loss functions such as squared error. Theoretical methods of characterizing admissible estimators are given, and practical computational methods for their use are illustrated. Point, confidence limit, and confidence interval estimation are included in a single theoretical formulation, and incorporated into estimators of an "omnibus" form called "confidence curves." The usefulness of the latter for some applications as well as theoretical purposes is illustrated. Fisher's maximum likelihood principle of estimation is generalized, given exact (non-asymptotic) justification, and unified with the theory of tests and confidence regions of Neyman and Pearson. Relations between exact and asymptotic results are discussed. Further developments, including multiparameter and nuisance parameter problems, problems of choice among admissible estimators, formal and informal criteria for optimality, and related problems in the foundations of statistical inference, will be presented subsequently.},
  file = {/Users/zad/Google Drive/Research/Zotero/The Annals of Mathematical Statistics/1961/Birnbaum_1961_A unified theory of estimation, I.pdf},
  journal = {The Annals of Mathematical Statistics},
  note = {\url{https://doi.org/10.1214/aoms/1177705145}},
  number = {1}
}

@misc{blackEpisheetRothmanEpisheet2019,
  title = {Episheet: {{Rothman}}'s {{Episheet}}},
  author = {Black, James and Rothman, Kenneth and Thelwall, Simon},
  year = {2019},
  month = jan,
  abstract = {A collection of R functions supporting the text book Modern Epidemiology, Second Edition, by Kenneth J.Rothman and Sander Greenland. ISBN 13: 978-0781755641 See {$<$}http://www.krothman.org/{$>$} for more information.},
  howpublished = {CRAN},
  note = {\url{https://cran.r-project.org/package=episheet}}
}

@article{blandMeasuringAgreementMethod1999,
  title = {Measuring Agreement in Method Comparison Studies},
  author = {Bland, J. M. and Altman, D. G.},
  year = {1999},
  month = jun,
  volume = {8},
  pages = {135--160},
  issn = {0962-2802},
  doi = {10.1177/096228029900800204},
  abstract = {Agreement between two methods of clinical measurement can be quantified using the differences between observations made using the two methods on the same subjects. The 95\% limits of agreement, estimated by mean difference +/- 1.96 standard deviation of the differences, provide an interval within which 95\% of differences between measurements by the two methods are expected to lie. We describe how graphical methods can be used to investigate the assumptions of the method and we also give confidence intervals. We extend the basic approach to data where there is a relationship between difference and magnitude, both with a simple logarithmic transformation approach and a new, more general, regression approach. We discuss the importance of the repeatability of each method separately and compare an estimate of this to the limits of agreement. We extend the limits of agreement approach to data with repeated measurements, proposing new estimates for equal numbers of replicates by each method on each subject, for unequal numbers of replicates, and for replicated data collected in pairs, where the underlying value of the quantity being measured is changing. Finally, we describe a nonparametric approach to comparing methods.},
  file = {/Users/zad/Google Drive/Research/Zotero/Statistical Methods in Medical Research/1999/Bland_Altman_1999_Measuring agreement in method comparison studies.pdf},
  journal = {Statistical Methods in Medical Research},
  keywords = {Clinical Laboratory Techniques,Confidence Intervals,Humans,Linear Models,Medical Laboratory Science,Reproducibility of Results,Statistics; Nonparametric},
  language = {eng},
  note = {\url{https://doi.org/10.1177/096228029900800204}},
  number = {2},
  pmid = {10501650}
}

@article{blumbergCausalInferenceStatistics2016,
  title = {Causal {{Inference}} for {{Statistics}}, {{Social}}, and {{Biomedical Sciences}}: {{An Introduction}}: {{Book Reviews}}},
  shorttitle = {Causal {{Inference}} for {{Statistics}}, {{Social}}, and {{Biomedical Sciences}}},
  author = {Blumberg, Carol Joyce},
  year = {2016},
  month = apr,
  volume = {84},
  pages = {159--159},
  issn = {03067734},
  doi = {10.1111/insr.12170},
  file = {/Users/zad/Zotero/storage/MVZ2ITH5/Blumberg - 2016 - Causal Inference for Statistics, Social, and Biome.pdf},
  journal = {International Statistical Review},
  language = {en},
  note = {\url{http://doi.wiley.com/10.1111/insr.12170}},
  number = {1}
}

@article{boringMathematicalVsScientific1919,
  title = {Mathematical vs. Scientific Significance},
  author = {Boring, Edwin G.},
  year = {1919},
  volume = {16},
  pages = {335--338},
  issn = {1939-1455(Electronic),0033-2909(Print)},
  doi = {10.1037/h0074554},
  abstract = {Differentiates between mathematical and scientific methods. The differences between scientific intuition and mathematical results have been attributed to the fact that scientific generalization is broader than mathematical description. While scientific methods deal with samples which are representative of the total whole, the mathematical methods measure the differences between the particular samples observed. Science begins with description but ends in generalization. Mathematical measures are too high and may need to be discounted in arriving at a scientific conclusion. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/zad/Google Drive/Research/Zotero/Psychological Bulletin/1919/Boring_1919_Mathematical vs.pdf},
  journal = {Psychological Bulletin},
  keywords = {Experimental Methods,Intuition,Mathematics,Sciences},
  note = {\url{https://doi.org/10.1037/h0074554}},
  number = {10}
}

@article{bowleyDiscussionDrNeyman1934,
  title = {Discussion on {{Dr}}. {{Neyman}}'s {{Paper}}. {{P}}. 607\textendash 610 in: {{Neyman J}}. {{On}} the Two Different Aspects of the Representative Method: {{The}} Method of Stratified Sampling and the Method of Purposive Selection (with Discussion)},
  author = {Bowley, Arthur L.},
  year = {1934},
  volume = {4},
  pages = {558--625},
  doi = {10.2307/2342192},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of the Royal Statistical Society/1934/Bowley_1934_Discussion on Dr.pdf},
  journal = {Journal of the Royal Statistical Society},
  note = {\url{https://doi.org/10.2307/2342192}},
  number = {97}
}

@article{boxSamplingBayesInference1980,
  title = {Sampling and {{Bayes}}' Inference in Scientific Modelling and Robustness},
  author = {Box, George E. P.},
  year = {1980},
  volume = {143},
  pages = {383--430},
  issn = {0035-9238},
  doi = {10.2307/2982063},
  abstract = {Scientific learning is an iterative process employing Criticism and Estimation. Correspondingly the formulated model factors into two complementary parts--a predictive part allowing model criticism, and a Bayes posterior part allowing estimation. Implications for significance tests, the theory of precise measurement and for ridge estimates are considered. Predictive checking functions for transformation, serial correlation, bad values, and their relation with Bayesian options are considered. Robustness is seen from a Bayesian viewpoint and examples are given. For the bad value problem a comparison with M estimators is made.},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of the Royal Statistical Society. Series A (General)/1980/Box_1980_Sampling and Bayes' inference in scientific modelling and robustness.pdf},
  journal = {Journal of the Royal Statistical Society. Series A (General)},
  note = {\url{https://doi.org/10.2307/2982063}},
  number = {4}
}

@article{brownAssociationAntenatalExposure2017,
  title = {The Association between Antenatal Exposure to Selective Serotonin Reuptake Inhibitors and Autism: {{A}} Systematic Review and Meta-Analysis},
  shorttitle = {The Association between Antenatal Exposure to Selective Serotonin Reuptake Inhibitors and Autism: {{A}} Systematic Review and Meta-Analysis},
  author = {Brown, Hilary K. and {Hussain-Shamsy}, Neesha and Lunsky, Yona and Dennis, Cindy-Lee E. and Vigod, Simone N.},
  year = {2017},
  month = jan,
  volume = {78},
  pages = {e48-e58},
  issn = {1555-2101},
  doi = {10.4088/JCP.15r10194},
  abstract = {OBJECTIVE: This systematic review and meta-analysis examines the relationship between antenatal selective serotonin reuptake inhibitor (SSRI) exposure and child autism, with specific attention to maternal mental illness (MMI) as a potential confounding factor. DATA SOURCES: We searched MEDLINE, Embase, PsycINFO, and CINAHL from database inception to January 28, 2016. STUDY SELECTION: Keywords included terms for SSRIs, pregnancy, and autism. We included published, peer-reviewed articles written in English. DATA EXTRACTION: Two reviewers used standardized instruments for data extraction and quality assessment. We generated pooled estimates for studies of the same design for SSRI exposure at any time during pregnancy and exposure during the first trimester. Subanalyses were conducted among studies with analyses (1) adjusted for MMI and (2) restricted to MMI. RESULTS: We included in the meta-analysis 4 case-control studies and 2 cohort studies. In the case-control studies, the adjusted pooled odds ratio (aPOR) values were 1.4 (95\% CI, 1.0-2.0) (any) and 1.7 (95\% CI, 1.1-2.6) (first trimester). In MMI-adjusted analyses, only first trimester exposure remained statistically significant (aPOR = 1.8; 95\% CI, 1.1-3.1). In MMI-restricted analyses, neither exposure period was statistically significant. In the cohort studies, MMI-adjusted relative risk values were 1.5 (95\% CI, 0.9-2.7) (any) and 1.4 (95\% CI, 1.0-1.9) (first trimester). In MMI-restricted analyses, SSRI exposure at any time during pregnancy was nonsignificant. CONCLUSIONS: It remains unclear whether the association between first trimester SSRI exposure and child autism that was present in the case-control studies even after adjustment for MMI is a true association or a product of residual confounding. Future studies require robust measurement of MMI prior to and during pregnancy.},
  journal = {The Journal of Clinical Psychiatry},
  keywords = {Autism Spectrum Disorder,Case-Control Studies,Child,Child; Preschool,Cohort Studies,Depressive Disorder,Female,Humans,Infant,Infant; Newborn,Observational Studies as Topic,Odds Ratio,Pregnancy,Pregnancy Complications,Pregnancy Trimester; First,Prenatal Exposure Delayed Effects,Serotonin Uptake Inhibitors},
  language = {eng},
  note = {\url{https://doi.org/10.4088/JCP.15r10194}},
  number = {1},
  pmid = {28129495}
}

@article{brownAssociationSerotonergicAntidepressant2017,
  title = {Association between Serotonergic Antidepressant Use during Pregnancy and Autism Spectrum Disorder in Children},
  author = {Brown, Hilary K. and Ray, Joel G. and Wilton, Andrew S. and Lunsky, Yona and Gomes, Tara and Vigod, Simone N.},
  year = {2017},
  month = apr,
  volume = {317},
  pages = {1544--1552},
  issn = {0098-7484},
  doi = {10.1001/jama.2017.3415},
  file = {/Users/zad/Google Drive/Research/Zotero/JAMA/2017/Brown et al_2017_Association Between Serotonergic Antidepressant Use During Pregnancy and Autism.pdf},
  journal = {Journal of the American Medical Association},
  language = {en},
  note = {\url{https://doi.org/10.1001/jama.2017.3415}},
  number = {15}
}

@article{burknerBrmsPackageBayesian2017,
  ids = {burknerBrmsPackageBayesian2017a},
  title = {Brms: {{An R Package}} for {{Bayesian Multilevel Models Using Stan}}},
  shorttitle = {Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  month = aug,
  volume = {80},
  pages = {1--28},
  issn = {1548-7660},
  doi = {10.18637/jss.v080.i01},
  copyright = {Copyright (c) 2017 Paul-Christian B\"urkner},
  encoding = {UTF-8},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of Statistical Software/2017/Bürkner_2017_brms.pdf;/Users/zad/Zotero/storage/RLVFVEIM/Bürkner_2017_brms.pdf},
  journal = {Journal of Statistical Software},
  keywords = {Bayesian inference,MCMC,multilevel model,ordinal data,R,Stan},
  language = {en},
  note = {\url{https://www.jstatsoft.org/index.php/jss/article/view/v080i01}},
  number = {1}
}

@book{burnhamModelSelectionMultimodel2002,
  title = {Model {{Selection}} and {{Multimodel Inference}}: {{A Practical Information}}-{{Theoretic Approach}}},
  shorttitle = {Model {{Selection}} and {{Multimodel Inference}}},
  author = {Burnham, Kenneth P. and Anderson, David R.},
  year = {2002},
  edition = {Second},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  abstract = {We wrote this book to introduce graduate students and research workers in various scienti?c disciplines to the use of information-theoretic approaches in the analysis of empirical data. These methods allow the data-based selection of a ``best'' model and a ranking and weighting of the remaining models in a pre-de?ned set. Traditional statistical inference can then be based on this selected best model. However, we now emphasize that information-theoretic approaches allow formal inference to be based on more than one model (m- timodel inference). Such procedures lead to more robust inferences in many cases, and we advocate these approaches throughout the book. The second edition was prepared with three goals in mind. First, we have tried to improve the presentation of the material. Boxes now highlight ess- tial expressions and points. Some reorganization has been done to improve the ?ow of concepts, and a new chapter has been added. Chapters 2 and 4 have been streamlined in view of the detailed theory provided in Chapter 7. S- ond, concepts related to making formal inferences from more than one model (multimodel inference) have been emphasized throughout the book, but p- ticularly in Chapters 4, 5, and 6. Third, new technical material has been added to Chapters 5 and 6. Well over 100 new references to the technical literature are given. These changes result primarily from our experiences while giving several seminars, workshops, and graduate courses on material in the ?rst e- tion.},
  file = {/Users/zad/Google Drive/Research/Zotero/Springer-Verlag/2002/Burnham_Anderson_2002_Model Selection and Multimodel Inference.pdf},
  isbn = {978-0-387-95364-9},
  language = {en},
  note = {\url{https://doi.org/10.1007/b97636}}
}

@article{buurenMiceMultivariateImputation2011,
  title = {Mice: {{Multivariate Imputation}} by {{Chained Equations}} in {{R}}},
  shorttitle = {Mice},
  author = {van Buuren, Stef and {Groothuis-Oudshoorn}, Karin},
  year = {2011},
  month = dec,
  volume = {45},
  pages = {1--67},
  issn = {1548-7660},
  doi = {10.18637/jss.v045.i03},
  copyright = {Copyright (c) 2009 Stef van Buuren, Karin Groothuis-Oudshoorn},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of Statistical Software/2011/Buuren_Groothuis-Oudshoorn_2011_mice.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  note = {\url{https://www.jstatsoft.org/index.php/jss/article/view/v045i03}},
  number = {1}
}

@article{callawayRaceCoronavirusVaccines2020,
  title = {The Race for Coronavirus Vaccines: A Graphical Guide},
  shorttitle = {The Race for Coronavirus Vaccines},
  author = {Callaway, Ewen},
  year = {2020},
  month = apr,
  volume = {580},
  pages = {576--577},
  publisher = {{Nature Publishing Group}},
  doi = {10.1038/d41586-020-01221-y},
  abstract = {Eight ways in which scientists hope to provide immunity to SARS-CoV-2 .},
  copyright = {2020 Nature},
  file = {/Users/zad/Zotero/storage/E6U5KHMQ/Callaway_2020_The race for coronavirus vaccines.pdf;/Users/zad/Zotero/storage/K9Y597CL/d41586-020-01221-y.html},
  journal = {Nature},
  language = {en},
  note = {\url{https://www.nature.com/articles/d41586-020-01221-y}},
  number = {7805}
}

@article{Camerer2016-yf,
  title = {Evaluating Replicability of Laboratory Experiments in Economics},
  author = {Camerer, Colin F and Dreber, Anna and Forsell, Eskil and Ho, Teck-Hua and Huber, J{\"u}rgen and Johannesson, Magnus and Kirchler, Michael and Almenberg, Johan and Altmejd, Adam and Chan, Taizan and Heikensten, Emma and Holzmeister, Felix and Imai, Taisuke and Isaksson, Siri and Nave, Gideon and Pfeiffer, Thomas and Razen, Michael and Wu, Hang},
  year = {2016},
  month = mar,
  volume = {351},
  pages = {1433--1436},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaf0918},
  abstract = {The replicability of some scientific findings has recently been called into question. To contribute data about replicability in economics, we replicated 18 studies published in the American Economic Review and the Quarterly Journal of Economics between 2011 and 2014. All of these replications followed predefined analysis plans that were made publicly available beforehand, and they all have a statistical power of at least 90\% to detect the original effect size at the 5\% significance level. We found a significant effect in the same direction as in the original study for 11 replications (61\%); on average, the replicated effect size is 66\% of the original. The replicability rate varies between 67\% and 78\% for four additional replicability indicators, including a prediction market measure of peer beliefs.},
  affiliation = {Division of Humanities and Social Sciences, California Institute of Technology, 1200 East California Boulevard, MC 228-77, Pasadena, CA 91125, USA. Department of Economics, Stockholm School of Economics, Box 6501, SE-113 83 Stockholm, Sweden. Haas School of Business, University of California-Berkeley, Berkeley, CA 94720-1900, USA. NUS Business School, National University of Singapore, Singapore 119245. Department of Banking and Finance, University of Innsbruck, Universit\"atsstrasse 15, 6020 Innsbruck, Austria. Department of Banking and Finance, University of Innsbruck, Universit\"atsstrasse 15, 6020 Innsbruck, Austria. Centre for Finance, Department of Economics, University of G\"oteborg, SE-40530 G\"oteborg, Sweden. Sveriges Riksbank, SE-103 37 Stockholm, Sweden. Office of the Deputy President (Research and Technology), National University of Singapore, Singapore 119077. New Zealand Institute for Advanced Study, Private Bag 102904, North Shore Mail Centre, Auckland 0745, New Zealand. Wissenschaftskolleg zu Berlin, Institute for Advanced Study, D-14193 Berlin, Germany. NUS Business School, National University of Singapore, Singapore 119245.},
  file = {/Users/zad/Google Drive/Research/Zotero/Science/2016/Camerer et al_2016_Evaluating replicability of laboratory experiments in economics.pdf},
  journal = {Science},
  language = {English},
  note = {\url{https://doi.org/10.1126/science.aaf0918}},
  number = {6280},
  pmid = {26940865}
}

@misc{cantyBootBootstrapSPlus2019,
  title = {Boot: {{Bootstrap R}} ({{S}}-{{Plus}}) {{Functions}}},
  author = {Canty, Angelo and Ripley, Brian},
  year = {2019},
  howpublished = {\url{https://cran.r-project.org/package=boot}}
}

@article{carpenterStanProbabilisticProgramming2017,
  ids = {carpenter2017jssa},
  title = {Stan: {{A Probabilistic Programming Language}}},
  shorttitle = {Stan},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  month = jan,
  volume = {76},
  pages = {1--32},
  issn = {1548-7660},
  doi = {10.18637/jss.v076.i01},
  copyright = {Copyright (c) 2017 Bob Carpenter, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, Allen Riddell},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of Statistical Software/2017/Carpenter et al_2017_Stan.pdf;/Users/zad/Google Drive/Research/Zotero/Journal of Statistical Software/2017/Carpenter et al_2017_Stan2.pdf;/Users/zad/Zotero/storage/2QD9DA2T/Carpenter et al. - 2017 - Stan A Probabilistic Programming Language.pdf},
  journal = {Journal of Statistical Software},
  keywords = {algorithmic differentiation,Bayesian inference,probabilistic programming,Stan},
  language = {en},
  note = {\url{https://www.jstatsoft.org/index.php/jss/article/view/v076i01}},
  number = {1}
}

@article{cassidyFailingGrade892019,
  title = {Failing Grade: 89\% of Introduction-to-Psychology Textbooks That Define or Explain Statistical Significance Do so Incorrectly},
  author = {Cassidy, Scott A. and Dimova, Ralitza and Gigu{\`e}re, Benjamin and Spence, Jeffrey R. and Stanley, David J.},
  year = {2019},
  month = jun,
  volume = {2},
  pages = {233--239},
  issn = {2515-2459},
  doi = {10.1177/2515245919858072},
  abstract = {Null-hypothesis significance testing (NHST) is commonly used in psychology; however, it is widely acknowledged that NHST is not well understood by either psychology professors or psychology students. In the current study, we investigated whether introduction-to-psychology textbooks accurately define and explain statistical significance. We examined 30 introductory-psychology textbooks, including the best-selling books from the United States and Canada, and found that 89\% incorrectly defined or explained statistical significance. Incorrect definitions and explanations were most often consistent with the odds-against-chance fallacy. These results suggest that it is common for introduction-to-psychology students to be taught incorrect interpretations of statistical significance. We hope that our results will create awareness among authors of introductory-psychology books and provide the impetus for corrective action. To help with classroom instruction, we provide slides that correctly describe NHST and may be useful for introductory-psychology instructors.},
  file = {/Users/zad/Google Drive/Research/Zotero/Advances in Methods and Practices in Psychological Science/2019/Cassidy et al_2019_Failing Grade.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  note = {\url{https://doi.org/10.1177/2515245919858072}}
}

@misc{choiProfileLikelihoodProfileLikelihood2011,
  title = {{{ProfileLikelihood}}: {{Profile}} Likelihood for a Parameter in Commonly Used Statistical Models},
  author = {Choi, Leena},
  year = {2011},
  howpublished = {\url{https://CRAN.R-project.org/package=ProfileLikelihood}}
}

@article{coleMaximumLikelihoodProfile2013,
  title = {Maximum {{Likelihood}}, {{Profile Likelihood}}, and {{Penalized Likelihood}}: {{A Primer}}},
  author = {Cole, Stephen R. and Chu, Haitao and Greenland, Sander},
  year = {2013},
  month = oct,
  volume = {179},
  pages = {252--260},
  issn = {0002-9262},
  doi = {10/f5mx4q},
  abstract = {The method of maximum likelihood is widely used in epidemiology, yet many epidemiologists receive little or no education in the conceptual underpinnings of the approach. Here we provide a primer on maximum likelihood and some important extensions which have proven useful in epidemiologic research, and which reveal connections between maximum likelihood and Bayesian methods. For a given data set and probability model, maximum likelihood finds values of the model parameters that give the observed data the highest probability. As with all inferential statistical methods, maximum likelihood is based on an assumed model and cannot account for bias sources that are not controlled by the model or the study design. Maximum likelihood is nonetheless popular, because it is computationally straightforward and intuitive and because maximum likelihood estimators have desirable large-sample properties in the (largely fictitious) case in which the model has been correctly specified. Here, we work through an example to illustrate the mechanics of maximum likelihood estimation and indicate how improvements can be made easily with commercial software. We then describe recent extensions and generalizations which are better suited to observational health research and which should arguably replace standard maximum likelihood as the default method.},
  file = {/Users/zad/Zotero/storage/7RLX7A4S/Cole et al_2013_Maximum Likelihood, Profile Likelihood, and Penalized Likelihood.pdf},
  journal = {American Journal of Epidemiology},
  note = {\url{https://doi.org/10.1093/aje/kwt245}},
  number = {2}
}

@article{coleSurprise2020,
  title = {Surprise!},
  author = {Cole, Stephen R. and Edwards, Jessie K. and Greenland, Sander},
  year = {2020},
  month = jul,
  doi = {10/gg63md},
  abstract = {Abstract.  Measures of information and surprise, such as the Shannon information (the \$S\$ value), quantify the signal present in a stream of noisy data. We illu},
  file = {/Users/zad/Zotero/storage/5LHZ35L5/5869593.html},
  journal = {American Journal of Epidemiology},
  language = {en},
  note = {\url{https://doi.org/10.1093/aje/kwaa136}}
}

@article{colquhounFalsePositiveRisk2019,
  ids = {colquhounFalsePositiveRisk2019a},
  title = {The {{False Positive Risk}}: {{A Proposal Concerning What}} to {{Do About}} p-{{Values}}},
  shorttitle = {The {{False Positive Risk}}},
  author = {Colquhoun, David},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {192--201},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1529622},
  abstract = {It is widely acknowledged that the biomedical literature suffers from a surfeit of false positive results. Part of the reason for this is the persistence of the myth that observation of p\,{$<$}\,0.05 is sufficient justification to claim that you have made a discovery. It is hopeless to expect users to change their reliance on p-values unless they are offered an alternative way of judging the reliability of their conclusions. If the alternative method is to have a chance of being adopted widely, it will have to be easy to understand and to calculate. One such proposal is based on calculation of false positive risk(FPR). It is suggested that p-values and confidence intervals should continue to be given, but that they should be supplemented by a single additional number that conveys the strength of the evidence better than the p-value. This number could be the minimum FPR (that calculated on the assumption of a prior probability of 0.5, the largest value that can be assumed in the absence of hard prior data). Alternatively one could specify the prior probability that it would be necessary to believe in order to achieve an FPR of, say, 0.05.},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/Colquhoun_2019_The False Positive Risk.pdf;/Users/zad/Zotero/storage/E382KKKG/Colquhoun_2019_The False Positive Risk.pdf;/Users/zad/Zotero/storage/NG68F3B9/00031305.2018.html},
  journal = {The American Statistician},
  keywords = {Bayes,False positive,False positive report probability,False positive risk,FPR,Likelihood ratio,Point null,Positive predictive value},
  note = {\url{http://amstat.tandfonline.com/doi/full/10.1080/00031305.2018.1529622}},
  number = {sup1}
}

@book{cooperHandbookResearchSynthesis2009,
  title = {The Handbook of Research Synthesis and Meta-Analysis},
  editor = {Cooper, Harris M. and Hedges, Larry V. and Valentine, Jeff C.},
  year = {2009},
  edition = {2nd ed},
  publisher = {{Russell Sage Foundation}},
  address = {{New York}},
  annotation = {OCLC: ocn264670503},
  file = {/Users/zad/Zotero/storage/FZ5HEU4W/Cooper et al. - 2009 - The handbook of research synthesis and meta-analys.pdf},
  isbn = {978-0-87154-163-5},
  keywords = {Handbooks; manuals; etc,Information storage and retrieval systems,Methodology,Research,Statistical methods},
  language = {en},
  lccn = {Q180.55.M4 H35 2009}
}

@article{cousinsJeffreysLindleyParadox2017,
  title = {The {{Jeffreys}}\textendash{{Lindley}} Paradox and Discovery Criteria in High Energy Physics},
  author = {Cousins, Robert D.},
  year = {2017},
  month = feb,
  volume = {194},
  pages = {395--432},
  issn = {1573-0964},
  doi = {10.1007/s11229-014-0525-z},
  abstract = {The Jeffreys\textendash Lindley paradox displays how the use of a p{$\mathsl{p}$}p value (or number of standard deviations zz) in a frequentist hypothesis test can lead to an inference that is radically different from that of a Bayesian hypothesis test in the form advocated by Harold Jeffreys in the 1930s and common today. The setting is the test of a well-specified null hypothesis (such as the Standard Model of elementary particle physics, possibly with ``nuisance parameters'') versus a composite alternative (such as the Standard Model plus a new force of nature of unknown strength). The pp value, as well as the ratio of the likelihood under the null hypothesis to the maximized likelihood under the alternative, can strongly disfavor the null hypothesis, while the Bayesian posterior probability for the null hypothesis can be arbitrarily large. The academic statistics literature contains many impassioned comments on this paradox, yet there is no consensus either on its relevance to scientific communication or on its correct resolution. The paradox is quite relevant to frontier research in high energy physics. This paper is an attempt to explain the situation to both physicists and statisticians, in the hope that further progress can be made.},
  file = {/Users/zad/Google Drive/Research/Zotero/Synthese/2017/Cousins_2017_The Jeffreys–Lindley paradox and discovery criteria in high energy physics.pdf},
  journal = {Synthese},
  keywords = {Bayesian model selection,High energy physics,Jeffreys–Lindley paradox,Lindley’s paradox,p values},
  language = {en},
  note = {\url{https://doi.org/10.1007/s11229-014-0525-z}},
  number = {2}
}

@incollection{coxChapterAsymptoticTheory1974,
  title = {Chapter 9, {{Asymptotic Theory}}},
  booktitle = {Theoretical {{Statistics}}},
  author = {Cox, D. R. and Hinkley, D. V.},
  year = {1974},
  pages = {279--364},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b14832},
  abstract = {A text that stresses the general concepts of the theory of statistics Theoretical Statistics provides a systematic statement of the theory of statistics,},
  file = {/Users/zad/Zotero/storage/2W43DIFT/Cox_Hinkley_1974_Chapter 9, Asymptotic Theory.pdf},
  isbn = {978-0-429-17021-8},
  language = {en},
  note = {\url{https://doi.org/10.1201/b14832}}
}

@incollection{coxChapterIntervalEstimation1974,
  title = {Chapter 7, {{Interval}} Estimation},
  booktitle = {Theoretical {{Statistics}}},
  author = {Cox, D. R. and Hinkley, D. V.},
  year = {1974},
  pages = {207--249},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b14832},
  abstract = {A text that stresses the general concepts of the theory of statistics Theoretical Statistics provides a systematic statement of the theory of statistics,},
  file = {/Users/zad/Google Drive/Research/Zotero/Chapman and Hall/CRC/1974/Cox_Hinkley_1974_Chapter 7, Interval estimation.pdf},
  isbn = {978-0-429-17021-8},
  language = {en},
  note = {\url{https://doi.org/10.1201/b14832}}
}

@incollection{coxChapterPureSignificance1974,
  title = {Chapter 3, {{Pure}} Significance Tests},
  booktitle = {Theoretical {{Statistics}}},
  author = {Cox, D. R. and Hinkley, D. V.},
  year = {1974},
  pages = {64--87},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b14832},
  abstract = {A text that stresses the general concepts of the theory of statistics Theoretical Statistics provides a systematic statement of the theory of statistics,},
  file = {/Users/zad/Google Drive/Research/Zotero/Chapman and Hall/CRC/1974/Cox_Hinkley_1974_Chapter 3, Pure significance tests.pdf},
  isbn = {978-0-429-17021-8},
  language = {en},
  note = {\url{https://doi.org/10.1201/b14832}}
}

@incollection{coxChapterTechniquesFormal2011,
  title = {Chapter 8, {{Techniques}} of Formal Inference},
  booktitle = {Principles of {{Applied Statistics}}},
  author = {Cox, D. R. and Donnelly, Christl A.},
  year = {2011},
  month = jul,
  pages = {151},
  publisher = {{Cambridge University Press}},
  abstract = {Applied statistics is more than data analysis, but it is easy to lose sight of the big picture. David Cox and Christl Donnelly distil decades of scientific experience into usable principles for the successful application of statistics, showing how good statistical strategy shapes every stage of an investigation. As you advance from research or policy question, to study design, through modelling and interpretation, and finally to meaningful conclusions, this book will be a valuable guide. Over a hundred illustrations from a wide variety of real applications make the conceptual points concrete, illuminating your path and deepening your understanding. This book is essential reading for anyone who makes extensive use of statistical methods in their work.},
  googlebooks = {BMLMGr4kbQYC},
  isbn = {978-1-139-50354-9},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Epidemiology},
  language = {en},
  note = {\url{https://doi.org/10.1017/CBO9781139005036.009}}
}

@article{coxDiscussion2013,
  title = {Discussion},
  author = {Cox, David R.},
  year = {2013},
  volume = {81},
  pages = {40--41},
  issn = {1751-5823},
  doi = {10/gg9s2f},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/insr.12007},
  copyright = {\textcopyright{} 2013 The Author. International Statistical Review \textcopyright{} 2013 International Statistical Institute},
  file = {/Users/zad/Zotero/storage/Z3ERSSYH/insr.html},
  journal = {International Statistical Review},
  language = {en},
  note = {\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/insr.12007}},
  number = {1}
}

@article{coxNotePartiallyBayes1975,
  title = {A Note on Partially {{Bayes}} Inference and the Linear Model},
  author = {Cox, D. R.},
  year = {1975},
  month = dec,
  volume = {62},
  pages = {651--654},
  publisher = {{Oxford Academic}},
  issn = {0006-3444},
  doi = {10.1093/biomet/62.3.651},
  abstract = {AbstractSUMMARY.  Some results are outlined for estimation in a replicated linear model in which the variance changes from cell to cell in accordance with an in},
  file = {/Users/zad/Zotero/storage/SAI5YX4A/Cox_1975_A note on partially Bayes inference and the linear model.pdf;/Users/zad/Zotero/storage/B5CC2JHK/257297.html},
  journal = {Biometrika},
  language = {en},
  note = {\url{https://doi.org/10.1093/biomet/62.3.651}},
  number = {3}
}

@book{coxPrinciplesAppliedStatistics2011,
  title = {Principles of {{Applied Statistics}}},
  author = {Cox, D. R. and Donnelly, Christl A.},
  year = {2011},
  month = jul,
  publisher = {{Cambridge University Press}},
  abstract = {Applied statistics is more than data analysis, but it is easy to lose sight of the big picture. David Cox and Christl Donnelly distil decades of scientific experience into usable principles for the successful application of statistics, showing how good statistical strategy shapes every stage of an investigation. As you advance from research or policy question, to study design, through modelling and interpretation, and finally to meaningful conclusions, this book will be a valuable guide. Over a hundred illustrations from a wide variety of real applications make the conceptual points concrete, illuminating your path and deepening your understanding. This book is essential reading for anyone who makes extensive use of statistical methods in their work.},
  googlebooks = {BMLMGr4kbQYC},
  isbn = {978-1-139-50354-9},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Epidemiology},
  language = {en},
  note = {\url{https://doi.org/10.1017/CBO9781139005036}}
}

@book{coxPrinciplesStatisticalInference2006,
  title = {Principles of {{Statistical Inference}}},
  author = {Cox, D. R.},
  year = {2006},
  month = aug,
  publisher = {{Cambridge University Press}},
  abstract = {In this definitive book, D. R. Cox gives a comprehensive and balanced appraisal of statistical inference. He develops the key concepts, describing and comparing the main ideas and controversies over foundational issues that have been keenly argued for more than two-hundred years. Continuing a sixty-year career of major contributions to statistical thought, no one is better placed to give this much-needed account of the field. An appendix gives a more personal assessment of the merits of different ideas. The content ranges from the traditional to the contemporary. While specific applications are not treated, the book is strongly motivated by applications across the sciences and associated technologies. The mathematics is kept as elementary as feasible, though previous knowledge of statistics is assumed. The book will be valued by every user or student of statistics who is serious about understanding the uncertainty inherent in conclusions from statistical analyses.},
  googlebooks = {EMYWpoVn7vcC},
  isbn = {978-0-521-68567-2},
  keywords = {Business \& Economics / Statistics,Mathematics / Probability \& Statistics / General,Medical / Epidemiology,Social Science / Research},
  language = {en},
  note = {\url{https://doi.org/10.1017/cbo9780511813559}}
}

@book{coxTheoreticalStatistics1974,
  title = {Theoretical {{Statistics}}},
  author = {Cox, D. R. and Hinkley, D. V.},
  year = {1974},
  publisher = {{Chapman and Hall/CRC}},
  doi = {10.1201/b14832},
  abstract = {A text that stresses the general concepts of the theory of statistics Theoretical Statistics provides a systematic statement of the theory of statistics,},
  file = {/Users/zad/Google Drive/Research/Zotero/Chapman and Hall/CRC/1974/Cox_Hinkley_1974_Theoretical Statistics.pdf},
  isbn = {978-0-429-17021-8},
  language = {en},
  note = {\url{https://doi.org/10.1201/b14832}}
}

@book{cummingsAnalysisIncidenceRates2019,
  title = {Analysis of {{Incidence Rates}}},
  author = {Cummings, Peter},
  year = {2019},
  month = apr,
  publisher = {{CRC Press}},
  abstract = {Incidence rates are counts divided by person-time; mortality rates are a well-known example. Analysis of Incidence Rates offers a detailed discussion of the practical aspects of analyzing incidence rates. Important pitfalls and areas of controversy are discussed. The text is aimed at graduate students, researchers, and analysts in the disciplines of epidemiology, biostatistics, social sciences, economics, and psychology.  Features:   Compares and contrasts incidence rates with risks, odds, and hazards.   Shows stratified methods, including standardization, inverse-variance weighting, and Mantel-Haenszel methods   Describes Poisson regression methods for adjusted rate ratios and rate differences.   Examines linear regression for rate differences with an emphasis on common problems.   Gives methods for correcting confidence intervals.   Illustrates problems related to collapsibility.   Explores extensions of count models for rates, including negative binomial regression, methods for clustered data, and the analysis of longitudinal data. Also, reviews controversies and limitations.   Presents matched cohort methods in detail.   Gives marginal methods for converting adjusted rate ratios to rate differences, and vice versa.   Demonstrates instrumental variable methods.   Compares Poisson regression with the Cox proportional hazards model. Also, introduces Royston-Parmar models.   All data and analyses are in online Stata files which readers can download.   Peter Cummings is Professor Emeritus, Department of Epidemiology, School of Public Health, University of Washington, Seattle WA. His research was primarily in the field of injuries. He used matched cohort methods to estimate how the use of seat belts and presence of airbags were related to death in a traffic crash. He is author or co-author of over 100 peer-reviewed articles.},
  file = {/Users/zad/Google Drive/Research/Zotero/CRC Press/2019/Cummings_2019_Analysis of Incidence Rates.pdf},
  googlebooks = {y8ySDwAAQBAJ},
  isbn = {978-0-429-61905-2},
  keywords = {Mathematics / Probability \& Statistics / General,Reference / General},
  language = {en},
  note = {\url{https://doi.org/10.1201/9780429055713}}
}

@incollection{cummingsComparingModelsUsing2019,
  title = {Comparing Models Using {{Akaike}} and {{Bayesian}} Information Criterion},
  booktitle = {Analysis of {{Incidence Rates}}},
  author = {Cummings, Peter},
  year = {2019},
  month = apr,
  pages = {218},
  publisher = {{CRC Press}},
  abstract = {Incidence rates are counts divided by person-time; mortality rates are a well-known example. Analysis of Incidence Rates offers a detailed discussion of the practical aspects of analyzing incidence rates. Important pitfalls and areas of controversy are discussed. The text is aimed at graduate students, researchers, and analysts in the disciplines of epidemiology, biostatistics, social sciences, economics, and psychology.  Features:   Compares and contrasts incidence rates with risks, odds, and hazards.   Shows stratified methods, including standardization, inverse-variance weighting, and Mantel-Haenszel methods   Describes Poisson regression methods for adjusted rate ratios and rate differences.   Examines linear regression for rate differences with an emphasis on common problems.   Gives methods for correcting confidence intervals.   Illustrates problems related to collapsibility.   Explores extensions of count models for rates, including negative binomial regression, methods for clustered data, and the analysis of longitudinal data. Also, reviews controversies and limitations.   Presents matched cohort methods in detail.   Gives marginal methods for converting adjusted rate ratios to rate differences, and vice versa.   Demonstrates instrumental variable methods.   Compares Poisson regression with the Cox proportional hazards model. Also, introduces Royston-Parmar models.   All data and analyses are in online Stata files which readers can download.   Peter Cummings is Professor Emeritus, Department of Epidemiology, School of Public Health, University of Washington, Seattle WA. His research was primarily in the field of injuries. He used matched cohort methods to estimate how the use of seat belts and presence of airbags were related to death in a traffic crash. He is author or co-author of over 100 peer-reviewed articles.},
  googlebooks = {y8ySDwAAQBAJ},
  isbn = {978-0-429-61905-2},
  keywords = {Mathematics / Probability \& Statistics / General,Reference / General},
  language = {en}
}

@incollection{cummingsHeaderInformationTable2019,
  title = {The Header Information above the Table of Estimates},
  booktitle = {Analysis of {{Incidence Rates}}},
  author = {Cummings, Peter},
  year = {2019},
  month = apr,
  pages = {156},
  publisher = {{CRC Press}},
  abstract = {Incidence rates are counts divided by person-time; mortality rates are a well-known example. Analysis of Incidence Rates offers a detailed discussion of the practical aspects of analyzing incidence rates. Important pitfalls and areas of controversy are discussed. The text is aimed at graduate students, researchers, and analysts in the disciplines of epidemiology, biostatistics, social sciences, economics, and psychology.  Features:   Compares and contrasts incidence rates with risks, odds, and hazards.   Shows stratified methods, including standardization, inverse-variance weighting, and Mantel-Haenszel methods   Describes Poisson regression methods for adjusted rate ratios and rate differences.   Examines linear regression for rate differences with an emphasis on common problems.   Gives methods for correcting confidence intervals.   Illustrates problems related to collapsibility.   Explores extensions of count models for rates, including negative binomial regression, methods for clustered data, and the analysis of longitudinal data. Also, reviews controversies and limitations.   Presents matched cohort methods in detail.   Gives marginal methods for converting adjusted rate ratios to rate differences, and vice versa.   Demonstrates instrumental variable methods.   Compares Poisson regression with the Cox proportional hazards model. Also, introduces Royston-Parmar models.   All data and analyses are in online Stata files which readers can download.   Peter Cummings is Professor Emeritus, Department of Epidemiology, School of Public Health, University of Washington, Seattle WA. His research was primarily in the field of injuries. He used matched cohort methods to estimate how the use of seat belts and presence of airbags were related to death in a traffic crash. He is author or co-author of over 100 peer-reviewed articles.},
  googlebooks = {y8ySDwAAQBAJ},
  isbn = {978-0-429-61905-2},
  keywords = {Mathematics / Probability \& Statistics / General,Reference / General},
  language = {en}
}

@article{cummingsReportingStatisticalInformation2003,
  title = {Reporting Statistical Information in Medical Journal Articles},
  author = {Cummings, Peter and Rivara, Frederick P.},
  year = {2003},
  month = apr,
  volume = {157},
  pages = {321},
  issn = {1072-4710},
  doi = {10.1001/archpedi.157.4.321},
  file = {/Users/zad/Google Drive/Research/Zotero/Archives of Pediatrics & Adolescent Medicine/2003/Cummings_Rivara_2003_Reporting Statistical Information in Medical Journal Articles.pdf},
  journal = {Archives of Pediatrics \& Adolescent Medicine},
  language = {en},
  note = {\url{https://doi.org/10.1001/archpedi.157.4.321}},
  number = {4}
}

@book{cummingUnderstandingNewStatistics2012,
  title = {Understanding the {{New Statistics}}: {{Effect Sizes}}, {{Confidence Intervals}}, and {{Meta}}-Analysis},
  shorttitle = {Understanding the {{New Statistics}}},
  author = {Cumming, Geoff},
  year = {2012},
  publisher = {{Routledge}},
  abstract = {This is the first book to introduce the new statistics - effect sizes, confidence intervals, and meta-analysis - in an accessible way. It is chock full of practical examples and tips on how to analyze and report research results using these techniques. The book is invaluable to readers interested in meeting the new APA Publication Manual guidelines by adopting the new statistics - which are more informative than null hypothesis significance testing, and becoming widely used in many disciplines.Accompanying the book is the Exploratory Software for Confidence Intervals (ESCI) package, free software that runs under Excel and is accessible at www.thenewstatistics.com. The book\^ae(tm)s exercises use ESCI's simulations, which are highly visual and interactive, to engage users and encourage exploration. Working with the simulations strengthens understanding of key statistical ideas. There are also many examples, and detailed guidance to show readers how to analyze their own data using the new statistics, and practical strategies for interpreting the results. A particular strength of the book is its explanation of meta-analysis, using simple diagrams and examples. Understanding meta-analysis is increasingly important, even at undergraduate levels, because medicine, psychology and many other disciplines now use meta-analysis to assemble the evidence needed for evidence-based practice.The book\^ae(tm)s pedagogical program, built on cognitive science principles, reinforces learning:Boxes provide "evidence-based" advice on the most effective statistical techniques. Numerous examples reinforce learning, and show that many disciplines are using the new statistics.Graphs are tied in with ESCI to make important concepts vividly clear and memorable.Opening overviews and end of chapter take-home messages summarize key points.Exercises encourage exploration, deep understanding, and practical applications.This highly accessible book is intended as the core text for any course that emphasizes the new statistics, or as a supplementary text for graduate and/or advanced undergraduate courses in statistics and research methods in departments of psychology, education, human development , nursing, and natural, social, and life sciences. Researchers and practitioners interested in understanding the new statistics, and future published research, will also appreciate this book. A basic familiarity with introductory statistics is assumed.},
  file = {/Users/zad/Google Drive/Research/Zotero/Routledge/2012/Cumming_2012_Understanding the New Statistics.pdf},
  googlebooks = {AVBDYgEACAAJ},
  isbn = {978-0-415-87968-2},
  keywords = {Education / Statistics,Psychology / Statistics,Social Science / Statistics},
  language = {en},
  note = {\url{https://doi.org/10.4324/9780203807002}}
}

@book{degrootProbabilityStatistics2012,
  title = {Probability and {{Statistics}}},
  author = {DeGroot, Morris H. and Schervish, Mark J.},
  year = {2012},
  edition = {4th ed},
  publisher = {{Addison-Wesley}},
  address = {{Boston}},
  annotation = {OCLC: ocn502674206},
  file = {/Users/zad/Zotero/storage/S73ZZTM5/DeGroot and Schervish - 2012 - Probability and statistics.pdf},
  isbn = {978-0-321-50046-5},
  keywords = {Mathematical statistics,Probabilities,Textbooks},
  language = {en},
  lccn = {QA273 .D35 2012}
}

@misc{denworthSignificantProblemValues2019,
  title = {The {{Significant Problem}} of {{P Values}}},
  author = {Denworth, Lydia},
  year = {2019},
  month = oct,
  doi = {10.1038/scientificamerican1019-62},
  abstract = {Standard scientific methods are under fire. Will anything change?},
  howpublished = {\url{http://www.scientificamerican.com/article/the-significant-problem-of-p-values/}},
  journal = {Scientific American},
  language = {en}
}

@article{DiscussionMeetingSigns2020,
  title = {Discussion on the Meeting on `{{Signs}} and Sizes:Understanding and Replicating Statistical Findings'},
  year = {2020},
  month = feb,
  volume = {183},
  pages = {449--469},
  publisher = {{John Wiley \& Sons, Ltd}},
  issn = {0964-1998},
  doi = {10/gg4b5g},
  file = {/Users/zad/Zotero/storage/U4LPFFZM/2020_Discussion on the meeting on ‘Signs and sizes.pdf},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  note = {\url{https://doi.org/10.1111/rssa.12544}},
  number = {2}
}

@article{dudbridgeEstimationSignificanceThresholds2008,
  title = {Estimation of Significance Thresholds for Genomewide Association Scans},
  author = {Dudbridge, Frank and Gusnanto, Arief},
  year = {2008},
  month = apr,
  volume = {32},
  pages = {227--234},
  issn = {0741-0395},
  doi = {10.1002/gepi.20297},
  abstract = {The question of what significance threshold is appropriate for genomewide association studies is somewhat unresolved. Previous theoretical suggestions have yet to be validated in practice, whereas permutation testing does not resolve a discrepancy between the genomewide multiplicity of the experiment and the subset of markers actually tested. We used genotypes from the Wellcome Trust Case-Control Consortium to estimate a genomewide significance threshold for the UK Caucasian population. We subsampled the genotypes at increasing densities, using permutation to estimate the nominal P-value for 5\% family-wise error. By extrapolating to infinite density, we estimated the genomewide significance threshold to be about 7.2 \texttimes{} 10-8. To reduce the computation time, we considered Patterson's eigenvalue estimator of the effective number of tests, but found it to be an order of magnitude too low for multiplicity correction. However, by fitting a Beta distribution to the minimum P-value from permutation replicates, we showed that the effective number is a useful heuristic and suggest that its estimation in this context is an open problem. We conclude that permutation is still needed to obtain genomewide significance thresholds, but with subsampling, extrapolation and estimation of an effective number of tests, the threshold can be standardized for all studies of the same population.},
  file = {/Users/zad/Zotero/storage/EHU4KK6Y/Dudbridge_Gusnanto_2008_Estimation of significance thresholds for genomewide association scans.pdf},
  journal = {Genetic Epidemiology},
  note = {\url{https://doi.org/10.1002/gepi.20297}},
  number = {3},
  pmcid = {PMC2573032},
  pmid = {18300295}
}

@book{duhemAimStructurePhysical1991,
  title = {The {{Aim}} and {{Structure}} of {{Physical Theory}}},
  author = {Duhem, Pierre Maurice Marie},
  year = {1991},
  publisher = {{Princeton University Press}},
  googlebooks = {udDaAAAAMAAJ},
  language = {en},
  note = {\url{https://books.google.com/books/about/The_Aim_and_Structure_of_Physical_Theory.html?id=udDaAAAAMAAJ}}
}

@article{efronAutomaticConstructionBootstrap2018,
  title = {The Automatic Construction of Bootstrap Confidence Intervals},
  author = {Efron, Bradley and Narasimhan, Balasubramanian},
  year = {2018},
  month = oct,
  pages = {17},
  abstract = {The standard intervals, e.g., \texttheta\textasciicircum{$\pm$} 1.96{$\sigma$}\textasciicircum{} for nominal 95\% two-sided coverage, are familiar and easy to use, but can be of dubious accuracy in regular practice. Bootstrap confidence intervals offer an order of magnitude improvement\textendash from first order to second order accuracy. This paper introduces a new set of algorithms that automate the construction of bootstrap intervals, substituting computer power for the need to individually program particular applications. The algorithms are described in terms of the underlying theory that motivates them, along with examples of their application.},
  file = {/Users/zad/Zotero/storage/AI2JYX3Y/Efron and Narasimhan - The automatic construction of bootstrap conﬁdence .pdf},
  keywords = {⛔ No DOI found},
  language = {en}
}

@article{efronFisher21stCentury1998,
  title = {R. {{A}}. {{Fisher}} in the 21st Century ({{Invited}} Paper Presented at the 1996 {{R}}. {{A}}. {{Fisher Lecture}})},
  author = {Efron, Bradley},
  year = {1998},
  month = may,
  volume = {13},
  pages = {95--122},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10/cxg354},
  abstract = {Fisher is the single most important figure in 20th century statistics. This talk examines his influence on modern statistical thinking, trying to predict how Fisherian we can expect the 21st century to be. Fisher's philosophy is characterized as a series of shrewd compromises between the Bayesian and frequentist viewpoints, augmented by some unique characteristics that are particularly useful in applied problems. Several current research topics are examined with an eye toward Fisherian influence, or the lack of it, and what this portends for future statistical developments. Based on the 1996 Fisher lecture, the article closely follows the text of that talk.},
  file = {/Users/zad/Zotero/storage/F6N9JUNM/Efron_1998_R.pdf;/Users/zad/Zotero/storage/LPMPXIRC/1028905930.html},
  journal = {Statistical Science},
  keywords = {Bayes,bootstrap,confidence intervals,empirical Bayes,fiducial,frequentist,model selection,Statistical inference},
  language = {en},
  mrnumber = {MR1647499},
  note = {\url{https://doi.org/10/cxg354}},
  number = {2},
  zmnumber = {1074.01536}
}

@book{efronIntroductionBootstrap1994,
  title = {An {{Introduction}} to the {{Bootstrap}}},
  author = {Efron, Bradley and Tibshirani, R. J.},
  year = {1994},
  month = may,
  publisher = {{CRC Press}},
  abstract = {Statistics is a subject of many uses and surprisingly few effective practitioners. The traditional road to statistical knowledge is blocked, for most, by a formidable wall of mathematics. The approach in An Introduction to the Bootstrap avoids that wall. It arms scientists and engineers, as well as statisticians, with the computational techniques they need to analyze and understand complicated data sets.},
  googlebooks = {gLlpIUxRntoC},
  isbn = {978-0-412-04231-7},
  keywords = {Computers / Mathematical \& Statistical Software,Mathematics / General,Mathematics / Probability \& Statistics / General},
  language = {en}
}

@book{farawayExtendingLinearModel,
  title = {Extending the {{Linear Model}} with {{R}}},
  author = {Faraway, Julian J},
  file = {/Users/zad/Zotero/storage/ZHV3Y2CK/Faraway - Extending the Linear Model with R.pdf},
  language = {en}
}

@book{fisherStatisticalMethodsResearch1925,
  title = {Statistical {{Methods}} for {{Research Workers}}},
  author = {Fisher, Ronald A.},
  year = {1925},
  publisher = {{Edinburgh}},
  address = {{Oliver and Boyd}},
  note = {\url{https://books.google.com/books?id=GmNAAAAAIAAJ\&q}}
}

@article{fisherStatisticalMethodsScientific1955,
  ids = {fisher1955jrsssbma},
  title = {Statistical {{Methods}} and {{Scientific Induction}}},
  author = {Fisher, Ronald},
  year = {1955},
  volume = {17},
  pages = {69--78},
  issn = {0035-9246},
  doi = {10.1111/j.2517-6161.1955.tb00180.x},
  abstract = {[The attempt to reinterpret the common tests of significance used in scientific research as though they constituted some kind of acceptance procedure and led to "decisions" in Wald's sense, originated in several misapprehensions and has led, apparently, to several more. The three phrases examined here, with a view to elucidating the fallacies they embody, are: (i) "Repeated sampling from the same population", (ii) Errors of the "second kind", (iii) "Inductive behaviour". Mathematicians without personal contact with the Natural Sciences have often been misled by such phrases. The errors to which they lead are not always only numerical.]},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of the Royal Statistical Society. Series B (Methodological)/1955/Fisher_1955_Statistical Methods and Scientific Induction.pdf;/Users/zad/Google Drive/Research/Zotero/Journal of the Royal Statistical Society. Series B (Methodological)/1955/Fisher_1955_Statistical methods and scientific induction2.pdf},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  note = {\url{http://www.jstor.org/stable/2983785}},
  number = {1}
}

@book{folksIdeasStatistics1981,
  title = {Ideas of {{Statistics}}},
  author = {Folks, Leroy},
  year = {1981},
  publisher = {{Wiley}},
  abstract = {Origins of statistics; Description of data; Probability; Three distributions; Large and small samples; Opinions, conclusions and decisions; Two dimensions; Legendre's principle of least squares; Statistics of experimental science; Some randomized experiments; Important conflicts of ideas; Many dimensions.},
  googlebooks = {Bn8pAQAAMAAJ},
  isbn = {978-0-471-02099-8},
  keywords = {Mathematics / Probability \& Statistics / General,Statistics},
  language = {en},
  note = {\url{https://books.google.com/books/about/Ideas_of_statistics.html?id=Bn8pAQAAMAAJ}}
}

@article{fraserPvalueFunctionStatistical2019,
  title = {The {{P}}-Value Function and Statistical Inference},
  author = {Fraser, D. A. S.},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {135--147},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1556735},
  abstract = {This article has two objectives. The first and narrower is to formalize the p-value function, which records all possible p-values, each corresponding to a value for whatever the scalar parameter of interest is for the problem at hand, and to show how this p-value function directly provides full inference information for any corresponding user or scientist. The p-value function provides familiar inference objects: significance levels, confidence intervals, critical values for fixed-level tests, and the power function at all values of the parameter of interest. It thus gives an immediate accurate and visual summary of inference information for the parameter of interest. We show that the p-value function of the key scalar interest parameter records the statistical position of the observed data relative to that parameter, and we then describe an accurate approximation to that p-value function which is readily constructed.},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/Fraser_2019_The p-value Function and Statistical Inference.pdf},
  journal = {The American Statistician},
  keywords = {Accept–Reject,Ancillarity,Box–Cox,Conditioning,Decision or judgment,Discrete data,Extreme value model,Fieller–Creasy,Gamma mean,Percentile position,Power function,Statistical position},
  note = {\url{https://doi.org/10.1080/00031305.2018.1556735}},
  number = {sup1}
}

@article{fraserPValuesInsightModern2017,
  title = {P-{{Values}}: {{The Insight}} to {{Modern Statistical Inference}}},
  author = {Fraser, D.A.S.},
  year = {2017},
  month = mar,
  volume = {4},
  pages = {1--14},
  issn = {2326-8298},
  doi = {10.1146/annurev-statistics-060116-054139},
  abstract = {I introduce a p-value function that derives from the continuity inherent in a wide range of regular statistical models. This provides confidence bounds and confidence sets, tests, and estimates that all reflect model continuity. The development starts with the scalar-variable scalar-parameter exponential model and extends to the vector-parameter model with scalar interest parameter, then to general regular models, and then references for testing vector interest parameters are available. The procedure does not use sufficiency but applies directly to general models, although it reproduces sufficiency-based results when sufficiency is present. The emphasis is on the coherence of the full procedure, and technical details are not emphasized.},
  file = {/Users/zad/Google Drive/Research/Zotero/Annual Review of Statistics and Its Application/2017/Fraser_2017_p-Values.pdf},
  journal = {Annual Review of Statistics and Its Application},
  note = {\url{https://doi.org/10.1146/annurev-statistics-060116-054139}},
  number = {1}
}

@article{Freedman2015-bz,
  title = {The Economics of Reproducibility in Preclinical Research},
  author = {Freedman, Leonard P. and Cockburn, Iain M. and Simcoe, Timothy S.},
  year = {2015},
  month = jun,
  volume = {13},
  pages = {e1002165},
  issn = {1544-9173, 1545-7885},
  doi = {10.1371/journal.pbio.1002165},
  abstract = {Low reproducibility rates within life science research undermine cumulative knowledge production and contribute to both delays and costs of therapeutic drug development. An analysis of past studies indicates that the cumulative (total) prevalence of irreproducible preclinical research exceeds 50\%, resulting in approximately US28,000,000,000 (US28B)/year spent on preclinical research that is not reproducible-in the United States alone. We outline a framework for solutions and a plan for long-term improvements in reproducibility rates that will help to accelerate the discovery of life-saving therapies and cures.},
  affiliation = {Global Biological Standards Institute, Washington, D.C., United States of America. Boston University School of Management, Boston, Massachusetts, United States of America. Boston University School of Management, Boston, Massachusetts, United States of America; Council of Economic Advisers, Washington, D.C., United States of America.},
  file = {/Users/zad/Google Drive/Research/Zotero/PLoS Biol./2015/Freedman et al_2015_The Economics of Reproducibility in Preclinical Research.pdf},
  journal = {PLOS Biology},
  language = {English},
  note = {\url{https://doi.org/10.1371/journal.pbio.1002165}},
  number = {6},
  pmc = {PMC4461318},
  pmid = {26057340}
}

@article{freedmanIssuesFoundationStatistics1995,
  title = {Some Issues in the Foundation of Statistics},
  author = {Freedman, David},
  year = {1995},
  month = mar,
  volume = {1},
  pages = {19--39},
  issn = {1572-8471},
  doi = {10.1007/BF00208723},
  abstract = {After sketching the conflict between objectivists and subjectivists on the foundations of statistics, this paper discusses an issue facing statisticians of both schools, namely, model validation. Statistical models originate in the study of games of chance, and have been successfully applied in the physical and life sciences. However, there are basic problems in applying the models to social phenomena; some of the difficulties will be pointed out. Hooke's law will be contrasted with regression models for salary discrimination, the latter being a fairly typical application in the social sciences.},
  file = {/Users/zad/Google Drive/Research/Zotero/Foundations of Science/1995/Freedman_1995_Some issues in the foundation of statistics.pdf},
  journal = {Foundations of Science},
  keywords = {Bayes,de Finetti,Decision theory,Model validation,Objectivist,Probability,Regression,Statistics,Subjectivist},
  language = {en},
  note = {\url{https://doi.org/10.1007/BF00208723}},
  number = {1}
}

@book{friedmanFundamentalsClinicalTrials2015,
  title = {Fundamentals of {{Clinical Trials}}},
  author = {Friedman, Lawrence M. and Furberg, Curt and DeMets, David L.},
  year = {2015},
  edition = {5. ed},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  abstract = {Literaturangaben},
  annotation = {OCLC: 935903160},
  file = {/Users/zad/Zotero/storage/E8Q4VAA2/Friedman et al. - 2015 - Fundamentals of clinical trials.pdf},
  isbn = {978-3-319-18538-5},
  language = {en}
}

@article{friedmanRegularizationPathsGeneralized2010,
  title = {Regularization {{Paths}} for {{Generalized Linear Models}} via {{Coordinate Descent}}},
  author = {Friedman, Jerome H. and Hastie, Trevor and Tibshirani, Rob},
  year = {2010},
  month = feb,
  volume = {33},
  pages = {1--22},
  issn = {1548-7660},
  doi = {10.18637/jss.v033.i01},
  copyright = {Copyright (c) 2009 Jerome H. Friedman, Trevor Hastie, Rob Tibshirani},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of Statistical Software/2010/Friedman et al_2010_Regularization Paths for Generalized Linear Models via Coordinate Descent.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  note = {\url{https://www.jstatsoft.org/index.php/jss/article/view/v033i01}},
  number = {1}
}

@article{gabryVisualizationBayesianWorkflow2019,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  volume = {182},
  pages = {389--402},
  issn = {1467-985X},
  doi = {10.1111/rssa.12378},
  abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workflow and it is indispensable when drawing inferences from the types of modern, high dimensional models that are used by applied researchers.},
  copyright = {\textcopyright{} 2019 Royal Statistical Society},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of the Royal Statistical Society Series A (Statistics in Society)/2019/Gabry et al_2019_Visualization in Bayesian workflow.pdf},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  keywords = {Bayesian data analysis,Statistical graphics,Statistical workflow},
  language = {en},
  note = {\url{http://rss.onlinelibrary.wiley.com/doi/abs/10.1111/rssa.12378}},
  number = {2}
}

@book{geffnerProbabilisticCausalInference2020,
  title = {Probabilistic and {{Causal Inference}}: {{The}} Work of {{Judea Pearl}}.},
  author = {Geffner, H and Dechter, R and Halpern, J},
  year = {2020}
}

@article{Gelman2014-qk,
  ids = {gelmanPowerCalculationsAssessing2014},
  title = {Beyond {{Power Calculations}}: {{Assessing Type S}} ({{Sign}}) and {{Type M}} ({{Magnitude}}) {{Errors}}},
  author = {Gelman, Andrew and Carlin, John},
  year = {2014},
  month = nov,
  volume = {9},
  pages = {641--651},
  publisher = {{SAGE Publications Inc}},
  issn = {1745-6916, 1745-6924},
  doi = {10.1177/1745691614551642},
  abstract = {Statistical power analysis provides the conventional approach to assess error rates when designing a research study. However, power analysis is flawed in that a narrow emphasis on statistical significance is placed as the primary focus of study design. In noisy, small-sample settings, statistically significant results can often be misleading. To help researchers address this problem in the context of their own studies, we recommend design calculations in which (a) the probability of an estimate being in the wrong direction (Type S [sign] error) and (b) the factor by which the magnitude of an effect might be overestimated (Type M [magnitude] error or exaggeration ratio) are estimated. We illustrate with examples from recent published research and discuss the largest challenge in a design calculation: coming up with reasonable estimates of plausible effect sizes based on external information.},
  affiliation = {Department of Statistics and Department of Political Science, Columbia University gelman@stat.columbia.edu. Clinical Epidemiology and Biostatistics Unit, Murdoch Children's Research Institute, Parkville, Victoria, Australia Department of Paediatrics and School of Population and Global Health, University of Melbourne.},
  file = {/Users/zad/Google Drive/Research/Zotero/Perspect. Psychol. Sci./2014/Gelman_Carlin_2014_Beyond Power Calculations.pdf},
  journal = {Perspectives on Psychological Science},
  keywords = {Beauty,Data Interpretation; Statistical,design calculation,exaggeration  ratio,exaggeration ratio,Female,Humans,Male,Menstrual Cycle,Politics,Power,power analysis,Psychology,replication crisis,Research Design,Sex Ratio,statistical  significance,statistical significance,Type M error,Type S error},
  language = {English},
  note = {\url{https://doi.org/10.1177/1745691614551642}},
  number = {6},
  pmid = {26186114}
}

@article{gelmanDifferenceSignificantNot2006,
  ids = {Gelman2006-ha},
  title = {The {{Difference Between}} ``{{Significant}}'' and ``{{Not Significant}}'' Is Not {{Itself Statistically Significant}}},
  author = {Gelman, Andrew and Stern, Hal},
  year = {2006},
  month = nov,
  volume = {60},
  pages = {328--331},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1198/000313006x152649},
  abstract = {It is common to summarize statistical comparisons by declarations of statistical significance or nonsignificance. Here we discuss one problem with such declarations, namely that changes in statistical significance are often not themselves statistically significant. By this, we are not merely making the commonplace observation that any particular threshold is arbitrary\textemdash for example, only a small change is required to move an estimate from a 5.1\% significance level to 4.9\%, thus moving it into statistical significance. Rather, we are pointing out that even large changes in significance levels can correspond to small, nonsignificant changes in the underlying quantities.The error we describe is conceptually different from other oft-cited problems\textemdash that statistical significance is not the same as practical importance, that dichotomization into significant and nonsignificant results encourages the dismissal of observed differences in favor of the usually less interesting null hypothesis of no difference, and that any particular threshold for declaring significance is arbitrary. We are troubled by all of these concerns and do not intend to minimize their importance. Rather, our goal is to bring attention to this additional error of interpretation. We illustrate with a theoretical example and two applied examples. The ubiquity of this statistical error leads us to suggest that students and practitioners be made more aware that the difference between ``significant'' and ``not significant'' is not itself statistically significant.},
  file = {/Users/zad/Google Drive/Research/Zotero/Am. Stat./2006/Gelman_Stern_2006_The Difference Between “Significant” and “Not Significant” is not Itself.pdf;/Users/zad/Zotero/storage/ZBZP9UNF/Gelman_Stern_2006_The Difference Between “Significant” and “Not Significant” is not Itself.pdf;/Users/zad/Zotero/storage/U59ZEHVY/000313006X152649.html},
  journal = {The American Statistician},
  keywords = {NHST},
  note = {\url{https://doi.org/10.1198/000313006X152649}},
  number = {4}
}

@article{gelmanGardenForkingPaths2013,
  title = {The Garden of Forking Paths: {{Why}} Multiple Comparisons Can Be a Problem, Even When There Is No ``Fishing Expedition'' or ``p-Hacking'' and the Research Hypothesis Was Posited Ahead of Time},
  author = {Gelman, Andrew and Loken, Eric},
  year = {2013},
  file = {/Users/zad/Google Drive/Research/Zotero/Department of Statistics, Columbia University/2013/Gelman_Loken_2013_The garden of forking paths.pdf},
  journal = {Department of Statistics, Columbia University},
  keywords = {⛔ No DOI found},
  note = {\url{https://stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf}}
}

@misc{gelmanPriorChoiceRecommendations2020,
  title = {Prior {{Choice Recommendations}}},
  author = {Gelman, Andrew},
  year = {2020},
  month = apr,
  file = {/Users/zad/Zotero/storage/S6EJAGCG/Prior-Choice-Recommendations.html},
  howpublished = {\url{https://github.com/stan-dev/stan}},
  journal = {GitHub},
  language = {en}
}

@article{gelmanProblemsPvaluesAre2016,
  title = {The Problems with {{P}}-Values Are Not Just with {{P}}-Values},
  author = {Gelman, Andrew},
  year = {2016},
  volume = {70},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2016/Gelman_2016_The problems with P-values are not just with P-values.pdf},
  journal = {The American Statistician},
  keywords = {⛔ No DOI found},
  note = {\url{https://stat.columbia.edu/~gelman/research/published/asa_pvalues.pdf}},
  number = {2}
}

@article{gelmanStatisticalCrisisScience2014,
  title = {The Statistical Crisis in Science},
  author = {Gelman, Andrew and Loken, Eric},
  year = {2014},
  abstract = {Data-dependent analysis\textemdash a ``garden of forking paths''\textemdash{} explains why many statistically significant comparisons don't hold up.},
  journal = {American Scientist},
  language = {en},
  note = {\url{https://americanscientist.org/article/the-statistical-crisis-in-science}}
}

@article{gigerenzerMindlessStatistics2004,
  title = {Mindless Statistics},
  author = {Gigerenzer, Gerd},
  year = {2004},
  month = nov,
  volume = {33},
  pages = {587--606},
  issn = {1053-5357},
  doi = {10.1016/j.socec.2004.09.033},
  abstract = {Statistical rituals largely eliminate statistical thinking in the social sciences. Rituals are indispensable for identification with social groups, but they should be the subject rather than the procedure of science. What I call the ``null ritual'' consists of three steps: (1) set up a statistical null hypothesis, but do not specify your own hypothesis nor any alternative hypothesis, (2) use the 5\% significance level for rejecting the null and accepting your hypothesis, and (3) always perform this procedure. I report evidence of the resulting collective confusion and fears about sanctions on the part of students and teachers, researchers and editors, as well as textbook writers.},
  file = {/Users/zad/Google Drive/Research/Zotero/The Journal of Socio-Economics/2004/Gigerenzer_2004_Mindless statistics.pdf},
  journal = {The Journal of Socio-Economics},
  keywords = {Collective illusions,Editors,Rituals,Statistical significance,Textbooks},
  note = {\url{https://doi.org/10.1016/j.socec.2004.09.033}},
  number = {5},
  series = {Statistical {{Significance}}}
}

@article{gigerenzerSurrogateScienceIdol2015,
  title = {Surrogate {{Science}}: {{The Idol}} of a {{Universal Method}} for {{Scientific Inference}}},
  shorttitle = {Surrogate {{Science}}},
  author = {Gigerenzer, Gerd and Marewski, Julian N.},
  year = {2015},
  month = feb,
  volume = {41},
  pages = {421--440},
  publisher = {{SAGE Publications Inc}},
  issn = {0149-2063},
  doi = {10.1177/0149206314547522},
  abstract = {The application of statistics to science is not a neutral act. Statistical tools have shaped and were also shaped by its objects. In the social sciences, statistical methods fundamentally changed research practice, making statistical inference its centerpiece. At the same time, textbook writers in the social sciences have transformed rivaling statistical systems into an apparently monolithic method that could be used mechanically. The idol of a universal method for scientific inference has been worshipped since the ``inference revolution'' of the 1950s. Because no such method has ever been found, surrogates have been created, most notably the quest for significant p values. This form of surrogate science fosters delusions and borderline cheating and has done much harm, creating, for one, a flood of irreproducible results. Proponents of the ``Bayesian revolution'' should be wary of chasing yet another chimera: an apparently universal inference procedure. A better path would be to promote both an understanding of the various devices in the ``statistical toolbox'' and informed judgment to select among these.},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of Management/2015/Gigerenzer_Marewski_2015_Surrogate science.pdf},
  journal = {Journal of Management},
  keywords = {Inference,Judgment,Methodology,Psychometrics,Statistical Probability,Statistics},
  language = {en},
  note = {\url{https://doi.org/10.1177/0149206314547522}},
  number = {2}
}

@book{gilovichHeuristicsBiasesPsychology2002,
  title = {Heuristics and {{Biases}}: {{The Psychology}} of {{Intuitive Judgment}}},
  shorttitle = {Heuristics and {{Biases}}},
  author = {Gilovich, Thomas and Griffin, Dale and Kahneman, Daniel},
  year = {2002},
  month = jul,
  publisher = {{Cambridge University Press}},
  abstract = {Judgment pervades human experience. Do I have a strong enough case to go to trial? Will the Fed change interest rates? Can I trust this person? This book examines how, and how well, people answer such questions. How do people cope with the complexities of , say, the world economy, the uncertain behavior of friends and adversaries, or their own changing tastes and personalities? When are people's judgments prone to bias, and what is responsible for their biases? This book compiles psychologists' best attempts to answer these important questions.},
  isbn = {978-0-521-79260-8},
  keywords = {Psychology / Cognitive Psychology,Psychology / Movements / General},
  language = {en},
  note = {\url{https://books.google.com/books/about/Heuristics_and_Biases.html?id=FfTVDY-zrCoC}}
}

@article{goodCorrectionsSurpriseIndex1957,
  ids = {goodCorrectionsSurpriseIndex1957a},
  title = {Corrections to "{{The Surprise Index}} for the {{Multivariate Normal Distribution}}"},
  author = {Good, I. J.},
  year = {1957},
  volume = {28},
  pages = {1055--1055},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {00034851},
  doi = {10/dsgx9q},
  file = {/Users/zad/Zotero/storage/3EDRKKF4/Good_1957_Corrections to The Surprise Index for the Multivariate Normal Distribution.pdf},
  journal = {The Annals of Mathematical Statistics},
  note = {\url{http://www.jstor.org/stable/2237075}},
  number = {4}
}

@article{goodmanIntroductionBayesianMethods2005,
  title = {Introduction to {{Bayesian}} Methods {{I}}: {{Measuring}} the Strength of Evidence},
  shorttitle = {Introduction to {{Bayesian}} Methods {{I}}},
  author = {Goodman, Steven N.},
  year = {2005},
  volume = {2},
  issn = {1740-7745},
  doi = {10.1191/1740774505cn098oa},
  abstract = {Bayesian inference is a formal method to combine evidence external to a study, represented by a prior probability curve, with the evidence generated by the study, represented by a likelihood function. Because Bayes theorem provides a proper way to measure and to combine study evidence, Bayesian methods can be viewed as a calculus of evidence, not just belief. In this introduction, we explore the properties and consequences of using the Bayesian measure of evidence, the Bayes factor (in its simplest form, the likelihood ratio). The Bayes factor compares the relative support given to two hypotheses by the data, in contrast to the P-value, which is calculated with reference only to the null hypothesis. This comparative property of the Bayes factor, combined with the need to explicitly predefine the alternative hypothesis, produces a different assessment of the strength of evidence against the null hypothesis than does the P-value, and it gives Bayesian procedures attractive frequency properties. However, the most important contribution of Bayesian methods is the way in which they affect both who participates in a scientific dialogue, and what is discussed. With the emphasis moved from "error rates" to evidence, content experts have an opportunity for their input to be meaningfully incorporated, making it easier for regulatory decisions to be made correctly.},
  file = {/Users/zad/Google Drive/Research/Zotero/Clinical Trials/2005/Goodman_2005_Introduction to Bayesian methods I.pdf},
  journal = {Clinical Trials},
  keywords = {Bayes Theorem,Humans,United States,United States Food and Drug Administration},
  note = {\url{https://doi.org/10.1191/1740774505cn098oa}},
  number = {4},
  pmid = {16281426}
}

@misc{goodrichRstanarmBayesianApplied2020,
  title = {Rstanarm: {{Bayesian}} Applied Regression Modeling via {{Stan}}.},
  author = {Goodrich, Ben and Gabry, Jonah and Ali, Imad and Brilleman, Sam},
  year = {2020},
  howpublished = {\url{https://mc-stan.org/rstanarm}},
  keywords = {⛔ No DOI found}
}

@article{goodSurpriseIndexMultivariate1956,
  title = {The Surprise Index for the Multivariate Normal Distribution},
  author = {Good, I. J.},
  year = {1956},
  volume = {27},
  pages = {1130--1135},
  issn = {0003-4851},
  doi = {10.1214/aoms/1177728079},
  file = {/Users/zad/Google Drive/Research/Zotero/The Annals of Mathematical Statistics/1956/Good_1956_The surprise index for the multivariate normal distribution.pdf},
  journal = {The Annals of Mathematical Statistics},
  note = {\url{https://doi.org/10.1214/aoms/1177728079}},
  number = {4}
}

@article{Greenland2013-oa,
  title = {Living with p Values: Resurrecting a {{Bayesian}} Perspective on Frequentist Statistics},
  author = {Greenland, Sander and Poole, Charles},
  year = {2013},
  month = jan,
  volume = {24},
  pages = {62--68},
  issn = {1044-3983, 1531-5487},
  doi = {10.1097/EDE.0b013e3182785741},
  abstract = {In response to the widespread abuse and misinterpretation of significance tests of null hypotheses, some editors and authors have strongly discouraged P values. However, null P values still thrive in most journals and are routinely misinterpreted as probabilities of a ``chance finding'' or of the null, when they are no such thing. This misuse may be lessened by recognizing correct Bayesian interpretations. For example, under weak priors, 95\% confidence intervals approximate 95\% posterior probability intervals, one-sided P values approximate directional posterior probabilities, and point estimates approximate posterior medians. Furthermore, under certain conditions, a one-sided P value for a prior median provides an approximate lower bound on the posterior probability that the point estimate is on the wrong side of that median. More generally, P values can be incorporated into a modern analysis framework that emphasizes measurement of fit, distance, and posterior probability in place of ``statistical significance'' and accept/reject decisions.},
  affiliation = {Department of Epidemiology, University of California, Los Angeles, CA, USA. lesdomes@ucla.edu},
  file = {/Users/zad/Google Drive/Research/Zotero/Epidemiology/2013/Greenland_Poole_2013_Living with p values.pdf},
  journal = {Epidemiology},
  language = {English},
  note = {\url{https://doi.org/10.1097/EDE.0b013e3182785741}},
  number = {1},
  pmid = {23232611}
}

@article{Greenland2017-es,
  title = {Invited Commentary: {{The}} Need for Cognitive Science in Methodology},
  author = {Greenland, Sander},
  year = {2017},
  month = sep,
  volume = {186},
  pages = {639--645},
  issn = {0002-9262, 1476-6256},
  doi = {10.1093/aje/kwx259},
  abstract = {There is no complete solution for the problem of abuse of statistics, but methodological training needs to cover cognitive biases and other psychosocial factors affecting inferences. The present paper discusses 3 common cognitive distortions: 1) dichotomania, the compulsion to perceive quantities as dichotomous even when dichotomization is unnecessary and misleading, as in inferences based on whether a P value is ``statistically significant''; 2) nullism, the tendency to privilege the hypothesis of no difference or no effect when there is no scientific basis for doing so, as when testing only the null hypothesis; and 3) statistical reification, treating hypothetical data distributions and statistical models as if they reflect known physical laws rather than speculative assumptions for thought experiments. As commonly misused, null-hypothesis significance testing combines these cognitive problems to produce highly distorted interpretation and reporting of study results. Interval estimation has so far proven to be an inadequate solution because it involves dichotomization, an avenue for nullism. Sensitivity and bias analyses have been proposed to address reproducibility problems (Am J Epidemiol. 2017;186(6):646-647); these methods can indeed address reification, but they can also introduce new distortions via misleading specifications for bias parameters. P values can be reframed to lessen distortions by presenting them without reference to a cutoff, providing them for relevant alternatives to the null, and recognizing their dependence on all assumptions used in their computation; they nonetheless require rescaling for measuring evidence. I conclude that methodological development and training should go beyond coverage of mechanistic biases (e.g., confounding, selection bias, measurement error) to cover distortions of conclusions produced by statistical methods and psychosocial forces.},
  affiliation = {Department of Epidemiology, School of Public Health, University of California, Los Angeles, CA.},
  file = {/Users/zad/Google Drive/Research/Zotero/Am. J. Epidemiol./2017/Greenland_2017_Invited Commentary.pdf},
  journal = {American Journal of Epidemiology},
  keywords = {behavioral economics,bias analysis,cognitive bias,motivated  reasoning,motivated reasoning,nullism,overconfidence,sensitivity analysis,significance testing},
  language = {English},
  note = {\url{https://doi.org/10.1093/aje/kwx259}},
  number = {6},
  pmid = {28938712}
}

@article{greenlandAidScientificInference2020,
  title = {To {{Aid Scientific Inference}}, {{Emphasize Unconditional Descriptions}} of {{Statistics}}},
  author = {Greenland, Sander and Rafi, Zad},
  year = {2020},
  abstract = {We have elsewhere reviewed proposals to reform terminology and improve interpretations of conventional statistics by emphasizing logical and information concepts over probability concepts. We here give detailed reasons and methods for reinterpreting statistics (including but not limited to) P-values and interval estimates in unconditional terms, which describe compatibility of observations with an entire set of analysis assumptions, rather than just a narrow target hypothesis. Such reinterpretations help avoid overconfident inferences whenever there is uncertainty about the assumptions used to derive and compute the statistical results. Examples of such assumptions include not only standard statistical modeling assumptions, but also assumptions about absence of systematic errors, protocol violations, and data corruption. Unconditional descriptions introduce uncertainty about such assumptions directly into statistical presentations of results, rather than leaving that only to the informal discussion that ensues. We thus view unconditional description as a vital component of good statistical training and presentation.},
  archivePrefix = {arXiv},
  copyright = {All rights reserved},
  eprint = {1909.08583},
  eprinttype = {arxiv},
  file = {/Users/zad/Google Drive/Research/Zotero/arXiv1909.08583 [stat]/2019/Greenland_Chow_2019_To Aid Statistical Inference, Emphasize Unconditional Descriptions of Statistics.pdf},
  journal = {arXiv:1909.08583 [stat.ME]},
  keywords = {⛔ No DOI found},
  note = {\url{https://arxiv.org/abs/1909.08583}},
  primaryClass = {stat.ME}
}

@article{greenlandAnalysisGoalsErrorcost2020,
  title = {Analysis Goals, Error-Cost Sensitivity, and Analysis Hacking: {{Essential}} Considerations in Hypothesis Testing and Multiple Comparisons},
  author = {Greenland, Sander},
  year = {2020},
  journal = {Paediatric and Perinatal Epidemiology},
  keywords = {⛔ No DOI found},
  number = {in press}
}

@article{greenlandAreConfidenceIntervals2019,
  title = {Are Confidence Intervals Better Termed ``Uncertainty Intervals''? {{No}}: {{Call}} Them Compatibility Intervals.},
  author = {Greenland, Sander},
  year = {2019},
  month = sep,
  volume = {366},
  issn = {0959-8138, 1756-1833},
  doi = {10.1136/bmj.l5381},
  abstract = {{$<$}p{$>$}Debate abounds about how to describe weaknesses in statistics. \textbf{Andrew Gelman} has no confidence in the term ``confidence interval,'' but \textbf{Sander Greenland} doesn't find ``uncertainty interval'' any better and argues instead for ``compatibility interval''{$<$}/p{$>$}},
  file = {/Users/zad/Google Drive/Research/Zotero/BMJ/2019/Gelman_Greenland_2019_Are confidence intervals better termed “uncertainty intervals”.pdf},
  journal = {BMJ},
  language = {en},
  note = {\url{https://doi.org/10.1136/bmj.l5381}},
  pmid = {31506269}
}

@incollection{greenlandBiasAnalysis2008,
  title = {Bias Analysis},
  booktitle = {Modern {{Epidemiology}}},
  author = {Greenland, Sander and Lash, Timothy L.},
  editor = {Rothman, Kenneth J. and Greenland, Sander and Lash, Timothy L.},
  year = {2008},
  edition = {3rd},
  pages = {345--380},
  publisher = {{Lippincott Williams \& Wilkins}},
  abstract = {The thoroughly revised and updated Third Edition of the acclaimed Modern Epidemiology reflects both the conceptual development of this evolving science and the increasingly focal role that epidemiology plays in dealing with public health and medical problems. Coauthored by three leading epidemiologists, with sixteen additional contributors, this Third Edition is the most comprehensive and cohesive text on the principles and methods of epidemiologic research. The book covers a broad range of concepts and methods, such as basic measures of disease frequency and associations, study design, field methods, threats to validity, and assessing precision. It also covers advanced topics in data analysis such as Bayesian analysis, bias analysis, and hierarchical regression. Chapters examine specific areas of research such as disease surveillance, ecologic studies, social epidemiology, infectious disease epidemiology, genetic and molecular epidemiology, nutritional epidemiology, environmental epidemiology, reproductive epidemiology, and clinical epidemiology.},
  googlebooks = {Z3vjT9ALxHUC},
  isbn = {978-0-7817-5564-1},
  keywords = {Medical / Education \& Training,Medical / Epidemiology,Medical / Infectious Diseases,Medical / Occupational \& Industrial Medicine,Medical / Public Health,Medical / Test Preparation \& Review},
  language = {en},
  note = {\url{https://books.google.com/books/about/Modern_Epidemiology.html?id=Z3vjT9ALxHUC}}
}

@incollection{greenlandCausalFoundationsApplied2020,
  title = {The Causal Foundations of Applied Probability and Statistics},
  booktitle = {Probabilistic and {{Causal Inference}}: {{The Work}} of {{Judea Pearl}}.},
  author = {Greenland, Sander},
  editor = {Geffner, H and Dechter, R and Halpern, J},
  year = {2020},
  publisher = {{in press}}
}

@incollection{greenlandFundamentalsEpidemiologicData2008,
  title = {Fundamentals of {{Epidemiologic Data Analysis}}},
  booktitle = {Modern {{Epidemiology}}},
  author = {Greenland, Sander and Rothman, Kenneth J.},
  editor = {Rothman, Kenneth J. and Greenland, Sander and Lash, Timothy L.},
  year = {2008},
  edition = {3rd},
  pages = {213--237},
  publisher = {{Lippincott Williams \& Wilkins}},
  abstract = {The thoroughly revised and updated Third Edition of the acclaimed Modern Epidemiology reflects both the conceptual development of this evolving science and the increasingly focal role that epidemiology plays in dealing with public health and medical problems. Coauthored by three leading epidemiologists, with sixteen additional contributors, this Third Edition is the most comprehensive and cohesive text on the principles and methods of epidemiologic research. The book covers a broad range of concepts and methods, such as basic measures of disease frequency and associations, study design, field methods, threats to validity, and assessing precision. It also covers advanced topics in data analysis such as Bayesian analysis, bias analysis, and hierarchical regression. Chapters examine specific areas of research such as disease surveillance, ecologic studies, social epidemiology, infectious disease epidemiology, genetic and molecular epidemiology, nutritional epidemiology, environmental epidemiology, reproductive epidemiology, and clinical epidemiology.},
  googlebooks = {Z3vjT9ALxHUC},
  isbn = {978-0-7817-5564-1},
  keywords = {Medical / Education \& Training,Medical / Epidemiology,Medical / Infectious Diseases,Medical / Occupational \& Industrial Medicine,Medical / Public Health,Medical / Test Preparation \& Review},
  language = {en},
  note = {\url{https://books.google.com/books/about/Modern_Epidemiology.html?id=Z3vjT9ALxHUC}}
}

@article{greenlandIdentifiabilityExchangeabilityEpidemiological1986,
  title = {Identifiability, {{Exchangeability}}, and {{Epidemiological Confounding}}},
  author = {Greenland, Sander and Robins, James},
  year = {1986},
  month = sep,
  volume = {15},
  pages = {413--419},
  doi = {10.1093/ije/15.3.413},
  file = {/Users/zad/Zotero/storage/7B4MWMNA/Greenland_Robins_1986_Identifiability, Exchangeability, and Epidemiological Confounding.pdf;/Users/zad/Zotero/storage/KSWEG5SW/658713.html},
  journal = {International Journal of Epidemiology},
  note = {\url{https://doi.org/10.1093/ije/15.3.413}},
  number = {3}
}

@article{greenlandMultipleBiasModelling2005,
  title = {Multiple-bias Modelling for Analysis of Observational Data},
  author = {Greenland, Sander},
  year = {2005},
  month = mar,
  volume = {168},
  pages = {267--306},
  doi = {10.1111/j.1467-985X.2004.00349.x},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of the Royal Statistical Society. Series A (Statistics in Society)/2005/Greenland_2005_Multiple‐bias modelling for analysis of observational data.pdf},
  journal = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
  note = {\url{https://doi.org/10.1111/j.1467-985X.2004.00349.x}},
  number = {2}
}

@article{greenlandMultipleComparisonsControversies2019,
  title = {Multiple Comparisons Controversies Are about Context and Costs, Not Frequentism versus {{Bayesianism}}},
  author = {Greenland, Sander and Hofman, Albert},
  year = {2019},
  month = sep,
  issn = {1573-7284},
  doi = {10.1007/s10654-019-00552-z},
  abstract = {The advantages of hierarchical (multilevel) adjustments for multiple comparisons were recognized by the 1970s, yet those adjustments remain uncommon in all but the largest-scale exploratory analyses. The extreme of no adjustment remains the norm, thanks to both its simplicity and the fact that any sensible adjustment is likely to remove treasured findings of ``statistical significance'' and so endanger report publication and prominence. An extreme reaction to this norm is to demand conventional adjustments like Bonferroni, which destroy power to detect all but the most spectacular effects, thus implicitly treating costs of false positives as far above costs of false negatives. These hidden assumptions about error costs have aggravated controversies and perpetuated extreme recommendations. The present paper reviews these problems, and advocates (once again) a more a more sophisticated and responsible treatment of multiple comparisons within hierarchical modeling and cost analysis. From an algorithmic perspective, this treatment transcends any difference between frequentist and Bayesian statistics, as both perspectives are needed for contextual justification of procedures and for valid interpretation of statistical outputs.},
  file = {/Users/zad/Google Drive/Research/Zotero/European Journal of Epidemiology/2019/Greenland_Hofman_2019_Multiple comparisons controversies are about context and costs, not frequentism2.pdf},
  journal = {European Journal of Epidemiology},
  note = {\url{https://doi.org/10.1007/s10654-019-00552-z}}
}

@article{greenlandRandomizationStatisticsCausal1990,
  title = {Randomization, Statistics, and Causal Inference},
  author = {Greenland, Sander},
  year = {1990},
  volume = {1},
  pages = {421--429},
  issn = {1044-3983},
  doi = {10.1097/00001648-199011000-00003},
  abstract = {This paper reviews the role of statistics in causal inference. Special attention is given to the need for randomization to justify causal inferences from conventional statistics, and the need for random sampling to justify descriptive inferences. In most epidemiologic studies, randomization and random sampling play little or no role in the assembly of study cohorts. I therefore conclude that probabilistic interpretations of conventional statistics are rarely justified, and that such interpretations may encourage ministerpretation of nonrandomized studies. Possible remedies for this problem include deemphasizing inferential statistics in favor of data descriptors, and adopting statistical techniques based on more realistic probability models than those in common use.},
  file = {/Users/zad/Google Drive/Research/Zotero/Epidemiology/1990/Greenland_1990_Randomization, statistics, and causal inference.pdf},
  journal = {Epidemiology},
  note = {\url{https://doi.org/10.1097/00001648-199011000-00003}},
  number = {6}
}

@article{greenlandSamplesizePowerCalculations1988,
  title = {On Sample-Size and Power Calculations for Studies Using Confidence Intervals},
  author = {Greenland, Sander},
  year = {1988},
  month = jul,
  volume = {128},
  pages = {231--237},
  issn = {0002-9262},
  doi = {10.1093/oxfordjournals.aje.a114945},
  abstract = {Abstract.  A recent trend in epidemiologic analysis has been away from significance tests and toward confidence intervals. In accord with this trend, several au},
  file = {/Users/zad/Google Drive/Research/Zotero/American Journal of Epidemiology/1988/Greenland_1988_On sample-size and power calculations for studies using confidence intervals.pdf},
  journal = {American Journal of Epidemiology},
  language = {en},
  note = {\url{https://doi.org/10.1093/oxfordjournals.aje.a114945}},
  number = {1}
}

@article{greenlandSeriousMisinterpretationConsistent2017,
  title = {A Serious Misinterpretation of a Consistent Inverse Association of Statin Use with Glioma across 3 Case-Control Studies},
  author = {Greenland, Sander},
  year = {2017},
  month = jan,
  volume = {32},
  pages = {87--88},
  issn = {1573-7284},
  doi = {10.1007/s10654-016-0205-z},
  file = {/Users/zad/Google Drive/Research/Zotero/European Journal of Epidemiology/2017/Greenland_2017_A serious misinterpretation of a consistent inverse association of statin use.pdf},
  journal = {European Journal of Epidemiology},
  language = {en},
  note = {\url{https://doi.org/10.1007/s10654-016-0205-z}},
  number = {1}
}

@article{greenlandSparseDataBias2016,
  ids = {greenland2016ba},
  title = {Sparse Data Bias: A Problem Hiding in Plain Sight},
  shorttitle = {Sparse Data Bias},
  author = {Greenland, Sander and Mansournia, Mohammad Ali and Altman, Douglas G.},
  year = {2016},
  month = apr,
  volume = {352},
  pages = {i1981},
  issn = {1756-1833},
  doi = {10.1136/bmj.i1981},
  abstract = {{$<$}p{$>$}Effects of treatment or other exposure on outcome events are commonly measured by ratios of risks, rates, or odds. Adjusted versions of these measures are usually estimated by maximum likelihood regression (eg, logistic, Poisson, or Cox modelling). But resulting estimates of effect measures can have serious bias when the data lack adequate case numbers for some combination of exposure and outcome levels. This bias can occur even in quite large datasets and is hence often termed sparse data bias. The bias can arise or be worsened by regression adjustment for potentially confounding variables; in the extreme, the resulting estimates could be impossibly huge or even infinite values that are meaningless artefacts of data sparsity. Such estimate inflation might be obvious in light of background information, but is rarely noted let alone accounted for in research reports. We outline simple methods for detecting and dealing with the problem focusing especially on penalised estimation, which can be easily performed with common software packages.{$<$}/p{$>$}},
  copyright = {Published by the BMJ Publishing Group Limited. For permission to use (where not already granted under a licence) please go to http://group.bmj.com/group/rights-licensing/permissions},
  file = {/Users/zad/Google Drive/Research/Zotero/BMJ/2016/Greenland et al_2016_Sparse data bias.pdf;/Users/zad/Zotero/storage/BPMVBFGE/Greenland et al. - 2016 - Sparse data bias a problem hiding in plain sight.pdf},
  journal = {BMJ},
  language = {en},
  note = {\url{https://www.bmj.com/content/352/bmj.i1981}},
  pmid = {27121591}
}

@article{greenlandStatisticalTestsValues2016,
  title = {Statistical Tests, {{P}} Values, Confidence Intervals, and Power: {{A}} Guide to Misinterpretations},
  shorttitle = {Statistical Tests, {{P}} Values, Confidence Intervals, and Power},
  author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
  year = {2016},
  month = apr,
  volume = {31},
  pages = {337--350},
  issn = {1573-7284},
  doi = {10.1007/s10654-016-0149-3},
  abstract = {Misinterpretation and abuse of statistical tests, confidence intervals, and statistical power have been decried for decades, yet remain rampant. A key problem is that there are no interpretations of these concepts that are at once simple, intuitive, correct, and foolproof. Instead, correct use and interpretation of these statistics requires an attention to detail which seems to tax the patience of working scientists. This high cognitive demand has led to an epidemic of shortcut definitions and interpretations that are simply wrong, sometimes disastrously so\textemdash and yet these misinterpretations dominate much of the scientific literature. In light of this problem, we provide definitions and a discussion of basic statistics that are more general and critical than typically found in traditional introductory expositions. Our goal is to provide a resource for instructors, researchers, and consumers of statistics whose knowledge of statistical theory and technique may be limited but who wish to avoid and spot misinterpretations. We emphasize how violation of often unstated analysis protocols (such as selecting analyses for presentation based on the P values they produce) can lead to small P values even if the declared test hypothesis is correct, and can lead to large P values even if that hypothesis is incorrect. We then provide an explanatory list of 25 misinterpretations of P values, confidence intervals, and power. We conclude with guidelines for improving statistical interpretation and reporting.},
  file = {/Users/zad/Google Drive/Research/Zotero/European Journal of Epidemiology/2016/Greenland et al_2016_Statistical tests, P values, confidence intervals, and power.pdf},
  journal = {European Journal of Epidemiology},
  keywords = {Confidence intervals,Hypothesis testing,NHST,Null testing,P  value,P value,Power,Significance tests,Statistical  testing,Statistical testing},
  language = {en},
  note = {\url{https://doi.org/10.1007/s10654-016-0149-3}},
  number = {4}
}

@article{greenlandTechnicalIssuesInterpretation2020,
  title = {Technical {{Issues}} in the {{Interpretation}} of {{S}}-Values and {{Their Relation}} to {{Other Information Measures}}},
  author = {Greenland, Sander and Rafi, Zad},
  year = {2020},
  month = aug,
  abstract = {An extended technical discussion of \$S\$-values and unconditional information can be found in Greenland, 2019. Here we briefly cover several technical topics mentioned in our main paper, Rafi \& Greenland, 2020: Different units for (scaling of) the \$S\$-value besides base-2 logs (bits); the importance of uniformity (validity) of the \$P\$-value for interpretation of the \$S\$-value; and the relation of the \$S\$-value to other measures of statistical information about a test hypothesis or model.},
  copyright = {All rights reserved},
  file = {/Users/zad/Zotero/storage/55QB6WAU/Rafi and Greenland - 2020 - Technical Issues in the Interpretation of S-values.pdf;/Users/zad/Zotero/storage/BATZC584/Rafi and Greenland - 2020 - Technical Issues in the Interpretation of S-values.html},
  keywords = {⛔ No DOI found},
  language = {en},
  note = {\url{https://arxiv.org/abs/2008.12991v1}}
}

@article{greenlandValidPvaluesBehave2019,
  title = {Valid {{P}}-Values Behave Exactly as They Should: {{Some}} Misleading Criticisms of {{P}}-Values and Their Resolution with {{S}}-Values},
  shorttitle = {Valid {{P}}-{{Values Behave Exactly}} as {{They Should}}},
  author = {Greenland, Sander},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {106--114},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1529625},
  abstract = {The present note explores sources of misplaced criticisms of P-values, such as conflicting definitions of ``significance levels'' and ``P-values'' in authoritative sources, and the consequent misinterpretation of P-values as error probabilities. It then discusses several properties of P-values that have been presented as fatal flaws: That P-values exhibit extreme variation across samples (and thus are ``unreliable''), confound effect size with sample size, are sensitive to sample size, and depend on investigator sampling intentions. These properties are often criticized from a likelihood or Bayesian framework, yet they are exactly the properties P-values should exhibit when they are constructed and interpreted correctly within their originating framework. Other common criticisms are that P-values force users to focus on irrelevant hypotheses and overstate evidence against those hypotheses. These problems are not however properties of P-values but are faults of researchers who focus on null hypotheses and overstate evidence based on misperceptions that p\,=\,0.05 represents enough evidence to reject hypotheses. Those problems are easily seen without use of Bayesian concepts by translating the observed P-value p into the Shannon information (S-value or surprisal) \textendash log2(p).},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/Greenland_2019_Valid P-Values Behave Exactly as They Should.pdf},
  journal = {The American Statistician},
  keywords = {Compatibility,Dichotomania,Evidence,Information,Logworth,Nullism,P-values,S-values,Significance testing,Surprisal},
  note = {\url{https://doi.org/10.1080/00031305.2018.1529625}},
  number = {sup1}
}

@article{grunwaldSafeTesting2019,
  title = {Safe {{Testing}}},
  author = {Gr{\"u}nwald, Peter and {de Heide}, Rianne and Koolen, Wouter},
  year = {2019},
  month = jun,
  abstract = {We present a new theory of hypothesis testing. The main concept is the S-value, a notion of evidence which, unlike p-values, allows for effortlessly combining evidence from several tests, even in the common scenario where the decision to perform a new test depends on the previous test outcome: safe tests based on S-values generally preserve Type-I error guarantees under such "optional continuation". S-values exist for completely general testing problems with composite null and alternatives. Their prime interpretation is in terms of gambling or investing, each S-value corresponding to a particular investment. Surprisingly, optimal "GROW" S-values, which lead to fastest capital growth, are fully characterized by the joint information projection (JIPr) between the set of all Bayes marginal distributions on H0 and H1. Thus, optimal S-values also have an interpretation as Bayes factors, with priors given by the JIPr. We illustrate the theory using two classical testing scenarios: the one-sample t-test and the 2x2 contingency table. In the t-test setting, GROW s-values correspond to adopting the right Haar prior on the variance, like in Jeffreys' Bayesian t-test. However, unlike Jeffreys', the "default" safe t-test puts a discrete 2-point prior on the effect size, leading to better behavior in terms of statistical power. Sharing Fisherian, Neymanian and Jeffreys-Bayesian interpretations, S-values and safe tests may provide a methodology acceptable to adherents of all three schools.},
  archivePrefix = {arXiv},
  eprint = {1906.07801},
  eprinttype = {arxiv},
  file = {/Users/zad/Zotero/storage/EHB67VF4/Grünwald et al_2019_Safe Testing.pdf;/Users/zad/Zotero/storage/D8INZN6M/1906.html},
  journal = {arXiv:1906.07801 [cs, math, stat]},
  keywords = {⛔ No DOI found,Computer Science - Information Theory,Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Methodology},
  note = {\url{https://arxiv.org/abs/1906.07801}},
  primaryClass = {cs, math, stat}
}

@article{gustafsonIntervalEstimationMessy2009,
  title = {Interval {{Estimation}} for {{Messy Observational Data}}},
  author = {Gustafson, Paul and Greenland, Sander},
  year = {2009},
  month = aug,
  volume = {24},
  pages = {328--342},
  issn = {0883-4237},
  doi = {10/chxdkr},
  abstract = {We review some aspects of Bayesian and frequentist interval estimation, focusing first on their relative strengths and weaknesses when used in "clean" or "textbook" contexts. We then turn attention to observational-data situations which are "messy," where modeling that acknowledges the limitations of study design and data collection leads to nonidentifiability. We argue, via a series of examples, that Bayesian interval estimation is an attractive way to proceed in this context even for frequentists, because it can be supplied with a diagnostic in the form of a calibration-sensitivity simulation analysis. We illustrate the basis for this approach in a series of theoretical considerations, simulations and an application to a study of silica exposure and lung cancer.},
  archivePrefix = {arXiv},
  eprint = {1010.0306},
  eprinttype = {arxiv},
  file = {/Users/zad/Zotero/storage/J978U9PL/Gustafson_Greenland_2009_Interval Estimation for Messy Observational Data.pdf;/Users/zad/Zotero/storage/Z2U7M3NL/1010.html},
  journal = {Statistical Science},
  keywords = {Statistics - Methodology},
  note = {\url{https://arxiv.org/abs/1010.0306}},
  number = {3}
}

@book{handImprobabilityPrincipleWhy2014,
  title = {The {{Improbability Principle}}: {{Why Coincidences}}, {{Miracles}}, and {{Rare Events Happen Every Day}}},
  shorttitle = {The {{Improbability Principle}}},
  author = {Hand, David J.},
  year = {2014},
  month = feb,
  publisher = {{Macmillan}},
  abstract = {In The Improbability Principle, the renowned statistician David J. Hand argues that extraordinarily rare events are anything but. In fact, they're commonplace. Not only that, we should all expect to experience a miracle roughly once every month. But Hand is no believer in superstitions, prophecies, or the paranormal. His definition of "miracle" is thoroughly rational. No mystical or supernatural explanation is necessary to understand why someone is lucky enough to win the lottery twice, or is destined to be hit by lightning three times and still survive. All we need, Hand argues, is a firm grounding in a powerful set of laws: the laws of inevitability, of truly large numbers, of selection, of the probability lever, and of near enough. Together, these constitute Hand's groundbreaking Improbability Principle. And together, they explain why we should not be so surprised to bump into a friend in a foreign country, or to come across the same unfamiliar word four times in one day. Hand wrestles with seemingly less explicable questions as well: what the Bible and Shakespeare have in common, why financial crashes are par for the course, and why lightning does strike the same place (and the same person) twice. Along the way, he teaches us how to use the Improbability Principle in our own lives\textemdash including how to cash in at a casino and how to recognize when a medicine is truly effective. An irresistible adventure into the laws behind "chance" moments and a trusty guide for understanding the world and universe we live in, The Improbability Principle will transform how you think about serendipity and luck, whether it's in the world of business and finance or you're merely sitting in your backyard, tossing a ball into the air and wondering where it will land.},
  googlebooks = {e1iNAgAAQBAJ},
  isbn = {978-0-374-17534-4},
  keywords = {Business \& Economics / Statistics,Business \& Economics / Strategic Planning,Mathematics / Probability \& Statistics / General},
  language = {en},
  note = {\url{https://books.google.com/books?id=raZRAQAAQBAJ}}
}

@book{haraCommunityPriorsBayesian2010,
  title = {Community of {{Priors}}: {{A Bayesian Approach}} to {{Consensus Building}}},
  shorttitle = {Community of {{Priors}}},
  author = {Hara, Motoaki},
  year = {2010},
  publisher = {{ProQuest LLC}},
  abstract = {Despite having drawn from empirical evidence and cumulative prior expertise in the formulation of research questions as well as study design, each study is treated as a stand-alone product rather than positioned within a sequence of cumulative evidence. While results of prior studies are typically cited within the body of prior literature review, the actual analyses of newly collected data are usually conducted without taking these sources of prior information into consideration, and study findings are often accompanied by a list of limitations including the lack of generalizability of study results. As a result, individuals who hope to rely on the body of scholarly work for any type of evidence based decision-making either a) rely on large scale review work conducted with similar research objectives by third party organizations such as the Cochrane Collaboration, or b) face the challenge of synthesizing available empirical evidence. This task becomes particularly daunting when the issue under consideration is contentious, with large volumes of studies appearing to exist on both side of the argument.    The primary objective of this dissertation is to investigate and illustrate the logic, use, and value of conducting Bayesian analyses using a "Community of Prior" (CP) in evaluations of interventions and programs in the behavioral sciences, education and related fields. Utilizing the basic underpinnings of Bayesian analysis, this dissertation outlines how prior information from multiple sources can be systematically incorporated in the analysis of newly collected data at hand. Rather than relying on a single (or a few hand-picked) prior specification(s)--an aspect frequently critiqued in conventional Bayesian analysis for potential subjectivity, the "Community of Prior" approach adopted in this dissertation allows for the incorporation of a potentially large number of sources for prior specification, thereby effectively considering prior evidence of completely opposing viewpoints.    The main illustration of the implementation of such an approach will focus on analyses of the data from a large-scale evaluation of a behavioral intervention, i.e., the Treatment System Impact (TSI) study, designed to investigate the effectiveness of a behavioral treatment for incarcerated substance abusers. Of particular interest is the in-depth examination of practical considerations involved in the construction and implementation of CP, including: 1) identification of key segments which constitutes the community of interest (e.g., researchers, policy-makers, practitioners), as well as which segments of, or individuals in, the community seem to take different sides on the policy-debate or central issues of interest, 2) identification of available sources to be used for CP construction (e.g., scientific literature, experimental data, as well as expert elicitations), 3) formulation and specification of CP as probability distributions / densities (e.g., issues concerning location, form, spread). This includes considerations of determining, and perhaps varying, the weight placed on a prior relative to the likelihood (e.g., exchangeability), and 4) assessment of the sensitivity of inferences concerning the treatment of interest based on the various posterior distributions resulting from the specified CP.    [The dissertation citations contained here are published with the permission of ProQuest LLC. Further reproduction is prohibited without permission. Copies of dissertations may be obtained by Telephone (800) 1-800-521-0600. Web page: http://www.proquest.com/en-US/products/dissertations/individuals.shtml.]},
  file = {/Users/zad/Zotero/storage/WFBI82AF/eric.ed.gov.html},
  isbn = {978-1-124-37339-3},
  journal = {ProQuest LLC},
  keywords = {Bayesian Statistics,Behavioral Science Research,Behavioral Sciences,Convergent Thinking,Evidence,Experimenter Characteristics,Expertise,Identification,Individual Characteristics,Inferences,Information Sources,Institutionalized Persons,Intervention,Maximum Likelihood Statistics,Measures (Individuals),Meta Analysis,Outcomes of Treatment,Probability,Program Implementation,Research Methodology,Research Problems,Substance Abuse},
  language = {en}
}

@article{harringtonNewGuidelinesStatistical2019,
  title = {New Guidelines for Statistical Reporting in the Journal},
  author = {Harrington, David and D'Agostino, Ralph B. and Gatsonis, Constantine and Hogan, Joseph W. and Hunter, David J. and Normand, Sharon-Lise T. and Drazen, Jeffrey M. and Hamel, Mary Beth},
  year = {2019},
  month = jul,
  volume = {381},
  pages = {285--286},
  issn = {0028-4793},
  doi = {10.1056/NEJMe1906559},
  file = {/Users/zad/Google Drive/Research/Zotero/New England Journal of Medicine/2019/Harrington et al_2019_New Guidelines for Statistical Reporting in the Journal.pdf},
  journal = {New England Journal of Medicine},
  number = {3}
}

@article{heldNewStandardAnalysis2020,
  title = {A New Standard for the Analysis and Design of Replication Studies},
  author = {Held, Leonhard},
  year = {2020},
  volume = {183},
  pages = {431--448},
  issn = {1467-985X},
  doi = {10/gg7vrd},
  abstract = {A new standard is proposed for the evidential assessment of replication studies. The approach combines a specific reverse Bayes technique with prior-predictive tail probabilities to define replication success. The method gives rise to a quantitative measure for replication success, called the sceptical p-value. The sceptical p-value integrates traditional significance of both the original and the replication study with a comparison of the respective effect sizes. It incorporates the uncertainty of both the original and the replication effect estimates and reduces to the ordinary p-value of the replication study if the uncertainty of the original effect estimate is ignored. The framework proposed can also be used to determine the power or the required replication sample size to achieve replication success. Numerical calculations highlight the difficulty of achieving replication success if the evidence from the original study is only suggestive. An application to data from the Open Science Collaboration project on the replicability of psychological science illustrates the methodology proposed.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/rssa.12493},
  copyright = {\textcopyright{} 2019 The Authors Journal of the Royal Statistical Society: Series A (Statistics in Society) Published by John Wiley \& Sons Ltd on behalf of the Royal Statistical Society.},
  file = {/Users/zad/Zotero/storage/M862CXDV/Held_2020_A new standard for the analysis and design of replication studies.pdf;/Users/zad/Zotero/storage/8P3EM663/rssa.html},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  keywords = {Power,Prior–data conflict,Replication success,Reverse Bayes technique,Sample size,Sceptical p-value},
  language = {en},
  note = {\url{https://doi.org/10.1111/rssa.12493}},
  number = {2}
}

@article{hjortConfidenceDistributionsRelated2018,
  title = {Confidence Distributions and Related Themes},
  author = {Hjort, Nils Lid and Schweder, Tore},
  year = {2018},
  volume = {195},
  pages = {1--13},
  issn = {0378-3758},
  doi = {10.1016/j.jspi.2017.09.017},
  abstract = {This is the guest editors' general introduction to a Special Issue of the Journal of Statistical Planning and Inference, dedicated to confidence distributions and related themes. Confidence distributions (CDs) are distributions for parameters of interest, constructed via a statistical model after analysing the data. As such they serve the same purpose for the frequentist statisticians as the posterior distributions for the Bayesians. There have been several attempts in the literature to put up a clear theory for such confidence distributions, from Fisher's fiducial inference and onwards. There are certain obstacles and difficulties involved in these attempts, both conceptually and operationally, which have contributed to the CDs being slow in entering statistical mainstream. Recently there is a renewed surge of interest in CDs and various related themes, however, reflected in both series of new methodological research, advanced applications to substantive sciences, and dissemination and communication via workshops and conferences. The present special issue of the JSPI is a collection of papers emanating from the Inference With Confidence workshop in Oslo, May 2015. Several of the papers appearing here were first presented at that workshop. The present collection includes however also new research papers from other scholars in the field.},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of Statistical Planning and Inference/2018/Hjort_Schweder_2018_Confidence distributions and related themes.pdf},
  journal = {Journal of Statistical Planning and Inference},
  keywords = {Confidence curves,Confidence distributions,Focus parameters,Likelihood,Meta-analysis,Probability},
  note = {\url{http://www.sciencedirect.com/science/article/pii/S037837581730174X}}
}

@book{imbensCausalInferenceStatistics2015,
  title = {Causal Inference in Statistics: Social, and Biomedical Sciences: {{An}} Introduction},
  shorttitle = {Causal Inference in Statistics},
  author = {Imbens, Guido W and Rubin, Donald B},
  year = {2015},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  annotation = {OCLC: 926872682},
  file = {/Users/zad/Zotero/storage/V6ZKZVY2/Imbens and Rubin - 2015 - Causal inference in statistics social, and biomed.pdf},
  isbn = {978-0-521-88588-1},
  language = {en}
}

@misc{infangerPvaluefunctionsCreatesPlots2020,
  title = {Pvaluefunctions: {{Creates}} and {{Plots P}}-{{Value Functions}}, {{S}}-{{Value Functions}}, {{Confidence Distributions}} and {{Confidence Densities}}},
  shorttitle = {Pvaluefunctions},
  author = {Infanger, Denis},
  year = {2020},
  month = jun,
  abstract = {Contains functions to compute and plot confidence distributions, confidence densities, p-value functions and s-value (surprisal) functions for several commonly used estimates. Instead of just calculating one p-value and one confidence interval, p-value functions display p-values and confidence intervals for many levels thereby allowing to gauge the compatibility of several parameter values with the data. These methods are discussed by Infanger D, Schmidt-Trucks\"ass A. (2019) {$<$}doi:10.1002/sim.8293{$>$}; Poole C. (1987) {$<$}doi:10.2105/AJPH.77.2.195{$>$}; Schweder T, Hjort NL. (2002) {$<$}doi:10.1111/1467-9469.00285{$>$}; Bender R, Berg G, Zeeb H. (2005) {$<$}doi:10.1002/bimj.200410104{$>$} ; Singh K, Xie M, Strawderman WE. (2007) {$<$}doi:10.1214/074921707000000102{$>$}; Rothman KJ, Greenland S, Lash TL. (2008, ISBN:9781451190052); Amrhein V, Trafimow D, Greenland S. (2019) {$<$}doi:10.1080/00031305.2018.1543137{$>$}; and Greenland S. (2019) {$<$}doi:10.1080/00031305.2018.1529625{$>$}.},
  copyright = {GPL-3 | file LICENSE},
  howpublished = {CRAN},
  note = {\url{https://cran.r-project.org/package=pvaluefunctions}}
}

@article{infangerValueFunctionsUnderused2019,
  title = {P Value Functions: {{An}} Underused Method to Present Research Results and to Promote Quantitative Reasoning},
  shorttitle = {P Value Functions},
  author = {Infanger, Denis and Schmidt-Trucks{\"a}ss, Arno},
  year = {2019},
  issn = {1097-0258},
  doi = {10.1002/sim.8293},
  abstract = {Null hypothesis significance testing has received a great amount of attention in recent years in the light of the reproducibility crisis of science. Recently, there have been calls to retire the dichotomization of study results into ``significant'' or ``not significant'' depending on whether the P value crosses some threshold or not. Ways of improving the interpretation of P values and confidence intervals are therefore needed. We illustrate the use of P value functions, which display confidence limits and P values for any confidence level for a parameter. P value functions accessibly display a wealth of information: point estimate for the parameter, one-sided and two-sided confidence limits at any level, and one-sided and two-sided P values for any null and non-null value and the counternull value. Presenting several recent examples from the literature, we show how P value functions can be applied to present evidence and to make informed statistical inferences without resorting to dichotomization. We argue that P value functions are more informative than commonly used summaries of study results such as single P values or confidence intervals. P value functions require minimal retraining, are easily interpreted, and show potential to fix many of the common misinterpretation of P values and confidence intervals. To facilitate the adoption of P value functions, we released an R package for creating P value functions for several commonly used estimates.},
  copyright = {\textcopyright{} 2019 John Wiley \& Sons, Ltd.},
  file = {/Users/zad/Google Drive/Research/Zotero/Statistics in Medicine/undefined/Infanger_Schmidt‐Trucksäss_P value functions.pdf},
  journal = {Statistics in Medicine},
  keywords = {confidence interval,graphics,hypothesis testing,P value,statistical significance},
  language = {en},
  note = {\url{https://doi.org/10.1002/sim.8293}}
}

@article{Ioannidis2017-wj,
  title = {The Power of Bias in Economics Research},
  author = {Ioannidis, John P. A. and Stanley, T D and Doucouliagos, Hristos},
  year = {2017},
  month = oct,
  volume = {127},
  pages = {F236-F265},
  issn = {0013-0133, 1468-0297},
  doi = {10.1111/ecoj.12461},
  abstract = {We investigate two critical dimensions of the credibility of empirical economics research: statistical power and bias. We survey 159 empirical economics literatures that draw upon 64,076 estimates of economic parameters reported in more than 6,700 empirical studies. Half of the research areas have nearly 90\% of their results under-powered. The median statistical power is 18\%, or less. A simple weighted average of those reported results that are adequately powered (power {$\geq$} 80\%) reveals that nearly 80\% of the reported effects in these empirical economics literatures are exaggerated; typically, by a factor of two and with one-third inflated by a factor of four or more.},
  file = {/Users/zad/Google Drive/Research/Zotero/Econ. J. Nepal/2017/Ioannidis et al_2017_The Power of Bias in Economics Research.pdf},
  journal = {The Economic Journal},
  note = {\url{https://doi.org/10.1111/ecoj.12461}},
  number = {605}
}

@article{ioannidisImportancePredefinedRules2019,
  title = {The Importance of Predefined Rules and Prespecified Statistical Analyses: {{Do}} Not Abandon Significance},
  shorttitle = {The {{Importance}} of {{Predefined Rules}} and {{Prespecified Statistical Analyses}}},
  author = {Ioannidis, John P. A.},
  year = {2019},
  month = jun,
  volume = {321},
  pages = {2067--2068},
  issn = {0098-7484},
  doi = {10.1001/jama.2019.4582},
  abstract = {In this Viewpoint, John Ioannidis argues against abandoning the notion and language of statistical significance, which has been proposed as a means to diminish oversimplistic interpretations of clinical research. A significance filter in some form is essential for distinguishing signal from noise,...},
  file = {/Users/zad/Google Drive/Research/Zotero/JAMA/2019/Ioannidis_2019_The importance of predefined rules and prespecified statistical analyses.pdf},
  journal = {JAMA},
  language = {en},
  note = {\url{https://doi.org/10.1001/jama.2019.4582}},
  number = {21}
}

@book{jamesIntroductionStatisticalLearning2013,
  title = {An {{Introduction}} to {{Statistical Learning}}},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2013},
  volume = {103},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-7138-7},
  file = {/Users/zad/Zotero/storage/KLQW5TVN/James et al. - 2013 - An Introduction to Statistical Learning.pdf},
  isbn = {978-1-4614-7137-0 978-1-4614-7138-7},
  language = {en},
  note = {\url{http://link.springer.com/10.1007/978-1-4614-7138-7}},
  series = {Springer {{Texts}} in {{Statistics}}}
}

@article{janssensDefiningEvidencePrecision2019,
  title = {Defining Evidence for Precision Medicine: {{A}} Patient Is More than a Set of Covariates},
  shorttitle = {Defining {{Evidence}} for {{Precision Medicine}}},
  author = {Janssens, A. Cecile J. W.},
  year = {2019},
  month = may,
  volume = {30},
  pages = {342},
  issn = {1044-3983},
  doi = {10.1097/EDE.0000000000000992},
  abstract = {An abstract is unavailable.},
  file = {/Users/zad/Google Drive/Research/Zotero/Epidemiology/2019/Janssens_2019_Defining evidence for precision medicine.pdf},
  journal = {Epidemiology},
  language = {en-US},
  note = {\url{https://doi.org/10.1097/EDE.0000000000000992}},
  number = {3}
}

@book{jewellStatisticsEpidemiology2003,
  title = {Statistics for {{Epidemiology}}},
  author = {Jewell, Nicholas P.},
  year = {2003},
  month = aug,
  publisher = {{CRC Press}},
  abstract = {Statistical ideas have been integral to the development of epidemiology and continue to provide the tools needed to interpret epidemiological studies. Although epidemiologists do not need a highly mathematical background in statistical theory to conduct and interpret such studies, they do need more than an encyclopedia of "recipes." Statistics for Epidemiology achieves just the right balance between the two approaches, building an intuitive understanding of the methods most important to practitioners and the skills to use them effectively. It develops the techniques for analyzing simple risk factors and disease data, with step-by-step extensions that include the use of binary regression. It covers the logistic regression model in detail and contrasts it with the Cox model for time-to-incidence data. The author uses a few simple case studies to guide readers from elementary analyses to more complex regression modeling. Following these examples through several chapters makes it easy to compare the interpretations that emerge from varying approaches. Written by one of the top biostatisticians in the field, Statistics for Epidemiology stands apart in its focus on interpretation and in the depth of understanding it provides. It lays the groundwork that all public health professionals, epidemiologists, and biostatisticians need to successfully design, conduct, and analyze epidemiological studies.},
  googlebooks = {if4K02ui2p4C},
  isbn = {978-0-203-49686-2},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Biostatistics,Medical / Epidemiology,Science / Life Sciences / Biology},
  language = {en},
  note = {\url{https://books.google.com/books/about/Statistics_for_Epidemiology.html?id=if4K02ui2p4C}}
}

@book{kestenbaumEpidemiologyBiostatisticsIntroduction2009,
  title = {Epidemiology and Biostatistics: An Introduction to Clinical Research},
  shorttitle = {Epidemiology and Biostatistics},
  author = {Kestenbaum, Bryan and Adeney, Kathryn L. and Weiss, Noel S. and Shoben, Abigail B.},
  year = {2009},
  publisher = {{Springer}},
  address = {{Dordrecht ; New York}},
  annotation = {OCLC: ocn648077726},
  file = {/Users/zad/Zotero/storage/KGLINKBN/Kestenbaum et al. - 2009 - Epidemiology and biostatistics an introduction to.pdf},
  isbn = {978-0-387-88432-5 978-0-387-88433-2},
  keywords = {Biometry,Biostatistics,Epidemiology},
  language = {en},
  lccn = {RA651 .K44 2009}
}

@article{kimAlternativePerspectiveConsensus2016,
  title = {An {{Alternative Perspective}} on {{Consensus Priors}} with {{Applications}} to {{Phase I Clinical Trials}}.},
  author = {Kim, Steven B.},
  year = {2016},
  volume = {1},
  file = {/Users/zad/Zotero/storage/FKZQ6BET/Kim_2016_An Alternative Perspective on Consensus Priors with Applications to Phase I.pdf},
  journal = {J J  Biostat},
  keywords = {⛔ No DOI found},
  note = {\url{https://digitalcommons.csumb.edu/cgi/viewcontent.cgi?article=1001\&context=math_fac}},
  number = {1}
}

@book{kleinbaumPocketGuideEpidemiology2007,
  title = {A Pocket Guide to Epidemiology},
  author = {Kleinbaum, David G. and Sullivan, Kevin M. and Barker, Nancy D.},
  year = {2007},
  publisher = {{Springer}},
  address = {{New York}},
  file = {/Users/zad/Zotero/storage/4SS5I9NV/Kleinbaum et al. - 2007 - A pocket guide to epidemiology.pdf},
  isbn = {978-0-387-45964-6},
  keywords = {Epidemiology,Handbooks; manuals; etc,Problems; exercises; etc},
  language = {en},
  lccn = {RA651 .K55 2007}
}

@article{kuffnerWhyArePvalues2019,
  title = {Why Are {{P}}-Values Controversial?},
  author = {Kuffner, Todd A. and Walker, Stephen G.},
  year = {2019},
  month = jan,
  volume = {73},
  pages = {1--3},
  issn = {0003-1305},
  doi = {10.1080/00031305.2016.1277161},
  abstract = {While it is often argued that a p-value is a probability; see Wasserstein and Lazar, we argue that a p-value is not defined as a probability. A p-value is a bijection of the sufficient statistic for a given test which maps to the same scale as the Type I error probability. As such, the use of p-values in a test should be no more a source of controversy than the use of a sufficient statistic. It is demonstrated that there is, in fact, no ambiguity about what a p-value is, contrary to what has been claimed in recent public debates in the applied statistics community. We give a simple example to illustrate that rejecting the use of p-values in testing for a normal mean parameter is conceptually no different from rejecting the use of a sample mean. The p-value is innocent; the problem arises from its misuse and misinterpretation. The way that p-values have been informally defined and interpreted appears to have led to tremendous confusion and controversy regarding their place in statistical analysis.},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/Kuffner_Walker_2019_Why are p-Values Controversial.pdf},
  journal = {The American Statistician},
  keywords = {Decision rule,Sufficient statistic,Type I error},
  note = {\url{https://doi.org/10.1080/00031305.2016.1277161}},
  number = {1}
}

@misc{kuhnCaretClassificationRegression2020,
  title = {Caret: {{Classification}} and {{Regression Training}}.},
  author = {Kuhn, Max},
  year = {2020},
  howpublished = {\url{https://CRAN.R-project.org/package=caret}}
}

@book{lakatosMethodIncludingLakatos1999,
  title = {For and {{Against Method}}: {{Including Lakatos}}'s {{Lectures}} on {{Scientific Method}} and the {{Lakatos}}-{{Feyerabend Correspondence}}},
  shorttitle = {For and {{Against Method}}},
  author = {Lakatos, Imre and Feyerabend, Paul},
  year = {1999},
  month = oct,
  publisher = {{University of Chicago Press}},
  abstract = {The work that helped to determine Paul Feyerabend's fame and notoriety, Against Method, stemmed from Imre Lakatos's challenge: "In 1970 Imre cornered me at a party. 'Paul,' he said, 'you have such strange ideas. Why don't you write them down? I shall write a reply, we publish the whole thing and I promise you\textemdash we shall have a lot of fun.' " Although Lakatos died before he could write his reply, For and Against Method reconstructs his original counter-arguments from lectures and correspondence previously unpublished in English, allowing us to enjoy the "fun" two of this century's most eminent philosophers had, matching their wits and ideas on the subject of the scientific method.  For and Against Method opens with an imaginary dialogue between Lakatos and Feyerabend, which Matteo Motterlini has constructed, based on their published works, to synthesize their positions and arguments. Part one presents the transcripts of the last lectures on method that Lakatos delivered. Part two, Feyerabend's response, consists of a previously published essay on anarchism, which began the attack on Lakatos's position that Feyerabend later continued in Against Method. The third and longest section consists of the correspondence Lakatos and Feyerabend exchanged on method and many other issues and ideas, as well as the events of their daily lives, between 1968 and Lakatos's death in 1974.  The delight Lakatos and Feyerabend took in philosophical debate, and the relish with which they sparred, come to life again in For and Against Method, making it essential and lively reading for anyone interested in these two fascinating and controversial thinkers and their immense contributions to philosophy of science.  "The writings in this volume are of considerable intellectual importance, and will be of great interest to anyone concerned with the development of the philosophical views of Lakatos and Feyerabend, or indeed with the development of philosophy of science in general during this crucial period."\textemdash Donald Gillies, British Journal for the Philosophy of Science (on the Italian edition)  "A stimulating exchange of letters between two philosophical entertainers."\textemdash Tariq Ali, The Independent  Imre Lakatos (1922-1974) was professor of logic at the London School of Economics. He was the author of Proofs and Refutations and the two-volume Philosophical Papers. Paul Feyerabend (1924-1994) was educated in Europe and held numerous teaching posts throughout his career. Among his books are Against Method; Science in a Free Society; Farewell to Reason; and Killing Time: The Autobiography of Paul Feyerabend, the last published by the University of Chicago Press.},
  googlebooks = {osMnuvLZvPoC},
  isbn = {978-0-226-46774-0},
  keywords = {Science / General,Science / Philosophy \& Social Aspects,Science / Research \& Methodology},
  language = {en},
  note = {\url{https://books.google.com/books/about/For_and_Against_Method.html?id=osMnuvLZvPoC}}
}

@article{Lakens2018-im,
  title = {Equivalence Testing for Psychological Research: {{A}} Tutorial},
  author = {Lakens, Dani{\"e}l and Scheel, Anne M. and Isager, Peder M.},
  year = {2018},
  month = jun,
  volume = {1},
  pages = {259--269},
  publisher = {{SAGE Publications Inc}},
  issn = {2515-2459},
  doi = {10.1177/2515245918770963},
  abstract = {Psychologists must be able to test both for the presence of an effect and for the absence of an effect. In addition to testing against zero, researchers can use the two one-sided tests (TOST) procedure to test for equivalence and reject the presence of a smallest effect size of interest (SESOI). The TOST procedure can be used to determine if an observed effect is surprisingly small, given that a true effect at least as extreme as the SESOI exists. We explain a range of approaches to determine the SESOI in psychological science and provide detailed examples of how equivalence tests should be performed and reported. Equivalence tests are an important extension of the statistical tools psychologists currently use and enable researchers to falsify predictions about the presence, and declare the absence, of meaningful effects.},
  file = {/Users/zad/Google Drive/Research/Zotero/Advances in Methods and Practices in Psychological Science/2018/Lakens et al_2018_Equivalence Testing for Psychological Research.pdf},
  journal = {Advances in Methods and Practices in Psychological Science},
  note = {\url{https://doi.org/10.1177/2515245918770963}},
  number = {2}
}

@article{Lakens2018-lg,
  title = {Justify Your Alpha},
  author = {Lakens, Dani{\"e}l and Adolfi, Federico G and Albers, Casper J and Anvari, Farid and Apps, Matthew A J and Argamon, Shlomo E and Baguley, Thom and Becker, Raymond B and Benning, Stephen D and Bradford, Daniel E and Buchanan, Erin M and Caldwell, Aaron R and Van Calster, Ben and Carlsson, Rickard and Chen, Sau-Chin and Chung, Bryan and Colling, Lincoln J and Collins, Gary S and Crook, Zander and Cross, Emily S and Daniels, Sameera and Danielsson, Henrik and DeBruine, Lisa and Dunleavy, Daniel J and Earp, Brian D and Feist, Michele I and Ferrell, Jason D and Field, James G and Fox, Nicholas W and Friesen, Amanda and Gomes, Caio and {Gonzalez-Marquez}, Monica and Grange, James A and Grieve, Andrew P and Guggenberger, Robert and Grist, James and {van Harmelen}, Anne-Laura and Hasselman, Fred and Hochard, Kevin D and Hoffarth, Mark R and Holmes, Nicholas P and Ingre, Michael and Isager, Peder M and Isotalus, Hanna K and Johansson, Christer and Juszczyk, Konrad and Kenny, David A and Khalil, Ahmed A and Konat, Barbara and Lao, Junpeng and Larsen, Erik Gahner and Lodder, Gerine M A and Lukavsk{\'y}, Ji{\v r}{\'i} and Madan, Christopher R and Manheim, David and Martin, Stephen R and Martin, Andrea E and Mayo, Deborah G and McCarthy, Randy J and McConway, Kevin and McFarland, Colin and Nio, Amanda Q X and Nilsonne, Gustav and {de Oliveira}, Cilene Lino and {de Xivry}, Jean-Jacques Orban and Parsons, Sam and Pfuhl, Gerit and Quinn, Kimberly A and Sakon, John J and Adil Saribay, S and Schneider, Iris K and Selvaraju, Manojkumar and Sjoerds, Zsuzsika and Smith, Samuel G and Smits, Tim and Spies, Jeffrey R and Sreekumar, Vishnu and Steltenpohl, Crystal N and Stenhouse, Neil and {\'S}wi{\k{a}}tkowski, Wojciech and Vadillo, Miguel A and Van Assen, Marcel A L M and Williams, Matt N and Williams, Samantha E and Williams, Donald R and Yarkoni, Tal and Ziano, Ignazio and Zwaan, Rolf A},
  year = {2018},
  month = feb,
  volume = {2},
  pages = {168--171},
  publisher = {{Nature Publishing Group}},
  issn = {2397-3374, 2397-3374},
  doi = {10.1038/s41562-018-0311-x},
  abstract = {In response to recommendations to redefine statistical significance to P {$\leq$} 0.005, we propose that researchers should transparently report and justify all choices they make when designing a study, including the alpha level.},
  file = {/Users/zad/Google Drive/Research/Zotero/Nature Human Behaviour/2018/Lakens et al_2018_Justify your alpha.pdf},
  journal = {Nature Human Behaviour},
  language = {English},
  note = {\url{https://doi.org/10.1038/s41562-018-0311-x}},
  number = {3}
}

@book{lakshminarayananBayesianApplicationsPharmaceutical2019,
  title = {Bayesian {{Applications}} in {{Pharmaceutical Development}}},
  author = {Lakshminarayanan, Mani and Natanegara, Fanni},
  year = {2019},
  month = nov,
  publisher = {{CRC Press}},
  abstract = {The cost for bringing new medicine from discovery to market has nearly doubled in the last decade and has now reached \$2.6 billion. There is an urgent need to make drug development less time-consuming and less costly. Innovative trial designs/ analyses such as the Bayesian approach are essential to meet this need. This book will be the first to provide comprehensive coverage of Bayesian applications across the span of drug development, from discovery, to clinical trial, to manufacturing with practical examples.  This book will have a wide appeal to statisticians, scientists, and physicians working in drug development who are motivated to accelerate and streamline the drug development process, as well as students who aspire to work in this field. The advantages of this book are:   Provides motivating, worked, practical case examples with easy to grasp models, technical details, and computational codes to run the analyses  Balances practical examples with best practices on trial simulation and reporting, as well as regulatory perspectives  Chapters written by authors who are individual contributors in their respective topics  Dr. Mani Lakshminarayanan is a researcher and statistical consultant with more than 30 years of experience in the pharmaceutical industry. He has published over 50 articles, technical reports, and book chapters besides serving as a referee for several journals. He has a PhD in Statistics from Southern Methodist University, Dallas, Texas and is a Fellow of the American Statistical Association.   Dr. Fanni Natanegara has over 15 years of pharmaceutical experience and is currently Principal Research Scientist and Group Leader for the Early Phase Neuroscience Statistics team at Eli Lilly and Company. She played a key role in the Advanced Analytics team to provide Bayesian education and statistical consultation at Eli Lilly. Dr. Natanegara is the chair of the cross industry-regulatory-academic DIA BSWG to ensure that Bayesian methods are appropriately utilized for design and analysis throughout the drug-development process.},
  googlebooks = {R9W8DwAAQBAJ},
  isbn = {978-1-351-58416-6},
  keywords = {Business \& Economics / Industries / Pharmaceutical \& Biotechnology,Mathematics / Probability \& Statistics / Bayesian Analysis,Mathematics / Probability \& Statistics / General,Medical / Biostatistics,Medical / Pharmacology,Reference / General},
  language = {en}
}

@article{Lang1998-sb,
  title = {That Confounded {{P}}-Value},
  author = {Lang, J M and Rothman, Kenneth J. and Cann, C I},
  year = {1998},
  month = jan,
  volume = {9},
  pages = {7--8},
  issn = {1044-3983},
  journal = {Epidemiology},
  keywords = {⛔ No DOI found},
  language = {English},
  note = {\url{https://doi.org/10.1097/00001648-199801000-00004}},
  number = {1},
  pmid = {9430261}
}

@article{Lash2018-lf,
  title = {The Replication Crisis in Epidemiology: {{Snowball}}, Snow Job, or Winter Solstice?},
  author = {Lash, Timothy L. and Collin, Lindsay J. and Van Dyke, Miriam E.},
  year = {2018},
  month = jun,
  volume = {5},
  pages = {175--183},
  issn = {2196-2995},
  doi = {10.1007/s40471-018-0148-x},
  abstract = {Like a snowball rolling down a steep hill, the most recent crisis over the perceived lack of reproducibility of scientific results has outpaced the evidence of crisis. It has led to new actions and new guidelines that have been rushed to market without plans for evaluation, metrics for success, or due consideration of the potential for unintended consequences.},
  file = {/Users/zad/Google Drive/Research/Zotero/Current Epidemiology Reports/2018/Lash et al_2018_The replication crisis in epidemiology.pdf},
  journal = {Current Epidemiology Reports},
  note = {\url{https://doi.org/10.1007/s40471-018-0148-x}},
  number = {2}
}

@book{lashApplyingQuantitativeBias2009,
  title = {Applying {{Quantitative Bias Analysis}} to {{Epidemiologic Data}}},
  author = {Lash, Timothy L. and Fox, Matthew P. and Fink, Aliza K.},
  year = {2009},
  publisher = {{Springer New York}},
  abstract = {Bias analysis quantifies the influence of systematic error on an epidemiology study's estimate of association. The fundamental methods of bias analysis in epi- miology have been well described for decades, yet are seldom applied in published presentations of epidemiologic research. More recent advances in bias analysis, such as probabilistic bias analysis, appear even more rarely. We suspect that there are both supply-side and demand-side explanations for the scarcity of bias analysis. On the demand side, journal reviewers and editors seldom request that authors address systematic error aside from listing them as limitations of their particular study. This listing is often accompanied by explanations for why the limitations should not pose much concern. On the supply side, methods for bias analysis receive little attention in most epidemiology curriculums, are often scattered throughout textbooks or absent from them altogether, and cannot be implemented easily using standard statistical computing software. Our objective in this text is to reduce these supply-side barriers, with the hope that demand for quantitative bias analysis will follow.},
  file = {/Users/zad/Google Drive/Research/Zotero/Springer New York/2009/Lash et al_2009_Applying Quantitative Bias Analysis to Epidemiologic Data.pdf},
  googlebooks = {XzVGYgEACAAJ},
  isbn = {978-1-4419-2774-3},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Biostatistics,Medical / Epidemiology,Medical / General,Medical / Infectious Diseases,Medical / Instruments \& Supplies,Medical / Public Health,Social Science / Methodology,Social Science / Research},
  language = {en},
  note = {\url{https://doi.org/10.1007/b97920}}
}

@article{lashGoodPracticesQuantitative2014,
  title = {Good Practices for Quantitative Bias Analysis},
  author = {Lash, Timothy L. and Fox, Matthew P. and MacLehose, Richard F. and Maldonado, George and McCandless, Lawrence C. and Greenland, Sander},
  year = {2014},
  month = dec,
  volume = {43},
  pages = {1969--1985},
  issn = {0300-5771},
  doi = {10.1093/ije/dyu149},
  abstract = {Abstract.  Quantitative bias analysis serves several objectives in epidemiological research. First, it provides a quantitative estimate of the direction, magnit},
  file = {/Users/zad/Google Drive/Research/Zotero/International Journal of Epidemiology/2014/Lash et al_2014_Good practices for quantitative bias analysis.pdf},
  journal = {International Journal of Epidemiology},
  language = {en},
  note = {\url{https://doi.org/10.1093/ije/dyu149}},
  number = {6}
}

@article{lashHarmDoneReproducibility2017,
  ids = {Lash2017-ie},
  title = {The Harm Done to Reproducibility by the Culture of Null Hypothesis Significance Testing},
  author = {Lash, Timothy L.},
  year = {2017},
  month = sep,
  volume = {186},
  pages = {627--635},
  issn = {0002-9262},
  doi = {10.1093/aje/kwx261},
  abstract = {Abstract.  In the last few years, stakeholders in the scientific community have raised alarms about a perceived lack of reproducibility of scientific results. I},
  affiliation = {[object Object]},
  file = {/Users/zad/Google Drive/Research/Zotero/Am. J. Epidemiol./2017/Lash_2017_The Harm Done to Reproducibility by the Culture of Null Hypothesis Significance.pdf;/Users/zad/Google Drive/Research/Zotero/American Journal of Epidemiology/2017/Lash_2017_The Harm Done to Reproducibility by the Culture of Null Hypothesis Significance.pdf},
  journal = {American Journal of Epidemiology},
  keywords = {data interpretation,epidemiologic methods,epidemiologic research design,null hypothesis,reproducibility of results,significance testing,statistical,statistical  significance,statistical significance,statistics},
  language = {en},
  note = {\url{https://doi.org/10.1093/aje/kwx261}},
  number = {6},
  pmid = {[object Object]}
}

@article{leekStatisticsValuesAre2015,
  title = {Statistics: {{P}} Values Are Just the Tip of the Iceberg},
  shorttitle = {Statistics},
  author = {Leek, Jeffrey T. and Peng, Roger D.},
  year = {2015},
  month = apr,
  volume = {520},
  pages = {612},
  doi = {10.1038/520612a},
  abstract = {Ridding science of shoddy statistics will require scrutiny of every step, not merely the last one, say Jeffrey T. Leek and Roger D. Peng.},
  file = {/Users/zad/Zotero/storage/3H7HW7E6/Leek_Peng_2015_Statistics.pdf;/Users/zad/Zotero/storage/6WFHCXA3/Leek and Peng - 2015 - Statistics iPi values are just the tip of th.html},
  journal = {Nature News},
  language = {en},
  note = {\url{https://doi.org/10.1038/520612a}},
  number = {7549}
}

@book{lehmannMinimaxPrinciple1986,
  title = {The {{Minimax Principle}}},
  author = {Lehmann, E. L},
  year = {1986},
  annotation = {OCLC: 7329112449},
  file = {/Users/zad/Zotero/storage/XMHI8SUI/Lehmann - 1986 - The Minimax Principle.pdf},
  language = {en}
}

@book{littleStatisticalAnalysisMissing2019,
  title = {Statistical Analysis with Missing Data},
  author = {Little, Roderick J. A. and Rubin, Donald B.},
  year = {2019},
  edition = {Third edition},
  publisher = {{Wiley}},
  address = {{Hoboken, NJ}},
  file = {/Users/zad/Zotero/storage/UTT5CWG4/Little and Rubin - 2019 - Statistical analysis with missing data.pdf},
  isbn = {978-1-118-59601-2 978-1-118-59569-5},
  keywords = {Mathematical statistics,Missing observations (Statistics),Problems; exercises; etc},
  language = {en},
  lccn = {QA276},
  series = {Wiley Series in Probability and Statistics}
}

@article{matthewsMovingPost052019,
  title = {Moving {{Towards}} the {{Post}} p {$<$} 0.05 {{Era}} via the {{Analysis}} of {{Credibility}}},
  author = {Matthews, Robert A. J.},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {202--212},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10/gf4j2d},
  abstract = {It is now widely accepted that the techniques of null hypothesis significance testing (NHST) are routinely misused and misinterpreted by researchers seeking insight from data. There is, however, no consensus on acceptable alternatives, leaving researchers with little choice but to continue using NHST, regardless of its failings. I examine the potential for the Analysis of Credibility (AnCred) to resolve this impasse. Using real-life examples, I assess the ability of AnCred to provide researchers with a simple but robust framework for assessing study findings that goes beyond the standard dichotomy of statistical significance/nonsignificance. By extracting more insight from standard summary statistics while offering more protection against inferential fallacies, AnCred may encourage researchers to move toward the post p {$<$} 0.05 era.},
  annotation = {\_eprint: https://doi.org/10.1080/00031305.2018.1543136},
  file = {/Users/zad/Zotero/storage/S4D8UMKA/Matthews_2019_Moving Towards the Post p 0.pdf;/Users/zad/Zotero/storage/U6H5BDV8/00031305.2018.html},
  journal = {The American Statistician},
  keywords = {Analysis of credibility,Bayesian inference,Null hypothesis Significance testing,p-Values},
  note = {\url{https://doi.org/10.1080/00031305.2018.1543136}},
  number = {sup1}
}

@book{mayoStatisticalInferenceSevere2018,
  title = {Statistical {{Inference}} as {{Severe Testing}}: {{How}} to {{Get Beyond}} the {{Statistics Wars}}},
  shorttitle = {Statistical {{Inference}} as {{Severe Testing}}},
  author = {Mayo, Deborah G.},
  year = {2018},
  month = sep,
  publisher = {{Cambridge University Press}},
  abstract = {Mounting failures of replication in social and biological sciences give a new urgency to critically appraising proposed reforms. This book pulls back the cover on disagreements between experts charged with restoring integrity to science. It denies two pervasive views of the role of probability in inference: to assign degrees of belief, and to control error rates in a long run. If statistical consumers are unaware of assumptions behind rival evidence reforms, they can't scrutinize the consequences that affect them (in personalized medicine, psychology, etc.). The book sets sail with a simple tool: if little has been done to rule out flaws in inferring a claim, then it has not passed a severe test. Many methods advocated by data experts do not stand up to severe scrutiny and are in tension with successful strategies for blocking or accounting for cherry picking and selective reporting. Through a series of excursions and exhibits, the philosophy and history of inductive inference come alive. Philosophical tools are put to work to solve problems about science and pseudoscience, induction and falsification.},
  googlebooks = {t6wKtAEACAAJ},
  isbn = {978-1-107-05413-4},
  keywords = {Mathematics / Probability \& Statistics / General,Science / Philosophy \& Social Aspects},
  language = {en},
  note = {\url{https://doi.org/10.1017/9781107286184}}
}

@article{mccormackHowConfidenceIntervals2013,
  title = {How Confidence Intervals Become Confusion Intervals},
  author = {McCormack, James and Vandermeer, Ben and Allan, G. Michael},
  year = {2013},
  month = oct,
  volume = {13},
  pages = {134},
  issn = {1471-2288},
  doi = {10.1186/1471-2288-13-134},
  abstract = {Controversies are common in medicine. Some arise when the conclusions of research publications directly contradict each other, creating uncertainty for frontline clinicians.},
  file = {/Users/zad/Google Drive/Research/Zotero/BMC Medical Research Methodology/2013/McCormack et al_2013_How confidence intervals become confusion intervals.pdf},
  journal = {BMC Medical Research Methodology},
  note = {\url{https://doi.org/10.1186/1471-2288-13-134}},
  number = {1}
}

@article{mcshaneAbandonStatisticalSignificance2019,
  ids = {mcshane2019as},
  title = {Abandon {{Statistical Significance}}},
  author = {McShane, Blakeley B. and Gal, David and Gelman, Andrew and Robert, Christian and Tackett, Jennifer L.},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {235--245},
  issn = {0003-1305},
  doi = {10.1080/00031305.2018.1527253},
  abstract = {We discuss problems the null hypothesis significance testing (NHST) paradigm poses for replication and more broadly in the biomedical and social sciences as well as how these problems remain unresolved by proposals involving modified p-value thresholds, confidence intervals, and Bayes factors. We then discuss our own proposal, which is to abandon statistical significance. We recommend dropping the NHST paradigm\textemdash and the p-value thresholds intrinsic to it\textemdash as the default statistical paradigm for research, publication, and discovery in the biomedical and social sciences. Specifically, we propose that the p-value be demoted from its threshold screening role and instead, treated continuously, be considered along with currently subordinate factors (e.g., related prior evidence, plausibility of mechanism, study design and data quality, real world costs and benefits, novelty of finding, and other factors that vary by research domain) as just one among many pieces of evidence. We have no desire to ``ban'' p-values or other purely statistical measures. Rather, we believe that such measures should not be thresholded and that, thresholded or not, they should not take priority over the currently subordinate factors. We also argue that it seldom makes sense to calibrate evidence as a function of p-values or other purely statistical measures. We offer recommendations for how our proposal can be implemented in the scientific publication process as well as in statistical decision making more broadly.},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/McShane et al_2019_Abandon Statistical Significance.pdf;/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/McShane et al_2019_Abandon Statistical Significance2.pdf},
  journal = {The American Statistician},
  keywords = {Null hypothesis significance testing,p-Value,Replication,Sociology of science,Statistical significance},
  note = {\url{https://doi.org/10.1080/00031305.2018.1527253}},
  number = {sup1}
}

@article{mcshaneStatisticalSignificanceDichotomization2017,
  title = {Statistical Significance and the Dichotomization of Evidence},
  author = {McShane, Blakeley B. and Gal, David},
  year = {2017},
  month = jul,
  volume = {112},
  pages = {885--895},
  issn = {0162-1459},
  doi = {10.1080/01621459.2017.1289846},
  abstract = {In light of recent concerns about reproducibility and replicability, the ASA issued a Statement on Statistical Significance and p-values aimed at those who are not primarily statisticians. While the ASA Statement notes that statistical significance and p-values are ``commonly misused and misinterpreted,'' it does not discuss and document broader implications of these errors for the interpretation of evidence. In this article, we review research on how applied researchers who are not primarily statisticians misuse and misinterpret p-values in practice and how this can lead to errors in the interpretation of evidence. We also present new data showing, perhaps surprisingly, that researchers who are primarily statisticians are also prone to misuse and misinterpret p-values thus resulting in similar errors. In particular, we show that statisticians tend to interpret evidence dichotomously based on whether or not a p-value crosses the conventional 0.05 threshold for statistical significance. We discuss implications and offer recommendations.},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of the American Statistical Association/2017/McShane_Gal_2017_Statistical Significance and the Dichotomization of Evidence.pdf},
  journal = {Journal of the American Statistical Association},
  note = {\url{https://doi.org/10.1080/01621459.2017.1289846}},
  number = {519}
}

@article{moreyFallacyPlacingConfidence2016,
  title = {The Fallacy of Placing Confidence in Confidence Intervals},
  author = {Morey, Richard D. and Hoekstra, Rink and Rouder, Jeffrey N. and Lee, Michael D. and Wagenmakers, Eric-Jan},
  year = {2016},
  month = feb,
  volume = {23},
  pages = {103--123},
  issn = {1531-5320},
  doi = {10.3758/s13423-015-0947-8},
  abstract = {Interval estimates \textendash{} estimates of parameters that include an allowance for sampling uncertainty \textendash{} have long been touted as a key component of statistical analyses. There are several kinds of interval estimates, but the most popular are confidence intervals (CIs): intervals that contain the true parameter value in some known proportion of repeated samples, on average. The width of confidence intervals is thought to index the precision of an estimate; CIs are thought to be a guide to which parameter values are plausible or reasonable; and the confidence coefficient of the interval (e.g., 95 \%) is thought to index the plausibility that the true parameter is included in the interval. We show in a number of examples that CIs do not necessarily have any of these properties, and can lead to unjustified or arbitrary inferences. For this reason, we caution against relying upon confidence interval theory to justify interval estimates, and suggest that other theories of interval estimation should be used instead.},
  file = {/Users/zad/Google Drive/Research/Zotero/Psychonomic Bulletin & Review/2016/Morey et al_2016_The fallacy of placing confidence in confidence intervals.pdf},
  journal = {Psychonomic Bulletin \& Review},
  keywords = {Bayesian inference and parameter estimation,Bayesian statistics,Statistical inference,Statistics},
  language = {en},
  note = {\url{https://doi.org/10.3758/s13423-015-0947-8}},
  number = {1}
}

@article{moskowitzFasterthanlightNeutrinosAren2012,
  title = {Faster-than-Light Neutrinos Aren't},
  author = {Moskowitz, Clara},
  year = {2012},
  month = jun,
  abstract = {The same lab that first reported the shocking results last year, which could have upended modern physics, now reports that neutrinos "respect the cosmic speed limit"},
  journal = {Scientific American},
  language = {en},
  note = {\url{https://scientificamerican.com/article/faster-than-light-neutrin/}}
}

@article{naimiCanConfidenceIntervals,
  title = {Can {{Confidence Intervals Be Interpreted}}?},
  author = {Naimi, Ashley I. and Whitcomb, Brian W.},
  doi = {10/ggskqq},
  abstract = {The confidence interval is a fundamental tool for quantifying uncertainty due to sampling associated with a point estimate. However, the manner in which that un},
  file = {/Users/zad/Zotero/storage/VXTY3LIN/Naimi_Whitcomb_Can Confidence Intervals Be Interpreted.pdf;/Users/zad/Zotero/storage/2HUZ46UY/5717184.html},
  journal = {American Journal of Epidemiology},
  language = {en},
  note = {\url{https://academic.oup.com/aje/article/doi/10.1093/aje/kwaa004/5717184}}
}

@book{obrienPioneersModernEconomics2016,
  title = {Pioneers of {{Modern Economics}} in {{Britain}}},
  author = {O'Brien, D. P. and Presley, John R.},
  year = {2016},
  month = jan,
  publisher = {{Springer}},
  file = {/Users/zad/Google Drive/Research/Zotero/Springer/2016/O'Brien_Presley_2016_Pioneers of Modern Economics in Britain.pdf},
  googlebooks = {JuheCwAAQBAJ},
  isbn = {978-1-349-06912-5},
  keywords = {Business \& Economics / Economic History,Business \& Economics / Economics / General},
  language = {en},
  note = {\url{https://doi.org/10.1007/978-1-349-09376-2}}
}

@article{Open_Science_Collaboration2015-ph,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  year = {2015},
  month = aug,
  volume = {349},
  pages = {aac4716},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aac4716},
  abstract = {Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  file = {/Users/zad/Google Drive/Research/Zotero/Science/2015/Open Science Collaboration_2015_Estimating the reproducibility of psychological science.pdf},
  journal = {Science},
  language = {English},
  note = {\url{https://doi.org/10.1126/science.aac4716}},
  number = {6251},
  pmid = {26315443}
}

@book{parmigianiDecisionTheoryPrinciples2009,
  title = {Decision {{Theory}}: {{Principles}} and {{Approaches}}},
  shorttitle = {Decision {{Theory}}},
  author = {Parmigiani, Giovanni and Inoue, Lurdes},
  year = {2009},
  month = apr,
  publisher = {{John Wiley \& Sons}},
  abstract = {Decision theory provides a formal framework for making logical choices in the face of uncertainty. Given a set of alternatives, a set of consequences, and a correspondence between those sets, decision theory offers conceptually simple procedures for choice. This book presents an overview of the fundamental concepts and outcomes of rational decision making under uncertainty, highlighting the implications for statistical practice.   The authors have developed a series of self contained chapters focusing on bridging the gaps between the different fields that have contributed to rational decision making and presenting ideas in a unified framework and notation while respecting and highlighting the different and sometimes conflicting perspectives.   This book:  * Provides a rich collection of techniques and procedures. * Discusses the foundational aspects and modern day practice. * Links foundations to practical applications in biostatistics, computer science, engineering and economics. * Presents different perspectives and controversies to encourage readers to form their own opinion of decision making and statistics.   Decision Theory is fundamental to all scientific disciplines, including biostatistics, computer science, economics and engineering. Anyone interested in the whys and wherefores of statistical science will find much to enjoy in this book.},
  file = {/Users/zad/Google Drive/Research/Zotero/John Wiley & Sons/2009/Parmigiani_Inoue_2009_Decision Theory.pdf},
  googlebooks = {mnjGCYqWj7EC},
  isbn = {978-0-470-74667-7},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  language = {en},
  note = {\url{https://doi.org/10.1002/9780470746684}}
}

@article{pearsonCriterionThatGiven1900,
  title = {X. {{On}} the Criterion That a given System of Deviations from the Probable in the Case of a Correlated System of Variables Is Such That It Can Be Reasonably Supposed to Have Arisen from Random Sampling},
  author = {Pearson, Karl},
  year = {1900},
  volume = {50},
  pages = {157--175},
  doi = {10.1080/14786440009463897},
  file = {/Users/zad/Google Drive/Research/Zotero/The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science/1900/Pearson_1900_X.pdf},
  journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  note = {\url{https://doi.org/10.1080/14786440009463897}},
  number = {302}
}

@article{pearsonNoteSignificantNonsignificant1906,
  title = {V. {{Note}} on the {{Significant}} or {{Non}}-Significant Character of a {{Sub}}-Sample Drawn from a {{Sample}}},
  author = {Pearson, Karl},
  year = {1906},
  month = oct,
  volume = {5},
  pages = {181--183},
  issn = {0006-3444},
  doi = {10/dqbv8j},
  journal = {Biometrika},
  note = {\url{https://doi.org/10.1093/biomet/5.1-2.181}},
  number = {1-2}
}

@article{perezgonzalezPvaluesPercentilesCommentary2015,
  title = {P-Values as Percentiles. {{Commentary}} on: ``{{Null}} Hypothesis Significance Tests. {{A}} Mix\textendash up of Two Different Theories: The Basis for Widespread Confusion and Numerous Misinterpretations''},
  shorttitle = {P-Values as Percentiles. {{Commentary}} On},
  author = {Perezgonzalez, Jose D.},
  year = {2015},
  volume = {6},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2015.00341},
  abstract = {P-values as percentiles. Commentary on: ``Null hypothesis significance tests. A mix\textendash up of two different theories: the basis for widespread confusion and numerous misinterpretations''},
  file = {/Users/zad/Google Drive/Research/Zotero/Frontiers in Psychology/2015/Perezgonzalez_2015_P-values as percentiles.pdf},
  journal = {Frontiers in Psychology},
  keywords = {P-values,Percentiles,Probability,Significance testing,Statistical misinterpretations},
  language = {English},
  note = {\url{https://doi.org/10.3389/fpsyg.2015.00341}}
}

@article{Poole1987-nb,
  title = {Beyond the Confidence Interval},
  author = {Poole, Charles},
  year = {1987},
  month = feb,
  volume = {77},
  pages = {195--199},
  issn = {0090-0036},
  doi = {10.2105/AJPH.77.2.195},
  file = {/Users/zad/Google Drive/Research/Zotero/American Journal of Public Health/1987/Poole_1987_Beyond the confidence interval.pdf},
  journal = {American Journal of Public Health},
  language = {English},
  note = {\url{https://doi.org/10.2105/AJPH.77.2.195}},
  number = {2},
  pmc = {PMC1646825},
  pmid = {3799860}
}

@article{pooleConfidenceIntervalsExclude1987,
  title = {Confidence Intervals Exclude Nothing.},
  author = {Poole, Charles},
  year = {1987},
  month = apr,
  volume = {77},
  pages = {492--493},
  issn = {0090-0036},
  doi = {10.2105/ajph.77.4.492},
  file = {/Users/zad/Google Drive/Research/Zotero/American Journal of Public Health/1987/Poole_1987_Confidence intervals exclude nothing.pdf},
  journal = {American Journal of Public Health},
  note = {\url{https://doi.org/10.2105/ajph.77.4.492}},
  number = {4},
  pmcid = {PMC1646956},
  pmid = {2950780}
}

@book{popperLogicScientificDiscovery1959,
  title = {The {{Logic}} of {{Scientific Discovery}}},
  author = {Popper, Karl Raimund},
  year = {1959},
  publisher = {{Basic Books}},
  address = {{New York}},
  abstract = {Described by the philosopher A.J. Ayer as a work of 'great originality and power', this book revolutionized contemporary thinking on science and knowledge. Ideas such as the now legendary doctrine of 'falsificationism' electrified the scientific community, influencing even working scientists, as well as post-war philosophy. This astonishing work ranks alongside The Open Society and Its Enemies as one of Popper's most enduring books and contains insights and arguments that demand to be read to this day.},
  keywords = {Philosophy / Logic,Science / Philosophy \& Social Aspects},
  language = {en}
}

@article{quineMainTrendsRecent1951,
  title = {Main {{Trends}} in {{Recent Philosophy}}: {{Two Dogmas}} of {{Empiricism}}},
  shorttitle = {Main {{Trends}} in {{Recent Philosophy}}},
  author = {Quine, W. V.},
  year = {1951},
  volume = {60},
  pages = {20--43},
  publisher = {{[Duke University Press, Philosophical Review]}},
  issn = {0031-8108},
  doi = {10/bks5sm},
  journal = {The Philosophical Review},
  note = {\url{https://www.jstor.org/stable/2181906}},
  number = {1}
}

@misc{rafiConcurveComputesPlots2020,
  title = {Concurve: {{Computes}} and {{Plots Consonance}} ({{Confidence}}) {{Intervals}}, {{P}}-{{Values}}, and {{S}}-{{Values}} to {{Form Consonance}} and {{Surprisal Functions}}},
  shorttitle = {Concurve},
  author = {Rafi, Zad and Vigotsky, Andrew David},
  year = {2020},
  month = apr,
  abstract = {Allows one to compute consonance (confidence) intervals for various statistical tests along with their corresponding P-values and S-values. The intervals can be plotted to create consonance and surprisal functions allowing one to see what effect sizes are compatible with the test model at various consonance levels rather than being limited to one interval estimate such as 95\%. These methods are discussed by Poole C. (1987) {$<$}doi:10.2105/AJPH.77.2.195{$>$}, Schweder T, Hjort NL. (2002) {$<$}doi:10.1111/1467-9469.00285{$>$}, Singh K, Xie M, Strawderman WE. (2007) {$<$}arXiv:0708.0976{$>$}, Rothman KJ, Greenland S, Lash TL. (2008, ISBN:9781451190052), Amrhein V, Trafimow D, Greenland S. (2019) {$<$}doi:10.1080/00031305.2018.1543137{$>$}, Greenland S. (2019) {$<$}doi:10.1080/00031305.2018.1529625{$>$}, Chow ZR, Greenland S. (2019) {$<$}arXiv:1909.08579{$>$}, and Greenland S, Chow ZR. (2019) {$<$}arXiv:1909.08583{$>$}.},
  copyright = {GPL-3 | file LICENSE},
  howpublished = {CRAN},
  note = {\url{https://cran.r-project.org/package=concurve}}
}

@article{rafiMisplacedConfidenceObserved2020,
  title = {Misplaced {{Confidence}} in {{Observed Power}}},
  author = {Rafi, Zad},
  year = {2020},
  abstract = {A recently published randomized controlled trial in JAMA investigated the impact of the selective serotonin reuptake inhibitors, escitalopram, on the risk of major adverse events (MACE). The authors estimated a hazard ratio (HR) of 0.69 and further calculated how much statistical power their test had, using this to assess how reliable their results were. Here, we discuss why this approach is highly misleading.},
  archivePrefix = {arXiv},
  copyright = {All rights reserved},
  eprint = {1907.08242},
  eprinttype = {arxiv},
  file = {/Users/zad/Google Drive/Research/Zotero/arXiv1907.08242 [stat]/2019/Chow_2019_Misplaced Confidence in Observed Power.pdf;/Users/zad/Google Drive/Research/Zotero/arXiv1907.08242 [stat]/2019/Chow_2019_Misplaced Confidence in Observed Power2.pdf},
  journal = {arXiv:1907.08242 [stat]},
  keywords = {⛔ No DOI found,Statistics - Applications,Statistics - Methodology},
  note = {\url{http://arxiv.org/abs/1907.08242}},
  primaryClass = {stat}
}

@article{rafiSemanticCognitiveTools2020,
  title = {Semantic and Cognitive Tools to Aid Statistical Science: Replace Confidence and Significance by Compatibility and Surprise},
  author = {Rafi, Zad and Greenland, Sander},
  year = {2020},
  month = sep,
  volume = {20},
  pages = {244},
  issn = {1471-2288},
  doi = {10.1186/s12874-020-01105-9},
  abstract = {Researchers often misinterpret and misrepresent statistical outputs. This abuse has led to a large literature on modification or replacement of testing thresholds and P-values with confidence intervals, Bayes factors, and other devices. Because the core problems appear cognitive rather than statistical, we review some simple methods to aid researchers in interpreting statistical outputs. These methods emphasize logical and information concepts over probability, and thus may be more robust to common misinterpretations than are traditional descriptions.},
  copyright = {All rights reserved},
  file = {/Users/zad/Zotero/storage/Z3T9K3DT/Rafi_Greenland_2020_Semantic and cognitive tools to aid statistical science.pdf},
  journal = {BMC Medical Research Methodology},
  note = {\url{https://doi.org/10.1186/s12874-020-01105-9}},
  number = {1}
}

@misc{rafiShowSurpriseScripts2019,
  title = {Show of {{Surprise Scripts}}},
  author = {Rafi, Zad R.},
  year = {2019},
  month = jul,
  abstract = {Repository of Scripts and Figures for "The Show of Surprise" Manuscript by Chow \& Greenland, 2019      Hosted on the Open Science Framework},
  howpublished = {\url{https://osf.io/6w8g9/}},
  language = {en}
}

@misc{rafiSurprisalScript2019,
  title = {Surprisal\_script.{{R}}},
  author = {Rafi, Zad},
  year = {2019},
  month = jul,
  doi = {10.6084/m9.figshare.9202211.v1},
  abstract = {R script used to generate Tables 1 and 2 and Figures 3 and 4},
  howpublished = {\url{https://figshare.com/articles/surprisal_script_R/9202211}},
  keywords = {p-value functions,p-values,R,s-value functions,s-values}
}

@article{robinsAsymptoticDistributionValues2000,
  title = {Asymptotic {{Distribution}} of {{P Values}} in {{Composite Null Models}}},
  author = {Robins, James M. and {van der Vaart}, Aad and Ventura, Val{\'e}Rie},
  year = {2000},
  month = dec,
  volume = {95},
  pages = {1143--1156},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10/gg7krv},
  journal = {Journal of the American Statistical Association},
  note = {\url{https://doi.org/10.1080/01621459.2000.10474310}},
  number = {452}
}

@article{robinsConditioningLikelihoodCoherence2000,
  title = {Conditioning, Likelihood, and Coherence: {{A}} Review of Some Foundational Concepts},
  shorttitle = {Conditioning, {{Likelihood}}, and {{Coherence}}},
  author = {Robins, James and Wasserman, Larry},
  year = {2000},
  month = dec,
  volume = {95},
  pages = {1340--1346},
  issn = {0162-1459},
  doi = {10.1080/01621459.2000.10474344},
  file = {/Users/zad/Google Drive/Research/Zotero/Journal of the American Statistical Association/2000/Robins_Wasserman_2000_Conditioning, Likelihood, and Coherence.pdf},
  journal = {Journal of the American Statistical Association},
  note = {\url{https://doi.org/10.1080/01621459.2000.10474344}},
  number = {452}
}

@article{Rothman2018-tf,
  title = {Planning Study Size Based on Precision Rather than Power},
  author = {Rothman, Kenneth J. and Greenland, Sander},
  year = {2018},
  month = sep,
  volume = {29},
  pages = {599--603},
  issn = {1044-3983, 1531-5487},
  doi = {10.1097/EDE.0000000000000876},
  abstract = {Study size has typically been planned based on statistical power and therefore has been heavily influenced by the philosophy of statistical hypothesis testing. A worthwhile alternative is to plan study size based on precision, for example by aiming to obtain a desired width of a confidence interval for the targeted effect. This article presents formulas for planning the size of an epidemiologic study based on the desired precision of the basic epidemiologic effect measures.},
  affiliation = {From the Research Triangle Institute, Research Triangle Park, NC. Boston University School of Public Health, Boston, MA. Department of Epidemiology and Department of Statistics, University of California, Los Angeles, CA.},
  file = {/Users/zad/Google Drive/Research/Zotero/Epidemiology/2018/Rothman_Greenland_2018_Planning study size based on precision rather than power.pdf},
  journal = {Epidemiology},
  keywords = {Precision},
  language = {English},
  note = {\url{https://doi.org/10.1097/EDE.0000000000000876}},
  number = {5},
  pmid = {29912015}
}

@misc{rothmanEpisheet,
  title = {Episheet},
  author = {Rothman, Kenneth J.},
  howpublished = {\url{http://krothman.org/episheet.xls}}
}

@article{rothmanFlutamideEffectivePatients1999,
  title = {Is Flutamide Effective in Patients with Bilateral Orchiectomy?},
  author = {Rothman, Kenneth J. and Johnson, Eric S. and Sugano, David S.},
  year = {1999},
  month = apr,
  volume = {353},
  pages = {1184},
  publisher = {{Elsevier}},
  issn = {0140-6736, 1474-547X},
  doi = {10.1016/s0140-6736(05)74403-2},
  abstract = {In 1995, the Prostate Cancer Trialists' Collaborative Group published an overview of randomised trials of androgen blockade in the treatment of advanced prostate cancer.1 Ten of these trials addressed the efficacy of androgen blockade combined with flutamide. The results from these ten studies indicated an overall small survival advantage to patients who received flutamide; the pooled results for 1546 patients receiving flutamide and 1542 on placebo give a summary odds ratio (OR) for the ten studies of 0{$\cdot$}88 (95\% CI 0{$\cdot$}76\textendash 1{$\cdot$}02; Mantel Haenszel test),2 corresponding to a 12\% benefit in the odds of surviving for patients who received flutamide.},
  file = {/Users/zad/Zotero/storage/ZS7IUFVB/Rothman et al_1999_Is flutamide effective in patients with bilateral orchiectomy.pdf;/Users/zad/Zotero/storage/5MCACXDN/fulltext.html},
  journal = {The Lancet},
  language = {English},
  note = {\url{https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(05)74403-2/abstract}},
  number = {9159},
  pmid = {10210003}
}

@book{rothmanModernEpidemiology2008,
  title = {Modern {{Epidemiology}}},
  author = {Rothman, Kenneth J. and Greenland, Sander and Lash, Timothy L.},
  year = {2008},
  edition = {3rd},
  publisher = {{Lippincott Williams \& Wilkins}},
  abstract = {The thoroughly revised and updated Third Edition of the acclaimed Modern Epidemiology reflects both the conceptual development of this evolving science and the increasingly focal role that epidemiology plays in dealing with public health and medical problems. Coauthored by three leading epidemiologists, with sixteen additional contributors, this Third Edition is the most comprehensive and cohesive text on the principles and methods of epidemiologic research. The book covers a broad range of concepts and methods, such as basic measures of disease frequency and associations, study design, field methods, threats to validity, and assessing precision. It also covers advanced topics in data analysis such as Bayesian analysis, bias analysis, and hierarchical regression. Chapters examine specific areas of research such as disease surveillance, ecologic studies, social epidemiology, infectious disease epidemiology, genetic and molecular epidemiology, nutritional epidemiology, environmental epidemiology, reproductive epidemiology, and clinical epidemiology.},
  googlebooks = {Z3vjT9ALxHUC},
  isbn = {978-0-7817-5564-1},
  keywords = {Medical / Education \& Training,Medical / Epidemiology,Medical / Infectious Diseases,Medical / Occupational \& Industrial Medicine,Medical / Public Health,Medical / Test Preparation \& Review},
  language = {en},
  note = {\url{https://books.google.com/books/about/Modern_Epidemiology.html?id=Z3vjT9ALxHUC}}
}

@incollection{rothmanPrecisionStatisticsEpidemiologic2008,
  title = {Precision and Statistics in Epidemiologic Studies},
  booktitle = {Modern {{Epidemiology}}},
  author = {Rothman, Kenneth J. and Greenland, Sander and Lash, Timothy L.},
  editor = {Rothman, Kenneth J. and Greenland, Sander and Lash, Timothy L.},
  year = {2008},
  edition = {3rd},
  pages = {148--167},
  publisher = {{Lippincott Williams \& Wilkins}},
  abstract = {The thoroughly revised and updated Third Edition of the acclaimed Modern Epidemiology reflects both the conceptual development of this evolving science and the increasingly focal role that epidemiology plays in dealing with public health and medical problems. Coauthored by three leading epidemiologists, with sixteen additional contributors, this Third Edition is the most comprehensive and cohesive text on the principles and methods of epidemiologic research. The book covers a broad range of concepts and methods, such as basic measures of disease frequency and associations, study design, field methods, threats to validity, and assessing precision. It also covers advanced topics in data analysis such as Bayesian analysis, bias analysis, and hierarchical regression. Chapters examine specific areas of research such as disease surveillance, ecologic studies, social epidemiology, infectious disease epidemiology, genetic and molecular epidemiology, nutritional epidemiology, environmental epidemiology, reproductive epidemiology, and clinical epidemiology.},
  googlebooks = {Z3vjT9ALxHUC},
  isbn = {978-0-7817-5564-1},
  keywords = {Medical / Education \& Training,Medical / Epidemiology,Medical / Infectious Diseases,Medical / Occupational \& Industrial Medicine,Medical / Public Health,Medical / Test Preparation \& Review},
  language = {en},
  note = {\url{https://books.google.com/books/about/Modern_Epidemiology.html?id=Z3vjT9ALxHUC}}
}

@article{rothmanShowConfidence1978,
  title = {A Show of Confidence},
  author = {Rothman, Kenneth J.},
  year = {1978},
  month = dec,
  volume = {299},
  pages = {1362--1363},
  issn = {0028-4793},
  doi = {10.1056/NEJM197812142992410},
  abstract = {Many medical researchers believe that it would be fruitless to submit for publication any paper that lacks statistical tests of significance. Their belief is not ill founded: editors and referees commonly rely on tests of significance as indicators of a sophisticated and meaningful statistical analysis, as well as the primary means to assess sampling variability in a study. The preoccupation with significance tests is embodied in the focus on whether the P value is less than 0.05; results are considered "significant" or "not significant" according to whether or not the P value is less than or greater than 0.05. Dr. . . .},
  file = {/Users/zad/Google Drive/Research/Zotero/New England Journal of Medicine/1978/Rothman_1978_A show of confidence.pdf},
  journal = {New England Journal of Medicine},
  note = {\url{https://doi.org/10.1056/NEJM197812142992410}},
  number = {24},
  pmid = {362205}
}

@article{rothmanSignificanceQuesting1986,
  title = {Significance {{Questing}}},
  author = {Rothman, Kenneth J.},
  year = {1986},
  month = sep,
  volume = {105},
  pages = {445--447},
  publisher = {{American College of Physicians}},
  issn = {0003-4819},
  doi = {10.7326/0003-4819-105-3-445},
  file = {/Users/zad/Zotero/storage/4LIU5GGJ/Rothman_1986_Significance Questing.pdf;/Users/zad/Zotero/storage/3QGK9A5K/0003-4819-105-3-445.html},
  journal = {Annals of Internal Medicine},
  note = {\url{https://doi.org/10.7326/0003-4819-105-3-445}},
  number = {3}
}

@article{rothmanTakenSurprise2020,
  title = {Taken by {{Surprise}}},
  author = {Rothman, Kenneth J.},
  year = {2020},
  month = jul,
  doi = {10/gg63mf},
  abstract = {Abstract.  P values are often taken to be something they are not, a probability measure regarding the truth of the null hypothesis. P values work well if we int},
  file = {/Users/zad/Zotero/storage/UGVZHEQX/5869592.html},
  journal = {American Journal of Epidemiology},
  language = {en},
  note = {\url{https://academic.oup.com/aje/article/doi/10.1093/aje/kwaa137/5869592}}
}

@book{royallStatisticalEvidenceLikelihood1997,
  ids = {royall1997a},
  title = {Statistical {{Evidence}}: {{A Likelihood Paradigm}}},
  shorttitle = {Statistical {{Evidence}}},
  author = {Royall, Richard},
  year = {1997},
  month = jun,
  publisher = {{CRC Press}},
  abstract = {Interpreting statistical data as evidence, Statistical Evidence: A Likelihood Paradigm focuses on the law of likelihood, fundamental to solving many of the problems associated with interpreting data in this way. Statistics has long neglected this principle, resulting in a seriously defective methodology. This book redresses the balance, explaining why science has clung to a defective methodology despite its well-known defects. After examining the strengths and weaknesses of the work of Neyman and Pearson and the Fisher paradigm, the author proposes an alternative paradigm which provides, in the law of likelihood, the explicit concept of evidence missing from the other paradigms. At the same time, this new paradigm retains the elements of objective measurement and control of the frequency of misleading results, features which made the old paradigms so important to science. The likelihood paradigm leads to statistical methods that have a compelling rationale and an elegant simplicity, no longer forcing the reader to choose between frequentist and Bayesian statistics.},
  file = {/Users/zad/Zotero/storage/LRDKQG32/Royall - 1997 - Statistical evidence a likelihood paradigm.pdf},
  googlebooks = {[object Object]},
  isbn = {978-0-412-04411-3},
  keywords = {Estimation theory,Mathematical statistics,Mathematics / Probability \& Statistics / General,Probabilities},
  language = {en}
}

@misc{rubensteinNewLowDrug2009,
  title = {A {{New Low}} in {{Drug Research}}: 21 {{Fabricated Studies}}},
  shorttitle = {A {{New Low}} in {{Drug Research}}},
  author = {Rubenstein, Sarah},
  year = {2009},
  month = mar,
  abstract = {The researcher who allegedly faked the data has been influential in his field.},
  howpublished = {\url{https://blogs.wsj.com/health/2009/03/11/a-new-low-in-drug-research-21-fabricated-studies/}},
  journal = {WSJ},
  language = {en-US}
}

@book{rubinMATCHEDSAMPLINGCAUSAL2006,
  title = {{{MATCHED SAMPLING FOR CAUSAL EFFECTS}}},
  author = {Rubin, Donald B},
  year = {2006},
  file = {/Users/zad/Zotero/storage/2E4SGSL5/Rubin - 2006 - MATCHED SAMPLING FOR CAUSAL EFFECTS.pdf},
  keywords = {❓ Multiple DOI},
  language = {en}
}

@article{ruckerForestPlotDrapery2020,
  title = {Beyond the Forest Plot: {{The}} Drapery Plot},
  shorttitle = {Beyond the Forest Plot},
  author = {R{\"u}cker, Gerta and Schwarzer, Guido},
  year = {2020},
  month = apr,
  issn = {1759-2887},
  doi = {10.1002/jrsm.1410},
  abstract = {In the era of the ``reproducibility crisis'' and the ``P-value controversy'' new ways of presentation and interpretation of the results of a meta-analysis are desirable. One suggestion that has been made for single studies almost six decades ago and taken up now and then is the P-value function. For a given outcome, this function assigns a P-value to each possible hypothetical value, given the data. Moreover, the P-value function simultaneously provides two-sided confidence intervals for all possible alpha levels. An application to meta-analysis, while suggested early, has not been widely established. We introduce the drapery plot that presents the P-value function for all individual studies and pooled estimates in a meta-analysis as curves and the prediction range for a single future study. We also present a scaled variant with the test statistic on the y-axis. Both plots visualize the full information of a pairwise meta-analysis. We see a drapery plot as a complementary figure to a forest plot. It may be even an alternative in meta-analyses with many studies where forest plots tend to become very large and complex. This article is protected by copyright. All rights reserved.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jrsm.1410},
  copyright = {This article is protected by copyright. All rights reserved.},
  file = {/Users/zad/Zotero/storage/YSQMTW54/Rücker_Schwarzer_Beyond the forest plot.pdf;/Users/zad/Zotero/storage/ZKFKWL45/jrsm.html},
  journal = {Research Synthesis Methods},
  keywords = {drapery plot,forest plot,meta-analysis,P-value,P-value curve,reproducibility},
  language = {en},
  note = {\url{https://doi.org/10.1002/jrsm.1410}}
}

@article{saltelliFiveWaysEnsure2020,
  title = {Five Ways to Ensure That Models Serve Society: A Manifesto},
  shorttitle = {Five Ways to Ensure That Models Serve Society},
  author = {Saltelli, Andrea and Bammer, Gabriele and Bruno, Isabelle and Charters, Erica and Fiore, Monica Di and Didier, Emmanuel and Espeland, Wendy Nelson and Kay, John and Piano, Samuele Lo and Mayo, Deborah and Jr, Roger Pielke and Portaluri, Tommaso and Porter, Theodore M. and Puy, Arnald and Rafols, Ismael and Ravetz, Jerome R. and Reinert, Erik and Sarewitz, Daniel and Stark, Philip B. and Stirling, Andrew and van der Sluijs, Jeroen and Vineis, Paolo},
  year = {2020},
  month = jun,
  volume = {582},
  pages = {482--484},
  publisher = {{Nature Publishing Group}},
  doi = {10/gg27wg},
  abstract = {Pandemic politics highlight how predictions need to be transparent and humble to invite insight, not blame.},
  copyright = {2020 Nature},
  file = {/Users/zad/Zotero/storage/FABCNUIL/Saltelli et al_2020_Five ways to ensure that models serve society.pdf;/Users/zad/Zotero/storage/53WSJG6A/d41586-020-01812-9.html},
  journal = {Nature},
  language = {en},
  note = {\url{https://www.nature.com/articles/d41586-020-01812-9}},
  number = {7813}
}

@article{schmidtMistakenInferenceCaused2014,
  title = {Mistaken Inference Caused by Reliance on and Misinterpretation of a Significance Test},
  author = {Schmidt, Morten and Rothman, Kenneth J.},
  year = {2014},
  month = dec,
  volume = {177},
  pages = {1089--1090},
  issn = {1874-1754},
  doi = {10.1016/j.ijcard.2014.09.205},
  file = {/Users/zad/Google Drive/Research/Zotero/International Journal of Cardiology/2014/Schmidt_Rothman_2014_Mistaken inference caused by reliance on and misinterpretation of a.pdf},
  journal = {International Journal of Cardiology},
  keywords = {Anti-Inflammatory Agents; Non-Steroidal,Atrial fibrillation,Atrial Fibrillation,COX-2 inhibitors,Cyclooxygenase 2 Inhibitors,Data Interpretation; Statistical,Humans,Misinterpretation,Non-steroidal anti-inflammatory drugs,P-values,Pulmonary Disease; Chronic Obstructive,Renal Insufficiency; Chronic,Significance test},
  language = {eng},
  note = {\url{https://doi.org/10.1016/j.ijcard.2014.09.205}},
  number = {3},
  pmid = {25449519}
}

@article{schwederConfidenceLikelihood2002,
  ids = {Schweder2002-vh},
  title = {Confidence and {{Likelihood}}*},
  author = {Schweder, Tore and Hjort, Nils Lid},
  year = {2002},
  month = jun,
  volume = {29},
  pages = {309--332},
  issn = {0303-6898},
  doi = {10.1111/1467-9469.00285},
  abstract = {Confidence intervals for a single parameter are spanned by quantiles of a confidence distribution, and one-sided p-values are cumulative confidences. Confidence distributions are thus a unifying format for representing frequentist inference for a single parameter. The confidence distribution, which depends on data, is exact (unbiased) when its cumulative distribution function evaluated at the true parameter is uniformly distributed over the unit interval. A new version of the Neyman?Pearson lemma is given, showing that the confidence distribution based on the natural statistic in exponential models with continuous data is less dispersed than all other confidence distributions, regardless of how dispersion is measured. Approximations are necessary for discrete data, and also in many models with nuisance parameters. Approximate pivots might then be useful. A pivot based on a scalar statistic determines a likelihood in the parameter of interest along with a confidence distribution. This proper likelihood is reduced of all nuisance parameters, and is appropriate for meta-analysis and updating of information. The reduced likelihood is generally different from the confidence density. Confidence distributions and reduced likelihoods are rooted in Fisher?Neyman statistics. This frequentist methodology has many of the Bayesian attractions, and the two approaches are briefly compared. Concepts, methods and techniques of this brand of Fisher?Neyman statistics are presented. Asymptotics and bootstrapping are used to find pivots and their distributions, and hence reduced likelihoods and confidence distributions. A simple form of inverting bootstrap distributions to approximate pivots of the abc type is proposed. Our material is illustrated in a number of examples and in an application to multiple capture data for bowhead whales.},
  file = {/Users/zad/Google Drive/Research/Zotero/Scand J Stat/2002/Schweder_Hjort_2002_Confidence and Likelihood.pdf;/Users/zad/Google Drive/Research/Zotero/Scandinavian Journal of Statistics/2002/SCHWEDER_HJORT_2002_Confidence and Likelihood.pdf},
  journal = {Scandinavian Journal of Statistics},
  keywords = {abc correction,bootstrapping likelihoods,capture-recapture data,confidence distributions and densities,frequentist posteriors and priors,integrating information,Neyman–Pearson lemma,pivots,reduced likelihood},
  note = {\url{https://doi.org/10.1111/1467-9469.00285}},
  number = {2}
}

@book{schwederConfidenceLikelihoodProbability2016,
  title = {Confidence, {{Likelihood}}, {{Probability}}: {{Statistical Inference}} with {{Confidence Distributions}}},
  shorttitle = {Confidence, {{Likelihood}}, {{Probability}}},
  author = {Schweder, Tore and Hjort, Nils Lid},
  year = {2016},
  month = feb,
  publisher = {{Cambridge University Press}},
  abstract = {This lively book lays out a methodology of confidence distributions and puts them through their paces. Among other merits, they lead to optimal combinations of confidence from different sources of information, and they can make complex models amenable to objective and indeed prior-free analysis for less subjectively inclined statisticians. The generous mixture of theory, illustrations, applications and exercises is suitable for statisticians at all levels of experience, as well as for data-oriented scientists. Some confidence distributions are less dispersed than their competitors. This concept leads to a theory of risk functions and comparisons for distributions of confidence. Neyman\textendash Pearson type theorems leading to optimal confidence are developed and richly illustrated. Exact and optimal confidence distribution is the gold standard for inferred epistemic distributions. Confidence distributions and likelihood functions are intertwined, allowing prior distributions to be made part of the likelihood. Meta-analysis in likelihood terms is developed and taken beyond traditional methods, suiting it in particular to combining information across diverse data sources.},
  googlebooks = {t7KzCwAAQBAJ},
  isbn = {978-1-316-44505-1},
  keywords = {Business \& Economics / Econometrics,Business \& Economics / Economics / General,Mathematics / Probability \& Statistics / General},
  language = {en},
  note = {\url{https://books.google.com/books/about/Confidence_Likelihood_Probability.html?id=t7KzCwAAQBAJ}}
}

@article{sellkeCalibrationValuesTesting2001,
  title = {Calibration of {$\rho$} Values for Testing Precise Null Hypotheses},
  author = {Sellke, Thomas and Bayarri, M. J. and Berger, James O.},
  year = {2001},
  month = feb,
  volume = {55},
  pages = {62--71},
  issn = {0003-1305},
  doi = {10.1198/000313001300339950},
  abstract = {P values are the most commonly used tool to measure evidence against a hypothesis or hypothesized model. Unfortunately, they are often incorrectly viewed as an error probability for rejection of the hypothesis or, even worse, as the posterior probability that the hypothesis is true. The fact that these interpretations can be completely misleading when testing precise hypotheses is first reviewed, through consideration of two revealing simulations. Then two calibrations of a {$\rho$} value are developed, the first being interpretable as odds and the second as either a (conditional) frequentist error probability or as the posterior probability of the hypothesis.},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2001/Sellke et al_2001_Calibration of ρ values for testing precise null hypotheses.pdf},
  journal = {The American Statistician},
  keywords = {Bayes factors,Bayesian robustness,Conditional frequentist error probabilities,Odds},
  note = {\url{https://doi.org/10.1198/000313001300339950}},
  number = {1}
}

@book{sennStatisticalIssuesDrug2007,
  title = {Statistical {{Issues}} in {{Drug Development}}},
  author = {Senn, Stephen},
  year = {2007},
  edition = {2nd ed},
  publisher = {{John Wiley \& Sons}},
  address = {{Chichester, England ; Hoboken, NJ}},
  annotation = {OCLC: ocn180907943},
  file = {/Users/zad/Zotero/storage/TQZ7J8SM/Senn - 2007 - Statistical issues in drug development.pdf},
  isbn = {978-0-470-01877-4},
  keywords = {Clinical Trials as Topic,Drug Design,Drug development,methods,Statistical methods,Statistics as Topic},
  language = {en},
  lccn = {RM301.25 .S46 2007},
  series = {Statistics in Practice}
}

@article{shaferLanguageBettingStrategy2020,
  title = {The {{Language}} of {{Betting}} as a {{Strategy}} for {{Statistical}} and {{Scientific Communication}}},
  author = {Shafer, Glenn},
  year = {2020},
  volume = {in press},
  abstract = {The established language for statistical testing --- significance levels, power, and p-values --- is overly complicated and deceptively conclusive. Even teachers of statistics and scientists who use statistics misinterpret the results of statistical tests, tending to misstate their meaning and exaggerate their certainty. We can communicate the meaning and limitations of statistical evidence more clearly using the language of betting. This paper calls attention to a simple betting interpretation of likelihood ratios. This interpretation leads to methods that lend themselves to meta-analysis and accounting for multiple testing. It is closely related to the interpretation of probability as frequency, but it does not encourage the fallacy that probabilistic models imply the existence of unseen alternative worlds. For more on the betting interpretation of probability, see \textbackslash cite\{Shafer/Vovk:2019\} and the other working papers at www.probabilityandfinance.com.},
  file = {/Users/zad/Zotero/storage/G4M9Q6C4/Shafer_2019_The Language of Betting as a Strategy for Statistical and Scientific.pdf;/Users/zad/Zotero/storage/IJXX9EA8/1903.html},
  journal = {Journal of the Royal Statistical Society},
  keywords = {⛔ No DOI found,Mathematics - Statistics Theory}
}

@article{Shannon1948-uq,
  title = {A Mathematical Theory of Communication},
  author = {Shannon, C E},
  year = {1948},
  month = jul,
  volume = {27},
  pages = {379--423},
  issn = {0005-8580},
  doi = {10.1002/j.1538-7305.1948.tb01338.x},
  abstract = {The recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensified the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the final destination of the information.},
  file = {/Users/zad/Google Drive/Research/Zotero/The Bell System Technical Journal/1948/Shannon_1948_A mathematical theory of communication.pdf},
  journal = {The Bell System Technical Journal},
  note = {\url{https://doi.org/10.1002/j.1538-7305.1948.tb01338.x}},
  number = {3}
}

@article{Simmons2011-em,
  title = {False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant},
  author = {Simmons, Joseph P and Nelson, Leif D and Simonsohn, Uri},
  year = {2011},
  month = nov,
  volume = {22},
  pages = {1359--1366},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/0956797611417632},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings ({$\leq$} .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  affiliation = {Wharton School, University of Pennsylvania, Philadelphia, PA 19104, USA. jsimmo@wharton.upenn.edu},
  file = {/Users/zad/Google Drive/Research/Zotero/Psychol. Sci./2011/Simmons et al_2011_False-positive psychology.pdf},
  journal = {Psychological Science},
  keywords = {NHST},
  language = {English},
  note = {\url{https://doi.org/10.1177/0956797611417632}},
  number = {11},
  pmid = {22006061}
}

@article{Singh2007-zr,
  title = {Confidence Distribution ({{CD}}) -- Distribution Estimator of a Parameter},
  author = {Singh, Kesar and Xie, Minge and Strawderman, William E},
  year = {2007},
  month = aug,
  abstract = {The notion of confidence distribution (CD), an entirely frequentist concept, is in essence a Neymanian interpretation of Fisher's Fiducial distribution. It contains information related to every kind of frequentist inference. In this article, a CD is viewed as a distribution estimator of a parameter. This leads naturally to consideration of the information contained in CD, comparison of CDs and optimal CDs, and connection of the CD concept to the (profile) likelihood function. A formal development of a multiparameter CD is also presented.},
  archivePrefix = {arXiv},
  arxivid = {0708.0976},
  eprint = {0708.0976},
  eprinttype = {arxiv},
  file = {/Users/zad/Google Drive/Research/Zotero/undefined/2007/Singh et al_2007_Confidence distribution (CD) -- distribution estimator of a parameter.pdf},
  journal = {arXiv},
  keywords = {⛔ No DOI found},
  note = {\url{https://arxiv.org/abs/0708.0976}},
  primaryClass = {math.ST}
}

@article{Stark2018-eo,
  title = {Cargo-Cult Statistics and Scientific Crisis},
  author = {Stark, Philip B and Saltelli, Andrea},
  year = {2018},
  month = aug,
  volume = {15},
  pages = {40--43},
  issn = {1740-9705},
  doi = {10.1111/j.1740-9713.2018.01174.x},
  abstract = {The mechanical, ritualistic application of statistics is contributing to a crisis in science. Education, software and peer review have encouraged poor practice ? and it is time for statisticians to fight back. By Philip B. Stark and Andrea Saltelli The full-text article may be found on the RSS website.},
  file = {/Users/zad/Google Drive/Research/Zotero/Significance/2018/Stark_Saltelli_2018_Cargo-cult statistics and scientific crisis.pdf},
  journal = {Significance},
  note = {\url{https://doi.org/10.1111/j.1740-9713.2018.01174.x}},
  number = {4}
}

@article{starkConstraintsPriors2015,
  title = {Constraints versus {{Priors}}},
  author = {Stark, Philip B.},
  year = {2015},
  month = jan,
  volume = {3},
  pages = {586--598},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/130920721},
  abstract = {There are deep and important philosophical differences between Bayesian and frequentist approaches to quantifying uncertainty. However, some practitioners choose between these approaches primarily on the basis of convenience. For instance, the ability to incorporate parameter constraints is sometimes cited as a reason to use Bayesian methods. This reflects two misunderstandings: First, frequentist methods can indeed incorporate constraints on parameter values. Second, it ignores the crucial question of what the result of the analysis will mean. Bayesian and frequentist measures of uncertainty have similar sounding names but quite different meanings. For instance, Bayesian uncertainties typically involve expectations with respect to the posterior distribution of the parameter, holding the data fixed; frequentist uncertainties typically involve expectations with respect to the distribution of the data, holding the parameter fixed. Bayesian methods, including methods incorporating parameter constraints, require supplementing the constraints with a prior probability distribution for parameter values. This can cause frequentist and Bayesian estimates and their nominal uncertainties to differ substantially, even when the prior is ``uninformative.'' This paper gives simple examples where ``uninformative'' priors are, in fact, extremely informative, and sketches how to measure how much information the prior adds to the constraint. Bayesian methods can have good frequentist behavior, and a frequentist can use Bayesian methods and quantify the uncertainty by frequentist means---but absent a meaningful prior, Bayesian uncertainty measures lack meaning. The paper ends with brief reflections on practice.},
  file = {/Users/zad/Zotero/storage/SXDPS5AL/Stark_2015_Constraints versus Priors.pdf;/Users/zad/Zotero/storage/URW5B8BB/130920721.html;/Users/zad/Zotero/storage/ZVUUQGAC/Stark - 2015 - Constraints versus Priors.html},
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  note = {\url{https://doi.org/10.1137/130920721}},
  number = {1}
}

@incollection{stiglerAttemptsReviveBinomial1986,
  title = {Attempts to {{Revive}} the {{Binomial}}},
  booktitle = {The {{History}} of {{Statistics}}: {{The Measurement}} of {{Uncertainty Before}} 1900},
  author = {Stigler, Stephen M.},
  year = {1986},
  publisher = {{Harvard University Press}},
  abstract = {This magnificent book is the first comprehensive history of statistics from its beginnings around 1700 to its emergence as a distinct and mature discipline around 1900. Stephen M. Stigler shows how statistics arose from the interplay of mathematical concepts and the needs of several applied sciences including astronomy, geodesy, experimental psychology, genetics, and sociology. He addresses many intriguing questions: How did scientists learn to combine measurements made under different conditions? And how were they led to use probability theory to measure the accuracy of the result? Why were statistical methods used successfully in astronomy long before they began to play a significant role in the social sciences? How could the introduction of least squares predate the discovery of regression by more than eighty years? On what grounds can the major works of men such as Bernoulli, De Moivre, Bayes, Quetelet, and Lexis be considered partial failures, while those of Laplace, Galton, Edgeworth, Pearson, and Yule are counted as successes? How did Galton's probability machine (the quincunx) provide him with the key to the major advance of the last half of the nineteenth century? Stigler's emphasis is upon how, when, and where the methods of probability theory were developed for measuring uncertainty in experimental and observational science, for reducing uncertainty, and as a conceptual framework for quantitative studies in the social sciences. He describes with care the scientific context in which the different methods evolved and identifies the problems (conceptual or mathematical) that retarded the growth of mathematical statistics and the conceptual developments that permitted major breakthroughs. Statisticians, historians of science, and social and behavioral scientists will gain from this book a deeper understanding of the use of statistical methods and a better grasp of the promise and limitations of such techniques. The product of ten years of research, The History of Statistics will appeal to all who are interested in the humanistic study of science.},
  googlebooks = {M7yvkERHIIMC},
  isbn = {978-0-674-40341-3},
  keywords = {History / General,Mathematics / Probability \& Statistics / General},
  language = {en},
  note = {\url{https://books.google.com/books?id=M7yvkERHIIMC}}
}

@article{Sullivan1990-ha,
  title = {Use of the Confidence Interval Function},
  author = {Sullivan, K M and Foster, D A},
  year = {1990},
  month = jan,
  volume = {1},
  pages = {39--42},
  issn = {1044-3983},
  doi = {10.1097/00001648-199001000-00009},
  abstract = {Graphics displaying all confidence intervals around a point estimate have been referred to as P-value functions and consonance intervals. We recommend use of the term confidence interval function (CI function) rather than P-value function. The CI function is useful because it simultaneously depicts point estimation, variability, and the relation of these two factors to the null value. The usefulness of the CI function in demonstrating the concepts of effect modification and confounding, in meta-analysis, and in the comparison of various confidence interval procedures is evaluated. Software packages that produce CI functions are described.},
  affiliation = {Division of Nutrition, Centers for Disease Control, Atlanta, GA 30333.},
  file = {/Users/zad/Google Drive/Research/Zotero/Epidemiology/1990/Sullivan_Foster_1990_Use of the confidence interval function.pdf},
  journal = {Epidemiology},
  language = {English},
  note = {\url{https://doi.org/10.1097/00001648-199001000-00009}},
  number = {1},
  pmid = {2150497}
}

@article{The_Editors2001-vt,
  title = {The Value of {{P}}},
  author = {{The Editors}},
  year = {2001},
  month = may,
  volume = {12},
  pages = {286},
  issn = {1044-3983},
  abstract = {An abstract is unavailable.},
  journal = {Epidemiology},
  note = {\url{https://journals.lww.com/epidem/Fulltext/2001/05000/The_Value_of_P.2.aspx}},
  number = {3}
}

@article{tverskyJudgmentUncertaintyHeuristics1974,
  title = {Judgment under {{Uncertainty}}: {{Heuristics}} and {{Biases}}},
  shorttitle = {Judgment under {{Uncertainty}}},
  author = {Tversky, Amos and Kahneman, Daniel},
  year = {1974},
  month = sep,
  volume = {185},
  pages = {1124--1131},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.185.4157.1124},
  abstract = {This article described three heuristics that are employed in making judgements under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgements and decisions in situations of uncertainty.},
  chapter = {Articles},
  copyright = {1974 by the American Association for the Advancement of Science},
  file = {/Users/zad/Zotero/storage/3IGNLV4U/Tversky_Kahneman_1974_Judgment under Uncertainty.pdf;/Users/zad/Zotero/storage/897QHJTM/1124.html},
  journal = {Science},
  language = {en},
  note = {\url{https://doi.org/10.1126/science.185.4157.1124}},
  number = {4157},
  pmid = {17835457}
}

@article{tylerWhatStatisticalSignificance1931,
  title = {What Is Statistical Significance?},
  author = {Tyler, Ralph W.},
  year = {1931},
  volume = {10},
  pages = {115--142},
  issn = {1555-4023},
  journal = {Educational Research Bulletin},
  keywords = {⛔ No DOI found},
  note = {\url{https://jstor.org/stable/1471747}},
  number = {5}
}

@article{vickersInterpretingDataRandomized2005,
  title = {Interpreting Data from Randomized Trials: The {{Scandinavian}} Prostatectomy Study Illustrates Two Common Errors},
  shorttitle = {Interpreting Data from Randomized Trials},
  author = {Vickers, Andrew},
  year = {2005},
  month = sep,
  volume = {2},
  pages = {404},
  issn = {1743-4289},
  doi = {10.1038/ncpuro0294},
  abstract = {Statistical analysis is an essential part of clinical practice, since the very concept of evidence-based medicine hinges on sound interpretation of clinical data. Using the Scandinavian prostatectomy versus watchful waiting study as a practical example, Andrew Vickers presents two common errors: accepting the null hypothesis and misinterpreting the lower statistical power of overall versus cancer-specific survival, and warns of the dangers of forgetting these basic principles.},
  copyright = {2005 Nature Publishing Group},
  file = {/Users/zad/Google Drive/Research/Zotero/Nature Clinical Practice Urology/2005/Vickers_2005_Interpreting data from randomized trials.pdf},
  journal = {Nature Clinical Practice Urology},
  language = {En},
  note = {\url{https://doi.org/10.1038/ncpuro0294}},
  number = {9}
}

@misc{vickersScandinavianProstatectomyStudy,
  title = {Scandinavian Prostatectomy Study Illustrates Two Common Errors},
  author = {Vickers, Andrew},
  abstract = {This article discusses 2 common statistical errors: accepting the null hypothesis and misinterpreting the lower power of overall vs cancer-specific survival.},
  howpublished = {\url{https://medscape.com/viewarticle/512952}},
  journal = {Medscape}
}

@article{Viechtbauer2010-ss,
  ids = {viechtbauerConductingMetaanalysesMetafor2010},
  title = {Conducting Meta-Analyses in {{R}} with the Metafor Package},
  author = {Viechtbauer, Wolfgang},
  year = {2010},
  volume = {36},
  publisher = {{UCLA Statistics}},
  doi = {10.18637/jss.v036.i03},
  file = {/Users/zad/Google Drive/Research/Zotero/J. Stat. Softw./2010/Viechtbauer_2010_Conducting meta-analyses in R with the metafor package.pdf},
  journal = {J. Stat. Softw.},
  note = {\url{https://www.jstatsoft.org/article/view/v036i03/v36i03.pdf}},
  number = {3}
}

@article{vosFrequentistInferenceRepeated2019,
  title = {Frequentist Inference without Repeated Sampling},
  author = {Vos, Paul and Holbert, Don},
  year = {2019},
  month = jun,
  abstract = {Frequentist inference typically is described in terms of hypothetical repeated sampling but there are advantages to an interpretation that uses a single random sample. Contemporary examples are given that indicate probabilities for random phenomena are interpreted as classical probabilities, and this interpretation is applied to statistical inference using urn models. Both classical and limiting relative frequency interpretations can be used to communicate statistical inference, and the effectiveness of each is discussed. Recent descriptions of p-values, confidence intervals, and power are viewed through the lens of classical probability based on a single random sample from the population.},
  archivePrefix = {arXiv},
  eprint = {1906.08360},
  eprinttype = {arxiv},
  file = {/Users/zad/Google Drive/Research/Zotero/arXiv1906.08360 [stat]/2019/Vos_Holbert_2019_Frequentist Inference without Repeated Sampling.pdf},
  journal = {arXiv:1906.08360 [stat.OT]},
  keywords = {⛔ No DOI found,Statistics - Applications,Statistics - Other Statistics},
  note = {\url{https://arxiv.org/abs/1906.08360}},
  primaryClass = {stat.OT}
}

@article{wangResearcherRequestsInappropriate2018,
  title = {Researcher Requests for Inappropriate Analysis and Reporting: {{A U}}.{{S}}. Survey of Consulting Biostatisticians},
  shorttitle = {Researcher {{Requests}} for {{Inappropriate Analysis}} and {{Reporting}}},
  author = {Wang, Min Qi and Yan, Alice F. and Katz, Ralph V.},
  year = {2018},
  month = oct,
  volume = {169},
  pages = {554},
  issn = {0003-4819},
  doi = {10.7326/M18-1230},
  file = {/Users/zad/Google Drive/Research/Zotero/Annals of Internal Medicine/2018/Wang et al_2018_Researcher requests for inappropriate analysis and reporting.pdf},
  journal = {Annals of Internal Medicine},
  language = {en},
  note = {\url{https://doi.org/10.7326/M18-1230}},
  number = {8}
}

@article{wassersteinMovingWorld052019,
  ids = {wassersteinMovingWorld052019a},
  title = {Moving to a World beyond ``p {$<$} 0.05''},
  author = {Wasserstein, Ronald L. and Schirm, Allen L. and Lazar, Nicole A.},
  year = {2019},
  month = mar,
  volume = {73},
  pages = {1--19},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.2019.1583913},
  file = {/Users/zad/Google Drive/Research/Zotero/The American Statistician/2019/Wasserstein et al_2019_Moving to a World Beyond “p 0.pdf;/Users/zad/Zotero/storage/8Q2G4GJR/Wasserstein et al_2019_Moving to a World Beyond “p 0.pdf;/Users/zad/Zotero/storage/BJLPU7DI/00031305.2019.html},
  journal = {The American Statistician},
  note = {\url{https://doi.org/10.1080/00031305.2019.1583913}},
  number = {sup1}
}

@article{westreichTableFallacyPresenting2013,
  title = {The {{Table}} 2 {{Fallacy}}: {{Presenting}} and {{Interpreting Confounder}} and {{Modifier Coefficients}}},
  shorttitle = {The {{Table}} 2 {{Fallacy}}},
  author = {Westreich, Daniel and Greenland, Sander},
  year = {2013},
  month = feb,
  volume = {177},
  pages = {292--298},
  publisher = {{Oxford Academic}},
  issn = {0002-9262},
  doi = {10.1093/aje/kws412},
  abstract = {Abstract.  It is common to present multiple adjusted effect estimates from a single model in a single table. For example, a table might show odds ratios for one},
  file = {/Users/zad/Zotero/storage/V5TNKJ68/Westreich_Greenland_2013_The Table 2 Fallacy.pdf;/Users/zad/Zotero/storage/YGVJ7B36/147738.html},
  journal = {American Journal of Epidemiology},
  language = {en},
  note = {\url{https://doi.org/10.1093/aje/kws412}},
  number = {4}
}

@article{whiteheadCaseFrequentismClinical1993,
  title = {The Case for Frequentism in Clinical Trials},
  author = {Whitehead, John},
  year = {1993},
  volume = {12},
  pages = {1405--1413},
  issn = {1097-0258},
  doi = {10.1002/sim.4780121506},
  copyright = {Copyright \textcopyright{} 1993 John Wiley \& Sons, Ltd.},
  file = {/Users/zad/Google Drive/Research/Zotero/Statistics in Medicine/1993/Whitehead_1993_The case for frequentism in clinical trials.pdf},
  journal = {Statistics in Medicine},
  language = {en},
  note = {\url{https://doi.org/10.1002/sim.4780121506}},
  number = {15-16}
}

@misc{wilkeCowplotStreamlinedPlot2019,
  title = {Cowplot: {{Streamlined}} Plot Theme and Plot Annotations for 'Ggplot2'},
  author = {Wilke, Claus O.},
  year = {2019},
  howpublished = {\url{https://CRAN.R-project.org/package=cowplot}}
}

@article{xieConfidenceDistributionFrequentist2013,
  title = {Confidence {{Distribution}}, the {{Frequentist Distribution Estimator}} of a {{Parameter}}: {{A Review}}},
  author = {Xie, Min-ge and Singh, Kesar},
  year = {2013},
  month = apr,
  volume = {81},
  pages = {3--39},
  issn = {0306-7734},
  doi = {10.1111/insr.12000},
  abstract = {R\'esum\'e Il est courant, en inf\'erence fr\'equentielle, d'utiliser un point unique (une estimation ponctuelle) ou un intervalle (intervalle de confiance) dans le but d'estimer un param\`etre d'int\'er\^t. Une question tr\`es simple se pose: peut-on \'egalement utiliser, dans le m\^eme but, et dans la m\^eme optique fr\'equentielle, \`a la fa\c{c}on dont les Bay\'esiens utilisent une loi a posteriori, une distribution de probabilit\'e? La r\'eponse est affirmative, et les distributions de confiance apparaissent comme un choix naturel dans ce contexte. Le concept de distribution de confiance a une longue histoire, longtemps associ\'ee, \`a tort, aux th\'eories d'inf\'erence fiducielle, ce qui a compromis son d\'eveloppement dans l'optique fr\'equentielle. Les distributions de confiance ont r\'ecemment attir\'e un regain d'int\'er\^et, et plusieurs r\'esultats ont mis en \'evidence leur potentiel consid\'erable en tant qu'outil inf\'erentiel. Cet article pr\'esente une d\'efinition moderne du concept, et examine les ses \'evolutions r\'ecentes. Il aborde les m\'ethodes d'inf\'erence, les probl\`emes d'optimalit\'e, et les applications. A la lumi\`ere de ces nouveaux d\'eveloppements, le concept de distribution de confiance englobe et unifie un large \'eventail de cas particuliers, depuis les exemples param\'etriques r\'eguliers (distributions fiducielles), les lois de r\'e\'echantillonnage, les p-valeurs et les fonctions de vraisemblance normalis\'ees jusqu'aux a priori et posteriori bay\'esiens. La discussion est enti\`erement men\'ee d'un point de vue fr\'equentiel, et met l'accent sur les applications dans lesquelles les solutions fr\'equentielles sont inexistantes ou d'une application difficile. Bien que nous attirions \'egalement l'attention sur les similitudes et les diff\'erences que pr\'esentent les approches fr\'equentielle, fiducielle, et Bay\'esienne, notre intention n'est pas de rouvrir un d\'ebat philosophique qui dure depuis pr\`es de deux cents ans. Nous esp\'erons bien au contraire contribuer \`a combler le foss\'e qui existe entre les diff\'erents points de vue.},
  file = {/Users/zad/Google Drive/Research/Zotero/International Statistical Review/2013/Xie_Singh_2013_Confidence Distribution, the Frequentist Distribution Estimator of a Parameter.pdf},
  journal = {International Statistical Review},
  keywords = {Bayesian method,Confidence distribution,estimation theory,fiducial distribution,likelihood function,statistical inference},
  note = {\url{https://doi.org/10.1111/insr.12000}},
  number = {1}
}

@misc{yasgurAntidepressantsPregnancyNo2017,
  title = {Antidepressants in Pregnancy: {{No}} Link to Autism, {{ADHD}}},
  shorttitle = {Antidepressants in {{Pregnancy}}},
  author = {Yasgur, Batya},
  year = {2017},
  month = apr,
  abstract = {Extensive research has shown a link between maternal use of antidepressants during pregnancy and autism in the offspring. But is the relationship causal? New studies shed light on confounding factors.},
  howpublished = {\url{https://medscape.com/viewarticle/878948}},
  journal = {Medscape},
  type = {Medical {{Website}}}
}


